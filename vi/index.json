[{"uri":"https://thienluhoan.github.io/workshop-template/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Võ Hoàng Minh\nSố điện thoại: 0826400643\nEmail: minh7n3@gmail.com\nUniversity: FPT University\nNgành: Kỹ thuật phần mềm\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-network/5.3.1-vpc/","title":"Cấu hình VPC, Subnets &amp; Routing","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ thiết lập môi trường mạng cô lập cho IELTS BandUp. Chúng ta sẽ khởi tạo một Virtual Private Cloud (VPC), phân chia nó thành các subnet trên nhiều Availability Zones, và cấu hình định tuyến để truy cập Internet.\n1. Khởi tạo VPC Đầu tiên, chúng ta cần một không gian mạng riêng tư.\nTruy cập VPC Dashboard. Chọn Create VPC. Chọn mục VPC only. Name tag: Điền band-up-vpc. IPv4 CIDR block: Điền 10.0.0.0/16 (Dải mạng này cung cấp 65,536 địa chỉ IP, đủ cho việc mở rộng sau này). Giữ nguyên các cài đặt khác và nhấn Create VPC. 2. Tạo Subnets (Phân vùng mạng) Tiếp theo, chúng ta chia VPC thành các mạng nhỏ hơn (Subnets) phân tán trên hai Availability Zones (AZs) để đảm bảo tính sẵn sàng cao (High Availability). Chúng ta sẽ tuân theo sơ đồ IP sau:\nTên Subnet Loại CIDR Block Availability Zone public-subnet-1 Public 10.0.0.0/24 ap-southeast-1a public-subnet-2 Public 10.0.1.0/24 ap-southeast-1b private-app-subnet-1 Private 10.0.2.0/24 ap-southeast-1a private-app-subnet-2 Private 10.0.3.0/24 ap-southeast-1b private-database-subnet-1 Database 10.0.4.0/24 ap-southeast-1a private-database-subnet-2 Database 10.0.5.0/24 ap-southeast-1b Các bước thực hiện:\nVào menu Subnets \u0026gt; Create subnet. Chọn VPC ID: band-up-vpc. Nhập Subnet name, Availability Zone, và IPv4 CIDR block cho từng subnet theo bảng trên. Lặp lại quy trình cho đến khi tạo đủ 6 subnets. 3. Tạo Internet Gateway (IGW) Mặc định, một VPC hoàn toàn khép kín. Để các tài nguyên trong Public Subnet có thể giao tiếp với thế giới bên ngoài, ta cần một Internet Gateway.\nVào menu Internet gateways \u0026gt; Create internet gateway. Name tag: Điền band-up-igw. Nhấn Create internet gateway. Sau khi tạo xong, nhấn Actions \u0026gt; Attach to VPC. Chọn band-up-vpc và nhấn Attach internet gateway. 4. Cấu hình Route Tables (Bảng định tuyến) Cuối cùng, ta cần điều hướng lưu lượng từ Public Subnets ra Internet Gateway.\nVào menu Route tables \u0026gt; Create route table. Name: public-route-table. VPC: band-up-vpc. Nhấn Create route table. Thêm Route ra Internet:\nChọn public-route-table vừa tạo. Chuyển sang tab Routes \u0026gt; Edit routes. Thêm một route mới: Destination: 0.0.0.0/0 (Tất cả lưu lượng). Target: Chọn Internet Gateway -\u0026gt; band-up-igw. Nhấn Save changes. Liên kết Subnets (Subnet Association):\nChuyển sang tab Subnet associations \u0026gt; Edit subnet associations. Tích chọn các Public Subnets (public-subnet-1 và public-subnet-2). Nhấn Save associations. 5. Kiểm tra cấu hình Để kiểm chứng kiến trúc mạng đã được thiết lập chính xác hay chưa, hãy quay lại VPC Dashboard, chọn band-up-vpc và xem tab Resource map. Bạn sẽ thấy một sơ đồ rõ ràng liên kết các Public Subnet với Route Table và Internet Gateway.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"1. Kiến trúc tổng quan Nền tảng IELTS BandUp được xây dựng trên một kiến trúc mạnh mẽ, có tính sẵn sàng cao (High Availability) trên AWS. Hệ thống được thiết kế để xử lý lưu lượng người dùng một cách an toàn, đồng thời đảm bảo độ trễ thấp khi truy cập tài liệu học tập và các tính năng AI.\n2. Các dịch vụ AWS cốt lõi Để đạt được các mục tiêu về khả năng mở rộng, bảo mật và hiệu năng, chúng tôi sử dụng các nhóm dịch vụ chính sau:\nMạng \u0026amp; Phân phối nội dung (Networking) Amazon VPC (Virtual Private Cloud): Lớp mạng nền tảng. Chúng tôi sử dụng VPC tùy chỉnh với các Public Subnet và Private Subnet riêng biệt để kiểm soát chặt chẽ luồng truy cập. NAT Gateway: Cho phép các tài nguyên trong Private Subnet (như Backend) kết nối ra Internet (để tải thư viện, gọi API ngoài) mà không để lộ IP ra môi trường Public. Application Load Balancer (ALB): Phân phối lưu lượng truy cập ứng dụng đến các container trên nhiều Availability Zones (AZ), đảm bảo khả năng chịu lỗi của hệ thống. Amazon Route 53: Dịch vụ DNS giúp định tuyến tên miền và quản lý lưu lượng truy cập người dùng. Tính toán \u0026amp; Container (Compute) Amazon ECS (Elastic Container Service) với Fargate: Công cụ điều phối container serverless. Chúng tôi sử dụng Fargate để vận hành cả Next.js Frontend và Spring Boot Backend, giúp loại bỏ gánh nặng quản lý máy chủ vật lý (EC2). Amazon ECR (Elastic Container Registry): Kho lưu trữ container được quản lý hoàn toàn, nơi chứa các Docker image của ứng dụng trước khi deploy. Cơ sở dữ liệu \u0026amp; Lưu trữ (Database \u0026amp; Storage) Amazon RDS (Relational Database Service): Sử dụng PostgreSQL với mô hình Multi-AZ (Primary và Standby) để đảm bảo an toàn dữ liệu và khả năng khôi phục sau thảm họa. Amazon ElastiCache (Redis): Đóng vai trò bộ nhớ đệm (cache) trong bộ nhớ, giúp tăng tốc độ truy vấn và quản lý phiên đăng nhập (session) của người dùng. Amazon S3 (Simple Storage Service): Lưu trữ tài nguyên tĩnh, file media (file nghe) và dữ liệu người dùng tải lên với độ bền cao. AI \u0026amp; Tích hợp Serverless Để vận hành các tính năng thông minh của BandUp (Chấm điểm Writing/Speaking, Tạo Flashcard), chúng tôi áp dụng kiến trúc Serverless:\nAmazon Bedrock \u0026amp; Google Gemini API: Các mô hình Generative AI cốt lõi dùng để phân tích bài làm và đưa ra phản hồi cá nhân hóa. AWS Lambda: Các hàm tính toán serverless đóng vai trò điều phối quy trình AI, kết nối ứng dụng với các mô hình ngôn ngữ lớn. Amazon SQS (Simple Queue Service): Hàng đợi thông điệp giúp phân tách (decouple) backend và lớp xử lý AI, cho phép xử lý bất đồng bộ và tránh quá tải hệ thống. Amazon API Gateway: Cổng giao tiếp bảo mật (RESTful API) để gọi các dịch vụ AI từ ứng dụng chính. DevOps \u0026amp; CI/CD AWS CodePipeline: Tự động hóa quy trình phát hành phần mềm, đảm bảo cập nhật nhanh chóng và tin cậy. AWS CodeBuild: Biên dịch mã nguồn, chạy kiểm thử và đóng gói phần mềm (Docker images) sẵn sàng cho việc triển khai. Bảo mật (Security) AWS WAF (Web Application Firewall): Bảo vệ ứng dụng web khỏi các lỗ hổng bảo mật phổ biến. AWS Secrets Manager: Lưu trữ và quản lý an toàn các thông tin nhạy cảm (mật khẩu database, API keys) trong suốt vòng đời ứng dụng. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-setup-fe/5.4.1-docker/","title":"Thiết lập ECR &amp; Đẩy Image","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ tiến hành đóng gói ứng dụng Frontend (Next.js) thành Docker container và đẩy (push) image đó lên Amazon Elastic Container Registry (ECR). Image này sẽ được ECS Fargate sử dụng để khởi chạy ứng dụng sau này.\n1. Chuẩn bị Dockerfile Chúng tôi sử dụng Dockerfile đa tầng (multi-stage) được tối ưu hóa cho Bun (một JavaScript runtime tốc độ cao) và Next.js. Cấu hình này giúp giảm kích thước image cuối cùng và tăng cường bảo mật.\nBase Image: oven/bun:1.1.26 Builder: Thực hiện biên dịch ứng dụng Next.js. Runner: Môi trường production nhẹ nhàng, mở cổng 3000. 2. Build Docker Image Chạy lệnh sau tại thư mục gốc của dự án để build image. Chúng ta sẽ đặt tag là band-up-frontend.\ndocker build -t band-up-frontend . Quá trình build sẽ cài đặt các thư viện phụ thuộc bằng bun install và biên dịch dự án.\n3. Kiểm tra Image tại Local Sau khi build xong, hãy kiểm tra xem image đã được tạo thành công hay chưa.\ndocker image ls Bạn sẽ thấy band-up-frontend với tag latest trong danh sách.\nChạy thử nghiệm: Bạn có thể chạy thử container trên máy local để đảm bảo ứng dụng khởi động đúng cách trước khi đẩy lên AWS.\ndocker run -p 3000:3000 band-up-frontend:latest 4. Đẩy Image lên Amazon ECR Bây giờ chúng ta cần tải image này lên AWS.\nBước 1: Tạo Repository\nTruy cập Amazon ECR \u0026gt; Repositories. Nhấn Create repository. Visibility settings: Chọn Private. Repository name: Nhập band-up-frontend. Nhấn Create repository. Bước 2: Push Image Sử dụng AWS CLI để xác thực và đẩy image. Hãy thay thế [AWS_ACCOUNT_ID] và [REGION] bằng thông tin tài khoản của bạn.\nĐăng nhập vào ECR:\naws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin [AWS_ACCOUNT_ID].dkr.ecr.ap-southeast-1.amazonaws.com Gán Tag cho Image:\ndocker tag band-up-frontend:latest [AWS_ACCOUNT_ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:latest Đẩy Image lên ECR:\ndocker push [AWS_ACCOUNT_ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:latest Sau khi quá trình push hoàn tất, image của bạn đã được lưu trữ an toàn trên AWS ECR và sẵn sàng để triển khai.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-setup-be/5.5.1-ecr/","title":"Thiết lập ECR &amp; Đẩy Image","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ đóng gói ứng dụng Backend (Spring Boot) và đẩy Docker image đã được tối ưu hóa lên Amazon ECR.\n1. Chiến lược Dockerfile Đối với Backend, chúng ta sử dụng chiến lược Multi-Stage Build với eclipse-temurin:21 (Java 21). Điều này giúp tạo ra image cuối cùng nhỏ gọn và bảo mật.\nStage 1 (Deps): Tải về các thư viện phụ thuộc (dependencies) của Maven. Stage 2 (Package): Build ứng dụng và trích xuất Spring Boot Layered Jar. Kỹ thuật này tách ứng dụng thành các lớp riêng biệt (dependencies, spring-boot-loader, code ứng dụng), giúp Docker cache hiệu quả các phần ít thay đổi. Stage 3 (Final): Sao chép các lớp đã trích xuất vào một JRE image nhẹ. Đồng thời tạo một user không có quyền quản trị (appuser) để tăng cường bảo mật. 2. Build Docker Image Chạy lệnh build tại thư mục gốc của dự án backend. Chúng ta đặt tag là band-up-backend.\ndocker build -t band-up-backend . Docker sẽ thực thi các bước biên dịch và đóng gói như đã định nghĩa.\n3. Tạo ECR Repository Chúng ta cần một kho chứa cho image này.\nTruy cập Amazon ECR \u0026gt; Create repository. Repository name: Nhập band-up-backend. Visibility: Private. Image tag mutability: Mutable. Nhấn Create repository. 4. Đẩy Image lên ECR (Push) Sau khi build xong và repository đã sẵn sàng, chúng ta tiến hành đẩy image.\nBước 1: Gán Tag (Tagging) Gán tag phiên bản (ví dụ: v1.0.0) cho image local.\ndocker tag band-up-backend:latest [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-backend:v1.0.0 Bước 2: Push lên ECR Tải các layer lên AWS.\ndocker push [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-backend:v1.0.0 5. Kiểm tra kết quả Truy cập Amazon ECR Console và chọn repository bandup-backend. Bạn sẽ thấy image với tag v1.0.0 đã được tải lên thành công.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch “Kick-off Chương Trình The First Cloud Journey (FCJ)” Mục Đích Của Sự Kiện Chính thức khởi động chương trình The First Cloud Journey (FCJ) kéo dài 12 tuần. Kết nối, làm quen giữa các thành viên, Mentors và Ban Tổ Chức (BTC). Giới thiệu tổng quan về tổ chức, mục tiêu học tập và lộ trình triển khai dự án. Hướng dẫn quy trình làm việc nhóm và tiến hành thành lập các nhóm thực hiện dự án. Danh Sách Diễn Giả Đại diện Ban Tổ Chức (BTC) - Giới thiệu về tầm nhìn và sứ mệnh của chương trình. Các Mentors tiêu biểu - Chia sẻ kinh nghiệm và lộ trình thành công trong lĩnh vực Cloud. Các thành viên cựu (Alumni) - Chia sẻ các bài học kinh nghiệm thực tế. Nội Dung Nổi Bật Khung chương trình và Lộ trình 12 tuần Trình bày chi tiết roadmap 12 tuần, từ kiến thức AWS cơ bản (VPC, EC2) đến triển khai dự án Serverless hoàn chỉnh. Đặt ra mục tiêu cụ thể về kiến thức và sản phẩm đầu ra (Minimum Viable Product - MVP). Quy tắc làm việc và Văn hóa tổ chức Quy định về kỷ luật, tham gia: Nhấn mạnh sự cam kết và trách nhiệm cá nhân trong suốt hành trình. Văn hóa chia sẻ và hỗ trợ: Xây dựng tinh thần cộng đồng mạnh mẽ giữa các thành viên. Quy trình thành lập nhóm và Dự án Hướng dẫn cách thức tạo nhóm hiệu quả (phân bổ vai trò, công cụ giao tiếp). Đưa ra định hướng ban đầu cho các dự án Cloud để các nhóm bắt đầu nghiên cứu. An toàn tài khoản AWS Hướng dẫn thiết lập bảo mật hai lớp (2FA) và các thao tác cơ bản để quản lý chi phí (Budget) ngay từ đầu. Những Gì Học Được Tư Duy và Cam Kết Tầm quan trọng của kỷ luật: Nhận thức rõ tính nghiêm túc và mức độ cam kết cần thiết để hoàn thành chương trình. Vai trò của cộng đồng: Giá trị của việc học hỏi và hỗ trợ từ các Mentors và thành viên khác. Kiến Thức Tổ Chức Mục tiêu của chương trình: Hiểu rõ những kiến thức và kỹ năng Cloud mà chương trình mong muốn trang bị cho học viên. Lộ trình học tập rõ ràng: Nắm được các module chính cần chinh phục trong 12 tuần. Kỹ Năng Thực Hành Đầu Tiên Quy trình lập nhóm: Hoàn thành việc tạo nhóm dự án cùng các thành viên mới. Bảo mật cơ bản: Nắm được các bước ban đầu để thiết lập tài khoản AWS an toàn và tối ưu chi phí. Ứng Dụng Vào Công Việc Ngay lập tức thành lập nhóm và phân công nhiệm vụ đầu tiên. Bắt đầu tìm hiểu về tổ chức và các khái niệm Cloud cơ bản. Thực hiện các thao tác cơ bản trên tài khoản AWS như thiết lập 2FA và Budget (theo Worklog Tuần 1). Trải nghiệm trong event Tham gia buổi Kick-off là một trải nghiệm tràn đầy năng lượng và định hướng rõ ràng. Đây là sự kiện đặt nền móng cho toàn bộ hành trình 12 tuần:\nKết nối và Năng lượng Cộng đồng Cảm giác được chào đón: Gặp gỡ và làm quen với tất cả thành viên trong FCJ, tạo ra môi trường học tập và làm việc nhóm tích cực. Mức độ nghiêm túc: Buổi Kick-off đã truyền tải rõ ràng sự cam kết của BTC, giúp tôi ý thức được sự nghiêm túc cần thiết trong quá trình thực tập. Lộ trình và Mục tiêu Rõ ràng về định hướng: Lần đầu tiên thấy được toàn bộ lộ trình 12 tuần một cách trực quan, giúp tôi lên kế hoạch học tập chủ động hơn. Giá trị của dự án: Hiểu được rằng mục tiêu cuối cùng không chỉ là học mà còn là tạo ra một sản phẩm Cloud thực tế. Bài học thực tiễn ban đầu Tầm quan trọng của 2FA và Budget: Được hướng dẫn trực tiếp về các thao tác bảo mật và quản lý chi phí AWS, những bài học rất quan trọng ngay từ ngày đầu sử dụng Cloud. Teamwork: Nhanh chóng thành lập nhóm và bắt đầu thảo luận về cách thức phối hợp. Kết luận Buổi Kick-off không chỉ là sự kiện giới thiệu mà còn là một buổi huấn luyện, cung cấp đủ thông tin và động lực để tôi tự tin bắt đầu hành trình 12 tuần chinh phục Cloud.\nMột số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện đã hoàn thành xuất sắc mục tiêu: cung cấp thông tin, thiết lập kỷ luật, và khơi dậy sự hứng thú cho một hành trình học tập và phát triển chuyên sâu.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Tìm hiểu về tổ chức và các dịch vụ cơ bản của AWS. Các công việc cần triển khai trong tuần này Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tham gia buổi kick-off của FCJ\n- Tìm hiểu về tổ chức\n- Tạo nhóm cùng thực hiện các dự án 06/09/2025 06/09/2025 3 - Tạo tài khoản AWS\n- Xem và vẽ lại kiến trúc mẫu trên phần mềm draw.io\n- Tìm hiểu về điện toán đám mây 09/09/2025 09/09/2025 cloudjourney.awsstudygroup.com 4 - Tìm hiểu về mục tiêu của chương trình The First Cloud Journey và website AWS\n- Thực hiện các thao tác đầu trên tài khoản đã tạo:\n+ Tạo budget\n+ Tạo groups\n+ Thiết lập bảo mật hai lớp\n- Tìm hiểu về Support Centre của website AWS, cách hoạt động và cách gửi yêu cầu hỗ trợ 10/09/2025 10/09/2025 cloudjourney.awsstudygroup.com 5 - Tạo VPC\n- Chỉnh cấu hình cho VPC\n- Tạo Subnet\n- Cấu hình Subnet public để tự động cấp phát IP công cộng\n- Tạo Internet Gateway\n- Cấu hình Internet Gateway để kết nối với VPC\n- Tạo Route Table\n- Cấu hình Route Table để kết nối với Internet Gateway\n- Cấu hình Subnet Associations thành công\n- Tạo Security Group (public)\n- Tạo Security Group (private) 11/09/2025 14/09/2025 cloudjourney.awsstudygroup.com Kết quả đạt được tuần 1 Tham gia buổi kick-off và làm quen với các thành viên trong First Cloud Journey. Hiểu về tổ chức và các mục tiêu của chương trình. Thành công tạo nhóm để thực hiện các dự án. Tạo tài khoản AWS thành công và thực hiện các thao tác cơ bản: Thiết lập budget. Tạo groups. Kích hoạt bảo mật hai lớp (2FA). Tìm hiểu và vẽ lại kiến trúc mẫu trên draw.io. Nắm được khái niệm cơ bản về điện toán đám mây. Hiểu cách sử dụng Support Centre của AWS và cách gửi yêu cầu hỗ trợ. Thành công thực hiện các tác vụ liên quan đến VPC: Tạo và cấu hình VPC. Tạo và cấu hình Subnet (bao gồm Subnet public với IP công cộng tự động). Tạo và gắn Internet Gateway vào VPC. Tạo và cấu hình Route Table, kết nối với Internet Gateway. Cấu hình Subnet Associations thành công. Tạo Security Group cho cả public và private. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Trang này ghi lại toàn bộ Nhật ký công việc (Worklog) được thực hiện trong suốt chương trình thực tập First Cloud Journey (FCJ) tại AWS. Đây là tài liệu chi tiết hóa quá trình học tập, triển khai dự án Bandup IELTS, khắc phục lỗi hệ thống và tham gia các sự kiện chuyên môn trong vòng 12 tuần (khoảng 3 tháng).\nTrong 12 tuần này, tôi đã chuyển đổi từ việc làm quen với các khái niệm Cloud cơ bản sang việc xây dựng và tối ưu hóa một ứng dụng Serverless tích hợp AI hoàn chỉnh trên AWS, hoàn thành hơn 50 khóa học AWS Skill Builder trong quá trình này.\nTóm tắt công việc theo tuần: Tuần Công việc trọng tâm Tuần 1 Làm quen FCJ, tạo tài khoản AWS, và thiết lập môi trường mạng cơ bản (VPC, Subnets, Internet Gateway). Tuần 2 Nắm vững Amazon EC2 và VPC, hoàn thành các khóa AWS Skill Builder về IAM, Budgets, EC2, và tham gia sự kiện Cloud Day để học hỏi về AI/Data. Tuần 3 Khắc phục sự cố tài khoản AWS, cấu hình Hybrid DNS với Route 53 Resolver và VPC Peering, học CloudFormation và Cloud9 cho phát triển IaC. Tuần 4 Thành thạo AWS Transit Gateway cho quản lý mạng tập trung, nghiên cứu sâu EC2 Auto Scaling, Lightsail, và các dịch vụ Migration (DMS, VM Import/Export). Tuần 5 Phân tích và tối ưu chi phí AWS, thiết kế kiến trúc hạ tầng Serverless, học RDS, DynamoDB, ElastiCache, và thiết lập AWS Toolkit cho VS Code. Tuần 6 Thành thạo dịch vụ Storage AWS (S3, Glacier, Storage Gateway), nâng cao kỹ năng Python, hoàn thiện kiến trúc dự án, và tham gia webinar về DevSecOps và Amazon Q Developer. Tuần 7 Ôn tập toàn diện và củng cố kiến thức các dịch vụ AWS cơ bản (Compute, Storage, Networking, Database, Security) để chuẩn bị cho kỳ thi giữa kỳ. Tuần 8 Hoàn thành thi giữa kỳ, bắt đầu triển khai các chức năng CRUD nền tảng, nghiên cứu kiến trúc serverless (Lambda, API Gateway, DynamoDB), và thiết lập môi trường phát triển. Tuần 9 Chuyển đổi sang AWS SAM, tái cấu trúc các chức năng CRUD, tích hợp Docker cho môi trường build, và triển khai thành công dự án lên AWS vượt qua các thách thức gỡ lỗi Local. Tuần 10 Gỡ lỗi CORS và template validation errors, tích hợp Frontend/Backend, hoàn thành chức năng Read/Delete, giải quyết vấn đề xác thực Cognito, và tham gia AWS Cloud Mastery Series #1. Tuần 11 Triển khai kiến trúc Multi-Stack để tối ưu hóa, khắc phục triệt để lỗi CORS, và bắt đầu tích hợp AI Services (Lambda, Bedrock). Tuần 12 Hoàn thiện Lambda functions tích hợp AI, tích hợp Gemini API cho đánh giá IELTS, hoàn thành RAG pipeline cho tạo flashcard, và tham gia AWS Cloud Mastery Series cuối cùng. Lộ trình học AWS Skill Builder (Tuần 2-5) Danh mục Các khóa học đã hoàn thành Networking VPC, Route 53, VPC Peering, Transit Gateway, Networking Workshop Compute EC2, EC2 Auto Scaling, Lightsail, Lightsail Containers Security IAM, IAM Roles cho EC2 Database RDS, DynamoDB, ElastiCache Migration VM Import/Export, DMS, SCT, Elastic Disaster Recovery DevOps CloudFormation, Cloud9, AWS CLI, AWS Toolkit cho VS Code Quản lý chi phí AWS Budgets, Cost Explorer, Service Quotas, Right-Sizing Architecture Building Highly Available Web Applications Lộ trình học AWS Skill Builder (Tuần 6-10) Danh mục Các khóa học đã hoàn thành Storage Static Website Hosting với S3, AWS Backup, CloudFront Reliability Data Protection với AWS Backup Development AWS Toolkit cho VS Code, Serverless patterns Tiến trình Học tập Tuần 1-5: Nền tảng \u0026amp; Khám phá\nDịch vụ AWS cơ bản (EC2, S3, VPC, IAM) Networking fundamentals (VPC, Route 53, Transit Gateway) Tối ưu chi phí và thiết kế kiến trúc Infrastructure as Code (CloudFormation, Cloud9) Tuần 6-7: Củng cố \u0026amp; Đánh giá\nThành thạo dịch vụ Storage (S3, Glacier, Storage Gateway) Chiến lược disaster recovery và backup Ôn tập toàn diện cho kỳ thi Hoàn thành thi giữa kỳ Tuần 8-10: Triển khai \u0026amp; Deployment\nTriển khai kiến trúc Serverless (Lambda, API Gateway, DynamoDB) Áp dụng framework AWS SAM Tích hợp Docker cho builds nhất quán Tích hợp Frontend-Backend Production deployment và debugging Tuần 11-12: Tính năng Nâng cao \u0026amp; Tích hợp AI\nTối ưu hóa kiến trúc Multi-stack Tích hợp dịch vụ AI (Bedrock, Gemini API) Triển khai RAG pipeline Hoàn thiện dự án cuối cùng "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-ai-service/5.6.1-api-gateway/","title":"API Gateway","tags":[],"description":"","content":"Tổng Quan Tạo Amazon API Gateway làm entry point cho AI service requests.\nTạo REST API Điều hướng đến API Gateway → Create API → REST API Cài Đặt Giá Trị API name ielts-ai-api API type REST API Endpoint type Regional Tạo Resources và Methods Endpoints:\nMethod Path Description POST /writing/evaluate Submit writing sample POST /speaking/evaluate Submit audio recording POST /flashcards/generate Generate flashcard POST /upload/audio Upload audio POST /upload/document Upload document Cấu Hình SQS Integration Cho mỗi POST endpoint, cấu hình SQS integration:\nChọn method → Integration Request Integration type: AWS Service AWS Service: SQS HTTP method: POST Action: SendMessage Execution role: API Gateway role với SQS permissions Request Mapping Template:\nAction=SendMessage\u0026amp;MessageBody=$util.urlEncode($input.body)\u0026amp;QueueUrl=$util.urlEncode(\u0026#39;https://sqs.ap-southeast-1.amazonaws.com/{account}/ielts-writing-queue\u0026#39;) Enable CORS Chọn resource → Enable CORS Access-Control-Allow-Origin: * (hoặc specific domain) Access-Control-Allow-Methods: POST, GET, OPTIONS Deploy API Actions → Deploy API Stage name: prod Ghi lại invoke URL: https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod AWS CLI Commands # Tạo REST API API_ID=$(aws apigateway create-rest-api \\ --name ielts-ai-api \\ --endpoint-configuration types=REGIONAL \\ --query \u0026#39;id\u0026#39; --output text) # Lấy root resource ROOT_ID=$(aws apigateway get-resources \\ --rest-api-id $API_ID \\ --query \u0026#39;items[?path==`/`].id\u0026#39; --output text) # Tạo /ai resource AI_RESOURCE=$(aws apigateway create-resource \\ --rest-api-id $API_ID \\ --parent-id $ROOT_ID \\ --path-part ai \\ --query \u0026#39;id\u0026#39; --output text) # Tạo /ai/writing-assessment resource aws apigateway create-resource \\ --rest-api-id $API_ID \\ --parent-id $AI_RESOURCE \\ --path-part writing-assessment Bước Tiếp Theo Tiến hành đến SQS Queues.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.7-cicd-pipeline/5.7.1-create-gwe/","title":"Kết nối repo GitLab &amp; tạo dự án CodeBuild","tags":[],"description":"","content":"Mục tiêu Cấu hình hai dự án CodeBuild (frontend và backend) và trigger từ sự kiện Release của GitLab để khởi chạy CodePipeline. CodePipeline gọi CodeBuild dựa trên frontend-buildspec.yml và backend-buildspec.yml có sẵn trong repository, sau đó deploy lên ECS.\nTài nguyên AWS Dự án CodeBuild: Frontend: Source = CodePipeline; Buildspec = frontend-buildspec.yml Backend: Source = CodePipeline; Buildspec = backend-buildspec.yml CodePipeline (bước sau) nhận artifact và deploy lên ECS Tạo dự án CodeBuild \u0026amp; kết nối repository GitLab Trong phần cấu hình tạo mới CodeBuild Project, chọn Default project. Ở mục Source, chọn GitLab và repository Band-Up. Giữ nguyên cấu hình mặc định cho Environment. Chỉ định buildspec của dự án Band-Up cho frontend/backend như hình: Gửi tạo và lặp lại cho dự án CodeBuild frontend/backend còn lại. Tóm tắt Bạn đã có hai dự án CodeBuild (frontend và backend) sẵn sàng được gọi bởi CodePipeline. Sự kiện Release từ GitLab có thể kích hoạt CodePipeline, sau đó chạy mỗi dự án với frontend-buildspec.yml và backend-buildspec.yml tương ứng. Ở các bước tiếp theo, CodePipeline sẽ lấy artifact sau build và deploy lên ECS.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch “DX Talk#7: Reinventing DevSecOps with AWS Generative AI” Mục Đích Của Sự Kiện Khai thác góc nhìn chiến lược và thực tiễn về cuộc chuyển mình đầy mạnh mẽ của AI trong DevSecOps. Giới thiệu giải pháp tích hợp AI toàn diện: Từ tự động hóa quy trình đến kiểm tra bảo mật liên tục. \u0026ldquo;Mổ xẻ\u0026rdquo; các Case study từ CMC Global và AWS về cách áp dụng AI trong giải quyết các vấn đề bảo mật. Định hướng cho các DevSecOps Engineer trong thị trường đòi hỏi chuyên môn cao. Danh Sách Diễn Giả Anh Lê Thanh Đức – Cloud Delivery Manager, CMC Global Anh Dư Quốc Thành – Technical Leader, CMC Global Khách mời đặc biệt: Anh Văn Hoàng Kha – Cloud Engineer, AWS Community Builder Nội Dung Nổi Bật Giải pháp tích hợp AI toàn diện trong DevSecOps Tự động hóa quy trình, dự đoán rủi ro thông minh. Kiểm tra bảo mật liên tục trong quy trình CI/CD. Phản ứng nhanh với các mối đe dọa tiềm ẩn. Case study và Bài học thực tiễn Trực tiếp \u0026ldquo;mổ xẻ\u0026rdquo; các dự án từ CMC Global và AWS để học cách các doanh nghiệp áp dụng AI trong giải quyết các vấn đề bảo mật và vận hành hệ thống. Khám phá cách AI giúp gạt bỏ những “gatekeeper” cứng nhắc và quy trình phản hồi thủ công tốn kém. Định hướng sự nghiệp và nâng cao chuyên môn Thảo luận về việc liên tục cập nhật xu hướng và nâng cao chuyên môn là chìa khóa then chốt để kỹ sư chinh phục các dự án phức tạp. Những Gì Học Được Tích hợp AI và Tự động hóa Hiểu rõ về Giải pháp tích hợp AI toàn diện trong DevSecOps, bao gồm tự động hóa quy trình và kiểm tra bảo mật liên tục trong CI/CD. Nắm được cách AI có thể dự đoán rủi ro thông minh và tăng tốc độ phản ứng với các mối đe dọa. Tư duy DevSecOps hiện đại Nhận ra tầm quan trọng của việc tích hợp bảo mật vào SDLC (Software Development Life Cycle). Hiểu cách các công cụ phổ biến như Jenkins (CI/CD), SonarQube (SAST), OWASP ZAP (DAST), và Terraform (IaC) hoạt động. Công cụ Generative AI Khám phá Amazon Q Developer – trợ lý AI mạnh mẽ hỗ trợ code generation, testing, vulnerability scanning, và tối ưu hóa phát triển phần mềm trên AWS. Ứng Dụng Vào Công Việc (Từ Worklog Tuần 6) Áp dụng tư duy DevSecOps vào dự án hiện tại, tích hợp bảo mật ngay từ giai đoạn đầu phát triển. Nghiên cứu Amazon Q Developer để tích hợp vào workflow, hỗ trợ tạo code và kiểm tra lỗi bảo mật. Tìm hiểu các công cụ CI/CD và kiểm tra bảo mật SAST/DAST để đưa vào lộ trình phát triển dự án. Trải nghiệm trong event Workshop \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; mang đến một cái nhìn đa chiều, chiến lược và thực tiễn về tương lai của bảo mật và vận hành hệ thống Cloud:\nGóc nhìn từ chuyên gia Được lắng nghe những góc nhìn chiến lược từ các chuyên gia hàng đầu như Anh Lê Thanh Đức, Anh Dư Quốc Thành, và khách mời Anh Văn Hoàng Kha. Qua các Case Study, tôi hiểu cách các doanh nghiệp lớn áp dụng Generative AI để giải quyết các vấn đề bảo mật và vận hành phức tạp. Giá trị của AI trong DevSecOps Nhận thấy rõ khả năng của AI trong việc loại bỏ các rào cản thủ công (như gatekeeper cứng nhắc, ca trực 24/7), chuyển DevSecOps thành một quy trình tự động hóa và thông minh hơn. Sự kiện đã cung cấp giải pháp cụ thể cho việc tích hợp AI toàn diện, từ tự động hóa quy trình đến dự đoán rủi ro. Định hướng chuyên môn Nhấn mạnh tầm quan trọng của việc liên tục cập nhật xu hướng và nâng cao chuyên môn để kỹ sư DevSecOps có thể chinh phục các dự án phức tạp trong tương lai. Có cơ hội hỏi đáp trực tiếp cùng các diễn giả để giải đáp các thắc mắc về tích hợp AI vào dự án của mình. Kết luận Sự kiện là một nguồn thông tin quý giá, giúp tôi không chỉ hiểu về công nghệ mà còn về định hướng nghề nghiệp, đặc biệt là cách sử dụng các công cụ mạnh mẽ như Amazon Q Developer để tăng cường năng suất và tích hợp bảo mật vào quy trình phát triển.\nMột số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện đã thành công trong việc khai thác góc nhìn chiến lược và thực tiễn về DevSecOps với Generative AI, truyền cảm hứng và cung cấp định hướng rõ ràng cho các kỹ sư trẻ.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2 Hoàn thành Module 2, nắm vững kiến thức nền tảng về Amazon EC2 và VPC. Chuẩn bị và cấu hình các tài nguyên cần thiết để khởi tạo EC2. Tìm hiểu Amazon Route 53 và các khái niệm quản lý DNS. Tham gia sự kiện Cloud Day để học hỏi về AI và Data. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu sâu về kiến trúc VPC và các thành phần mạng.\n- Học nguyên tắc thiết kế kiến trúc AWS từ bài giảng của Mentor Gia Hung.\n- Hoàn thành AWS Skill Builder: Networking Essentials with Amazon VPC. 15/09/2025 16/09/2025 AWS VPC Documentation 3 - Tạo tài nguyên VPC để chuẩn bị cho việc triển khai EC2.\n- Khởi tạo EC2 instances từ các tài nguyên đã cấu hình.\n- Học về Security Groups và Network ACLs.\n- Hoàn thành: Compute Essentials with Amazon EC2. 16/09/2025 17/09/2025 AWS EC2 Documentation Introduction to Amazon EC2 Deploying FCJ Management Application with Auto Scaling Group 4 - Xử lý vấn đề xác thực tài khoản AWS bằng cách gửi giấy tờ xác minh.\n- Hoàn thành: Creating Your First AWS Account và Getting Help with AWS Support. 17/09/2025 20/09/2025 AWS Support\nYêu cầu Hỗ trợ từ AWS Support 5 - Tham gia sự kiện Cloud Day.\n- Thu thập kiến thức về xu hướng AI và Data.\n- Giao lưu với các mentor nổi bật trong cộng đồng AWS. 18/09/2025 18/09/2025 Cloud Day Event Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Creating Your First AWS Account Bắt đầu ✅ Managing Costs with AWS Budgets Quản lý chi phí ✅ Getting Help with AWS Support Hỗ trợ ✅ Access Management with AWS IAM Bảo mật ✅ Networking Essentials with Amazon VPC Mạng ✅ Compute Essentials with Amazon EC2 Compute ✅ Instance Profiling with IAM Roles for EC2 Bảo mật ✅ Kết quả đạt được tuần 2 Kỹ năng kỹ thuật đã tiếp thu:\nNắm vững kiến trúc VPC và các nguyên tắc cơ bản của EC2 Thành thạo quy trình chuẩn bị tài nguyên để triển khai EC2: Tạo và cấu hình Subnets để phân đoạn mạng Thiết lập Internet Gateway cho kết nối ra bên ngoài Cấu hình Route Tables để quản lý định tuyến traffic Triển khai Security Groups để kiểm soát traffic vào/ra Hiểu về IAM roles và instance profiles cho truy cập EC2 an toàn Học các chiến lược quản lý chi phí AWS sử dụng AWS Budgets Điểm nổi bật sự kiện Cloud Day:\nTham gia các phiên networking với mentors AWS và chuyên gia trong ngành Thu được kiến thức quý giá về xu hướng thị trường AI và Data Hiểu được tiềm năng tương lai và nhu cầu thị trường đối với công nghệ AI Nhận quà lưu niệm từ ban tổ chức sự kiện Bài học chính:\nVPC là nền tảng cho tất cả networking trên AWS - hiểu nó là cực kỳ quan trọng Security Groups hoạt động như tường lửa ảo ở cấp instance IAM roles loại bỏ nhu cầu hardcode credentials trong EC2 instances AWS Budgets giúp ngăn chặn chi phí không mong muốn thông qua giám sát chủ động "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"Workshop này được thiết kế dành cho Kỹ sư DevOps, Kiến trúc sư Cloud và Lập trình viên Full-stack mong muốn tìm hiểu quy trình triển khai một ứng dụng hiện đại tích hợp AI trên nền tảng AWS.\nĐể hoàn thành tốt workshop này, người tham gia cần trang bị các kiến thức, kỹ năng và công cụ sau đây.\n1. Yêu cầu về kiến thức kỹ thuật Kiến thức nền tảng AWS (AWS Fundamentals) Thao tác trên Console: Làm quen với giao diện quản trị AWS Management Console. Dịch vụ cốt lõi: Hiểu biết cơ bản về dịch vụ tính toán như Amazon EC2 và AWS Fargate, các khái niệm mạng trong Amazon VPC, và lưu trữ với Amazon S3. IAM \u0026amp; Bảo mật: Hiểu về AWS Identity and Access Management (IAM), cụ thể là vai trò (Roles), chính sách (Policies), và nguyên tắc đặc quyền tối thiểu (least privilege). Container \u0026amp; Điều phối (Containerization \u0026amp; Orchestration) Docker: Thành thạo trong việc tạo Dockerfile, build images và chạy container trên môi trường local. Cần nắm vững các khái niệm như layers, cổng kết nối (ports) và biến môi trường. Tham khảo Tài liệu Docker. Khái niệm ECS: Làm quen với các thuật ngữ của Amazon ECS bao gồm Task Definitions, Services, Clusters, và sự khác biệt giữa hai loại hình khởi chạy EC2 và Fargate. DevOps \u0026amp; CI/CD Git: Thành thạo quản lý mã nguồn (commit, push, branching) để kích hoạt các quy trình tự động hóa. Luồng CI/CD: Hiểu về nguyên lý Tích hợp liên tục (Continuous Integration) và Chuyển giao liên tục (Continuous Delivery) sử dụng các công cụ như AWS CodePipeline và AWS CodeBuild. Kiến thức cơ bản về mạng (Networking) Giao thức: Hiểu về HTTP/HTTPS, phân giải tên miền DNS với Amazon Route 53, và các khái niệm cân bằng tải sử dụng Application Load Balancer. Bảo mật mạng: Kiến thức về địa chỉ IP (CIDR blocks) và kiểm soát lưu lượng sử dụng Security Groups. 2. Thiết lập môi trường Trước khi bắt đầu workshop, hãy đảm bảo môi trường phát triển cục bộ của bạn đã được cài đặt đầy đủ các công cụ sau:\nTài khoản AWS: Một tài khoản AWS đang hoạt động với quyền Quản trị viên (Administrator access) để khởi tạo tài nguyên. IDE: Một trình soạn thảo mã nguồn như Visual Studio Code hoặc IntelliJ IDEA. Công cụ dòng lệnh (Command Line Tools): AWS CLI (v2): Đã cài đặt và cấu hình với thông tin đăng nhập của bạn. Hướng dẫn cài đặt. Git: Đã cài đặt để sao chép (clone) kho mã nguồn. Tải về. Docker Desktop: Đang chạy trên máy local để kiểm tra hoặc build images nếu cần thiết. Tải Docker. 3. Hạn mức dịch vụ \u0026amp; Chi phí Lưu ý về chi phí: Workshop này sử dụng các tài nguyên không nằm trong gói miễn phí (AWS Free Tier), bao gồm:\nNAT Gateways (Phí theo giờ + Phí xử lý dữ liệu) Application Load Balancers ECS Fargate Tasks (Tính theo vCPU/Memory sử dụng) Amazon RDS \u0026amp; ElastiCache Vui lòng đảm bảo dọn dẹp tài nguyên ngay sau khi hoàn thành workshop để tránh phát sinh chi phí không mong muốn. Hướng dẫn dọn dẹp sẽ được cung cấp ở phần cuối của tài liệu này.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-network/5.3.2-alb/","title":"Cấu hình Application Load Balancer (ALB)","tags":[],"description":"","content":"Application Load Balancer (ALB) đóng vai trò là cổng vào duy nhất cho mọi lưu lượng truy cập đến nền tảng. Nó chịu trách nhiệm phân phối yêu cầu đến các container phù hợp (Frontend hoặc Backend) và xử lý mã hóa SSL.\n1. Tạo Security Group cho ALB Trước khi tạo Load Balancer, chúng ta cần một lớp tường lửa cho phép truy cập từ Internet.\nTruy cập EC2 Dashboard \u0026gt; Security Groups \u0026gt; Create security group. Security group name: alb-sg. Description: Allow http and https traffic. VPC: Chọn band-up-vpc. Inbound rules: Thêm các quy tắc sau để cho phép truy cập từ bất kỳ đâu: Type: HTTP | Port: 80 | Source: Anywhere-IPv4 (0.0.0.0/0). Type: HTTPS | Port: 443 | Source: Anywhere-IPv4 (0.0.0.0/0). Nhấn Create security group. 2. Tạo Target Group ALB cần biết nơi để chuyển tiếp lưu lượng truy cập. Chúng ta sẽ tạo Target Group cho dịch vụ Frontend trước (Backend sẽ cấu hình sau).\nTruy cập EC2 Dashboard \u0026gt; Target groups \u0026gt; Create target group. Choose a target type: Chọn IP addresses (Bắt buộc cho ECS Fargate). Target group name: target-bandup-fe. Protocol: HTTP. Port: 3000 (Next.js frontend của chúng ta chạy trên port 3000). VPC: Chọn band-up-vpc. Nhấn Next. Register targets: Vì chúng ta chưa triển khai ECS task nào, hãy bỏ qua bước này và nhấn Create target group. 3. Khởi tạo Application Load Balancer Bây giờ, chúng ta sẽ kết hợp mọi thứ vào Load Balancer.\nBước 1: Cấu hình cơ bản (Basic Configuration)\nTruy cập Load Balancers \u0026gt; Create load balancer. Chọn Application Load Balancer và nhấn Create. Load balancer name: bandup-public-alb. Scheme: Internet-facing (Cho phép truy cập công khai). IP address type: IPv4. Bước 2: Ánh xạ mạng (Network Mapping)\nVPC: Chọn band-up-vpc. Mappings: Chọn hai Availability Zones (ap-southeast-1a và ap-southeast-1b). Subnets: QUAN TRỌNG - Phải chọn các Public Subnets (public-subnet-1 và public-subnet-2) đã tạo ở phần trước. Lưu ý: Nếu chọn nhầm Private subnets, ALB sẽ không thể nhận truy cập từ Internet. Bước 3: Security Groups \u0026amp; Listeners\nSecurity groups: Bỏ chọn default và chọn alb-sg vừa tạo. Listeners and routing: Protocol: HTTP | Port: 80. Default action: Forward to target-bandup-fe. Nhấn Create load balancer. ALB của bạn đang được khởi tạo. Sau khi chuyển sang trạng thái Active, nó sẽ sẵn sàng điều hướng lưu lượng đến ứng dụng Frontend.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-setup-be/5.5.2-rds/","title":"Tạo PostgreSQL RDS","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ khởi tạo một Amazon RDS cho PostgreSQL. Đây sẽ là nơi lưu trữ dữ liệu bền vững chính cho nền tảng IELTS BandUp. Chúng ta sẽ cấu hình nó với tính sẵn sàng cao (High Availability) và bảo mật trong VPC.\n1. Cấu hình Security Group Trước khi tạo cơ sở dữ liệu, chúng ta cần xác định các quy tắc tường lửa.\nBước 1.1: Tạo Backend Security Group Nhóm này dành cho ECS Fargate tasks (lớp ứng dụng).\nTên: ecs-backend-sg. Inbound: Cho phép cổng 8080 (Mặc định của Spring Boot) từ ALB. Bước 1.2: Tạo RDS Security Group Nhóm này được gắn vào chính database.\nTên: rds-sg. Inbound: Cho phép lưu lượng PostgreSQL (Cổng 5432) chỉ từ ecs-backend-sg vừa tạo ở trên. Điều này đảm bảo chỉ ứng dụng của chúng ta mới có thể giao tiếp với database. 2. Tạo DB Subnet Group RDS cần biết những subnet nào nó được phép sử dụng. Chúng ta sẽ gom nhóm các subnet database riêng tư lại với nhau.\nTruy cập Amazon RDS \u0026gt; Subnet groups \u0026gt; Create DB subnet group. Tên: bandup-db-subnet-group. VPC: Chọn band-up-vpc. Add subnets: Chọn các Availability Zone và chọn private-database-subnet-1 cùng private-database-subnet-2. 3. Khởi tạo Database Bây giờ, chúng ta sẽ khởi tạo instance PostgreSQL.\nTruy cập Databases \u0026gt; Create database. Phương thức tạo: Standard create. Engine options: PostgreSQL (Phiên bản 17.6 hoặc mới nhất). Availability and durability: Chọn Multi-AZ DB instance. Tùy chọn này tạo một DB chính và một bản sao đồng bộ (standby) ở một Availability Zone khác để tự động chuyển đổi khi có sự cố. Settings: DB instance identifier: bandup-db. Master username: postgres. Credential management: Self managed. Master password: Đặt mật khẩu mạnh (hãy lưu lại để dùng sau này). Instance configuration: DB instance class: Burstable classes -\u0026gt; db.t4g.micro (Tiết kiệm chi phí cho workshop). Storage: gp3 (General Purpose SSD) với dung lượng 20 GiB. Connectivity: Compute resource: Chọn Don\u0026rsquo;t connect to an EC2 compute resource. VPC: band-up-vpc. DB subnet group: bandup-db-subnet-group (Đã tạo ở bước 2). Public access: No (Rất quan trọng để bảo mật). VPC security group: Chọn existing -\u0026gt; rds-sg. Database authentication: Password authentication. Monitoring: Bật Performance Insights (lưu trữ 7 ngày). Additional configuration: Initial database name: band_up (Quan trọng: Hibernate sẽ tìm tên DB này khi khởi động). Backup: Bật sao lưu tự động. Encryption: Bật mã hóa. Nhấn Create database. Quá trình khởi tạo sẽ mất vài phút để hoàn tất. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-setup-fe/5.4.2-ecr/","title":"Thiết lập ECR &amp; IAM Role","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ chuẩn bị hạ tầng AWS cần thiết để lưu trữ các container image. Quá trình này bao gồm việc kiểm tra trạng thái ban đầu, tạo IAM Role cần thiết cho tính năng sao chép của ECR, và khởi tạo repository.\n1. Kiểm tra trạng thái ECR Đầu tiên, kiểm tra trạng thái hiện tại của Private Registry. Ban đầu, chưa có repository nào được tạo.\n2. Tạo IAM Role cho ECR Chúng ta cần tạo một Service-Linked Role cho phép Amazon ECR thực hiện các hành động sao chép (replication) qua các region hoặc tài khoản khác.\nTruy cập IAM \u0026gt; Roles \u0026gt; Create role. Select trusted entity: Chọn AWS service. Service or use case: Chọn Elastic Container Registry từ danh sách. Use case: Chọn Elastic Container Registry - Replication để cho phép ECR sao chép image. Add permissions: Xác nhận rằng chính sách ECRReplicationServiceRolePolicy đã được đính kèm. Đây là policy mặc định cấp các quyền cần thiết. Name, review, and create: Tên role được đặt tự động là AWSServiceRoleForECRReplication. Xem lại cấu hình và tạo role. Kết quả: Role đã được tạo thành công và xuất hiện trong danh sách IAM Roles. 3. Tạo ECR Repository Tiếp theo, chúng ta tạo kho lưu trữ cho image frontend.\nTruy cập Amazon ECR \u0026gt; Create repository. General settings: Repository name: band-up-frontend. Visibility settings: Private. Image tag settings: Giữ chế độ Mutable để cho phép ghi đè các image tag. Kết quả: Repository band-up-frontend đã được tạo thành công với mã hóa mặc định AES-256. 4. Cấu hình Truy cập CLI (CLI Access) Để đẩy image từ máy local lên AWS, bạn cần quyền truy cập thông qua AWS CLI. Chúng ta sẽ tạo Access Key cho IAM User của bạn.\nTruy cập IAM Dashboard \u0026gt; Users \u0026gt; Chọn user của bạn (ví dụ: NamDang). Chuyển sang tab Security credentials và nhấn Create access key. Use case: Chọn Command Line Interface (CLI). Description tag: Nhập mô tả (ví dụ: ECR Push Key) và nhấn Create access key. Lấy khóa: Quan trọng! Hãy sao chép hoặc tải về Access Key ID và Secret Access Key ngay lập tức, vì bạn sẽ không thể xem lại Secret Key sau này. 5. Cấu hình AWS CLI Mở terminal trên máy của bạn và cấu hình AWS CLI với thông tin xác thực vừa tạo.\naws configure Nhập các thông tin sau khi được hỏi:\nAWS Access Key ID: [Dán Key ID của bạn] AWS Secret Access Key: [Dán Secret Key của bạn] Default region name: ap-southeast-1 Default output format: json 6. Đẩy Image lên ECR (Push) Khi CLI đã được cấu hình, chúng ta tiến hành xác thực Docker và đẩy image lên.\nBước 1: Đăng nhập vào ECR Chạy lệnh đăng nhập để xác thực Docker client với registry của AWS.\naws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin [Account-ID]https://www.google.com/search?q=.dkr.ecr.ap-southeast-1.amazonaws.com Kết quả mong đợi: Login Succeeded\nBước 2: Gán Tag cho Image Gán tag cho image local band-up-frontend:latest với đường dẫn URI đầy đủ của ECR và phiên bản (ví dụ: v1.0.0).\ndocker tag band-up-frontend:latest [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:v1.0.0 Bước 3: Thực hiện Push Chạy lệnh push để tải các layer của image lên AWS.\ndocker push [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:v1.0.0 7. Kiểm tra kết quả cuối cùng Quay lại Amazon ECR Console và mở repository band-up-frontend. Bạn sẽ thấy image với tag v1.0.0 đã xuất hiện trong danh sách.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Hệ Thống Web Tự Học IELTS Nền Tảng Thông Minh Cho Việc Chuẩn Bị IELTS Độc Lập 1. Tóm Tắt Điều Hành Hệ Thống Web Tự Học IELTS là một nền tảng trực tuyến toàn diện được thiết kế để hỗ trợ sinh viên trong hành trình chuẩn bị IELTS độc lập. Nền tảng cung cấp giải pháp tất-trong-một bao gồm quản lý người dùng, blog giáo dục, phòng học tương tác, bài kiểm tra thực hành và hệ thống flashcard được hỗ trợ bởi AI. Tận dụng các công nghệ web hiện đại và tích hợp AI, hệ thống cung cấp trải nghiệm học tập được cá nhân hóa, tính năng cộng tác thời gian thực và công cụ đánh giá tự động để giúp sinh viên đạt được mục tiêu IELTS một cách hiệu quả.\n2. Phát Biểu Vấn Đề Vấn Đề Là Gì? Nhiều người học IELTS gặp khó khăn trong việc tìm kiếm các nền tảng tự học giá cả phải chăng, toàn diện và tương tác. Các phương pháp học truyền thống thiếu khả năng cộng tác thời gian thực, phản hồi cá nhân hóa và công cụ thực hành tích hợp. Sinh viên thường gặp khó khăn với:\nQuyền truy cập hạn chế vào tài liệu thực hành chất lượng và bài kiểm tra mô phỏng Thiếu phản hồi ngay lập tức về các bài thi Speaking và Writing Khó khăn trong việc tìm bạn học và duy trì kỷ luật học tập Tài nguyên phân mảnh trên nhiều nền tảng khác nhau Chi phí cao của các khóa học chuẩn bị IELTS truyền thống Giải Pháp Hệ Thống Web Tự Học IELTS cung cấp một nền tảng thống nhất với năm tính năng cốt lõi:\nHệ Thống Quản Lý Người Dùng: Thành viên nhiều cấp (Khách, Thành viên, Premium, Quản trị viên) với xác thực mạng xã hội (Google, Facebook), hồ sơ cá nhân và khả năng nhắn tin.\nNền Tảng Blog Giáo Dục: Nội dung do cộng đồng tạo ra với các thao tác CRUD, phân loại theo thể loại/thẻ, lọc nâng cao, bình luận, báo cáo và tính năng yêu thích.\nPhòng Học Tương Tác: Không gian học ảo với lên lịch, cuộc gọi thoại/video, bộ đếm thời gian Pomodoro, nhạc nền, tích hợp từ điển và hỗ trợ dịch thuật để nâng cao việc học.\nBài Kiểm Tra Thực Hành IELTS: Các bài kiểm tra mô phỏng toàn diện cho Reading và Listening với tính năng tự động trích xuất từ vựng vào flashcard, cộng với đánh giá được hỗ trợ bởi AI cho các bài Speaking và Writing, và bài tập chính tả.\nHệ Thống Flashcard Quizlet: Tạo flashcard thông minh với nhiều chế độ học, tự động trích xuất từ vựng từ văn bản, tạo bài quiz bằng AI từ tài liệu được tải lên và khả năng chia sẻ.\nLợi Ích và Lợi Tức Đầu Tư Cho Sinh Viên: Thay thế tiết kiệm chi phí cho các khóa học đắt đỏ, lộ trình học tập cá nhân hóa, truy cập tài liệu học 24/7, phản hồi được hỗ trợ bởi AI và môi trường học tập hợp tác. Giá Trị Giáo Dục: Phát triển kỷ luật tự giác, cung cấp chuẩn bị IELTS toàn diện, cho phép học tập ngang hàng và cung cấp tiến độ có thể theo dõi. Lợi Ích Kỹ Thuật: Kiến trúc có thể mở rộng, công nghệ hiện đại, tích hợp AI cho đánh giá tự động và tiềm năng mở rộng tính năng trong tương lai. Tiềm Năng Thị Trường: Nhu cầu ngày càng tăng về chuẩn bị IELTS trực tuyến, mô hình doanh thu dựa trên đăng ký (Khách → Thành viên → Premium) và tiềm năng hợp tác với các tổ chức giáo dục. 3. Kiến Trúc Giải Pháp Nền tảng sử dụng kiến trúc web full-stack hiện đại được thiết kế để có khả năng mở rộng, cộng tác thời gian thực và tích hợp AI. Hệ thống bao gồm năm module chính hoạt động cùng nhau để cung cấp trải nghiệm học IELTS toàn diện. Hạ tầng sử dụng triển khai active-passive Multi-AZ trên AWS ECS để đảm bảo tính sẵn sàng cao, trong đó AZ-1 xử lý toàn bộ lưu lượng hoạt động và AZ-2 đóng vai trò dự phòng để chuyển đổi dự phòng tự động.\nTổng Quan Kiến Trúc Hệ Thống: Công Nghệ Sử Dụng Frontend:\nNext.js 14+: Framework React hiện đại cho ứng dụng web đáp ứng TypeScript: Phát triển an toàn kiểu dữ liệu TailwindCSS: Styling tiện ích ưu tiên WebRTC: Giao tiếp video/thoại thời gian thực Socket.io Client: Nhắn tin và cộng tác thời gian thực Backend:\nSpring Boot 3.x: Kiến trúc API RESTful nguyên khối Java 17+: Ngôn ngữ lập trình backend Spring Security: Xác thực và phân quyền Spring WebSocket: Giao tiếp thời gian thực JWT: Xác thực dựa trên token an toàn OAuth 2.0: Tích hợp đăng nhập mạng xã hội (Google, Facebook) Cơ Sở Dữ Liệu:\nPostgreSQL 14+: Cơ sở dữ liệu quan hệ chính cho tất cả dữ liệu (người dùng, bài kiểm tra, blog, flashcard, phiên học) Amazon ElastiCache (Redis): Bộ nhớ đệm và quản lý phiên Hạ Tầng Đám Mây (AWS):\nAmazon ECS (Elastic Container Service): Điều phối container với triển khai active-passive Multi-AZ Application Load Balancer: Định tuyến lưu lượng đến AZ hoạt động với chuyển đổi dự phòng tự động Amazon RDS for PostgreSQL: Triển khai Multi-AZ (primary hoạt động ở AZ-1, standby thụ động ở AZ-2) Amazon S3: Lưu trữ tệp và phương tiện Amazon CloudFront: CDN cho tài nguyên tĩnh Amazon CloudWatch: Giám sát và ghi log Dịch Vụ Bên Thứ Ba:\nGoogle Gemini Flash API (Free Tier): Đánh giá Speaking/Writing được hỗ trợ bởi AI và tạo nội dung API Từ Điển Miễn Phí: Định nghĩa và ví dụ từ Thư viện dịch mã nguồn mở: Dịch thuật nhận biết ngữ cảnh (thay thế cho API trả phí) Thiết Kế Thành Phần 1. Module Quản Lý Người Dùng:\nHệ thống xác thực nhiều cấp (Khách, Thành viên, Premium, Quản trị viên) Tích hợp OAuth mạng xã hội (Google, Facebook) Quản lý hồ sơ người dùng với thống kê học tập Hệ thống nhắn tin thời gian thực Khôi phục mật khẩu và xác minh email 2. Module Nền Tảng Blog:\nCác thao tác CRUD cho bài đăng blog Hệ thống quản lý thể loại và thẻ Tìm kiếm và lọc nâng cao (theo thẻ, thể loại, ngày, mức độ phổ biến) Hệ thống bình luận với phản hồi lồng nhau Báo cáo và kiểm duyệt nội dung Tính năng yêu thích/đánh dấu Phân phối nội dung được tối ưu hóa SEO 3. Module Phòng Học:\nTạo và quản lý phòng học ảo Lên lịch phiên học với tích hợp lịch Cuộc gọi thoại và video dựa trên WebRTC Bộ đếm thời gian Pomodoro với khoảng thời gian tùy chỉnh Thư viện nhạc nền với danh sách phát tập trung Từ điển tích hợp với API từ điển miễn phí Hỗ trợ dịch thuật sử dụng thư viện mã nguồn mở Chia sẻ màn hình cho học tập cộng tác Quản lý người tham gia thời gian thực 4. Module Bài Kiểm Tra Thực Hành IELTS:\nQuản lý ngân hàng bài kiểm tra (Reading, Listening, Speaking, Writing) Mô phỏng bài kiểm tra có giới hạn thời gian với tự động nộp bài Tự động trích xuất từ vựng từ đoạn văn Reading vào flashcard Đánh giá Speaking được hỗ trợ bởi AI sử dụng Gemini Flash (phát âm, độ trôi chảy, mạch lạc) Đánh giá Writing được hỗ trợ bởi AI sử dụng Gemini Flash (ngữ pháp, từ vựng, hoàn thành nhiệm vụ) Bài tập chính tả cho thực hành Listening Báo cáo điểm chi tiết và phân tích Theo dõi tiến độ qua các loại bài kiểm tra 5. Module Flashcard Quizlet:\nCác thao tác CRUD cho bộ flashcard Nhiều chế độ học (flashcard, học, kiểm tra, ghép cặp, viết) Thuật toán lặp lại ngắt quãng (SRS) Tự động trích xuất từ vựng từ đoạn văn bản Tạo bài quiz bằng AI từ tài liệu/văn bản được tải lên sử dụng Gemini Flash Bộ flashcard cộng tác với khả năng chia sẻ Thống kê học tập và theo dõi mức độ thành thạo Chức năng nhập/xuất 4. Triển Khai Kỹ Thuật Các Giai Đoạn Triển Khai\nGiai Đoạn 1: Lập Kế Hoạch và Thiết Kế (Tuần 1-2)\nThu thập yêu cầu và định nghĩa user story Thiết kế kiến trúc hệ thống và lập kế hoạch hạ tầng AWS Thiết kế schema cơ sở dữ liệu cho PostgreSQL Wireframe và mockup UI/UX Thiết kế endpoint API cho Spring Boot Đánh giá và lập kế hoạch tích hợp dịch vụ bên thứ ba Thiết lập kiến trúc Multi-AZ trên AWS ECS Giai Đoạn 2: Phát Triển Cốt Lõi (Tuần 3-6)\nThiết lập ứng dụng Spring Boot với kiến trúc nguyên khối Xác thực và phân quyền người dùng với Spring Security Thiết lập cơ sở dữ liệu PostgreSQL trên Amazon RDS (Multi-AZ: active-passive) Tích hợp JWT và OAuth 2.0 (Google, Facebook) Thiết lập frontend Next.js với TypeScript Tạo thư viện component frontend Các thao tác CRUD cơ bản cho tất cả module Cấu hình AWS ECS cluster với chuyển đổi dự phòng active-passive Giai Đoạn 3: Phát Triển Tính Năng (Tuần 7-10)\nNền tảng blog với lọc và tìm kiếm nâng cao Tạo phòng học với tích hợp WebRTC Module bài kiểm tra thực hành với logic chấm điểm tự động Hệ thống flashcard với thuật toán lặp lại ngắt quãng Nhắn tin thời gian thực với Spring WebSocket Tích hợp API từ điển và Google Translate Tích hợp Amazon S3 cho tải tệp lên ElastiCache Redis cho quản lý phiên và bộ nhớ đệm Giai Đoạn 4: Tích Hợp AI \u0026amp; Triển Khai (Tuần 11-12)\nTích hợp Google Gemini Flash API cho đánh giá Speaking Tích hợp Google Gemini Flash API cho đánh giá Writing Thuật toán trích xuất từ vựng tự động Tạo bài quiz bằng AI từ nội dung được tải lên Kiểm thử toàn diện (đơn vị, tích hợp, end-to-end) Tối ưu hóa hiệu suất và kiểm tra tải Kiểm tra bảo mật và sửa lỗi Triển khai production lên AWS ECS với Multi-AZ Thiết lập giám sát với CloudWatch Yêu Cầu Kỹ Thuật\nMôi Trường Phát Triển:\nJava 17+ cho backend Spring Boot Node.js 18+ cho frontend Next.js PostgreSQL 14+ cho cơ sở dữ liệu Docker cho containerization cục bộ Git cho quản lý phiên bản Maven cho quản lý dependency Java Yêu Cầu Frontend:\nNext.js 14+ với App Router và TypeScript WebRTC cho giao tiếp video/thoại thời gian thực Socket.io client cho tính năng thời gian thực Xác thực biểu mẫu (React Hook Form + Zod) Yêu Cầu Backend:\nSpring Boot 3.x với Java 17+ Spring Data JPA cho các thao tác cơ sở dữ liệu Spring Security cho xác thực/phân quyền Spring WebSocket cho tính năng thời gian thực Spring Web cho API RESTful JWT cho xác thực dựa trên token OAuth 2.0 cho đăng nhập mạng xã hội Xử lý tải tệp lên multipart Hạ Tầng AWS:\nAmazon ECS: Loại khởi chạy Fargate cho ứng dụng container Application Load Balancer: Định tuyến lưu lượng đến AZ hoạt động với kiểm tra sức khỏe Amazon RDS PostgreSQL: Triển khai Multi-AZ active-passive cho tính sẵn sàng cao Amazon ElastiCache (Redis): Quản lý phiên và bộ nhớ đệm Amazon S3: Lưu trữ tệp phương tiện Amazon CloudFront: CDN cho tài nguyên tĩnh Amazon CloudWatch: Ghi log và giám sát Amazon VPC: Cô lập mạng với subnet công khai/riêng tư qua 2 AZ AWS Certificate Manager: Chứng chỉ SSL/TLS Tích Hợp AI/ML:\nGoogle Gemini Flash API (Free Tier) cho đánh giá Speaking/Writing 5. Lộ Trình \u0026amp; Mốc Triển Khai Lộ Trình Dự Án: 3 Tháng (12 Tuần)\nTuần 1-2: Lập Kế Hoạch \u0026amp; Thiết Kế\n✓ Phân tích và lập tài liệu yêu cầu ✓ Thiết kế kiến trúc AWS Multi-AZ ✓ Thiết kế schema cơ sở dữ liệu PostgreSQL ✓ Hoàn thành mockup UI/UX ✓ Thiết lập cấu trúc dự án Spring Boot Kết quả: Tài liệu đặc tả kỹ thuật hoàn chỉnh và kế hoạch hạ tầng AWS Tuần 3-6: Phát Triển Cốt Lõi\n✓ Thiết lập backend nguyên khối Spring Boot ✓ Triển khai Spring Security (JWT, OAuth 2.0) ✓ Quản lý người dùng và kiểm soát truy cập dựa trên vai trò ✓ Triển khai Amazon RDS PostgreSQL Multi-AZ ✓ Framework frontend Next.js và thư viện component ✓ Thiết lập AWS ECS cluster với Application Load Balancer ✓ Cấu hình ElastiCache Redis Kết quả: Hệ thống xác thực hoạt động và hạ tầng AWS Tuần 7-10: Phát Triển Tính Năng\n✓ Nền tảng blog với chức năng CRUD đầy đủ ✓ Tạo và quản lý phòng học ✓ Tích hợp WebRTC cho cuộc gọi video/thoại Module bài kiểm tra thực hành (Reading \u0026amp; Listening) Hệ thống flashcard với các chế độ học Tích hợp Amazon S3 cho lưu trữ phương tiện Tích hợp API từ điển miễn phí và thư viện dịch mã nguồn mở Spring WebSocket cho tính năng thời gian thực Kết quả: Tất cả năm tính năng cốt lõi hoạt động (không có AI) Tuần 11-12: Tích Hợp AI \u0026amp; Triển Khai\n✓ Tích hợp Google Gemini Flash API (Free Tier) cho đánh giá Writing ✓ Tích hợp Google Gemini Flash API (Free Tier) cho đánh giá Speaking ✓ Thuật toán trích xuất từ vựng ✓ Chức năng tạo bài quiz bằng AI ✓ Kiểm thử toàn diện (đơn vị, tích hợp, E2E) ✓ Tối ưu hóa hiệu suất và kiểm tra bảo mật ✓ Triển khai production lên AWS ECS Multi-AZ ✓ Thiết lập giám sát và cảnh báo CloudWatch ✓ Sửa lỗi cuối cùng và lập tài liệu Kết quả: Ứng dụng sẵn sàng production được triển khai trên AWS Các Mốc Quan Trọng:\nTuần 2: Đặc tả kỹ thuật và kiến trúc AWS được phê duyệt Tuần 6: Backend cốt lõi và hạ tầng được triển khai Tuần 10: Tất cả tính năng hoàn thành (phiên bản beta) Tuần 12: Ra mắt production với tích hợp AI Mục Tiêu Sprint Hàng Tuần:\nSprint 1-2: Kiến trúc và thiết lập Sprint 3-4: Xác thực và cơ sở dữ liệu Sprint 5-6: API cốt lõi và triển khai AWS Sprint 7-8: Tính năng blog và phòng học Sprint 9-10: Bài kiểm tra thực hành và flashcard Sprint 11: Tích hợp AI và kiểm thử Sprint 12: Triển khai production và ra mắt 6. Ước Tính Ngân Sách Chi Phí Phát Triển (Một lần)\nPhần Mềm \u0026amp; Công Cụ:\nCông cụ và giấy phép phát triển: $0 (sử dụng công cụ miễn phí/mã nguồn mở) Công cụ thiết kế (Figma Free): $0 Công cụ quản lý dự án: $0 (sử dụng gói miễn phí) Tổng Phần Mềm: $0 Thiết Lập Ban Đầu:\nĐăng ký tên miền: $1/năm Chứng chỉ SSL: $0 (AWS Certificate Manager - Miễn phí) Máy chủ phát triển: $0 (phát triển cục bộ) Tổng Thiết Lập Ban Đầu: $1 Chi Phí Vận Hành (Hàng Tháng)\nHạ Tầng \u0026amp; Hosting (AWS):\nHạ Tầng AWS \u0026amp; Hosting Dịch Vụ Bên Thứ Ba:\nGoogle Gemini Flash API: Gói miễn phí Tổng Phụ Dịch Vụ: $0/tháng Chi Phí Vận Hành Khác:\nGiám sát \u0026amp; phân tích: $10/tháng (tích hợp với CloudWatch) Lưu trữ sao lưu (RDS automated backups): $5/tháng Gia hạn tên miền \u0026amp; SSL: $0.08/tháng (phân bổ từ $1/năm, SSL qua AWS Certificate Manager - Miễn phí) Tổng Phụ Khác: $15.08/tháng Tổng Chi Phí Vận Hành Hàng Tháng: $103.66/tháng\nTóm Tắt Ngân Sách Hàng Năm\nGiai Đoạn Phát Triển (3 Tháng):\nChi phí phát triển: $1 (một lần, chỉ tên miền) Chi phí vận hành (3 tháng): $310.98 ($103.66 × 3 tháng) Tổng Giai Đoạn Phát Triển: $311.98 Năm 1 (Sau Ra Mắt):\nChi phí phát triển: $1 (một lần, chỉ tên miền) Chi phí vận hành: $1,243.92 ($103.66 × 12 tháng) Tổng Năm 1: $1,244.92 Năm 2+ (Định Kỳ Hàng Năm):\nChi phí vận hành: $1,243.92/năm Gia hạn tên miền: $1/năm Tổng Hàng Năm: $2,845.96 Dự Báo Doanh Thu (Mô Hình Đăng Ký)\nCác Cấp Thành Viên:\nKhách: Miễn phí (tính năng hạn chế) Thành viên: $5/tháng (tính năng cơ bản) Premium: $15/tháng (tất cả tính năng + đánh giá AI) Ước Tính Doanh Thu Thận Trọng (Năm 1):\nTháng 6-12: Trung bình 100 Premium + 200 Thành viên Doanh thu: (100 × $15 + 200 × $5) × 7 tháng = $17,500 Chi phí vận hành (Năm 1): $1,243.92 Lợi Nhuận Ròng Năm 1: $16,256.08 Hòa vốn: Tháng 1 sau khi ra mắt Ước Tính Doanh Thu Lạc Quan (Năm 2):\n500 Premium + 1,000 Thành viên Doanh thu hàng tháng: $12,500 Doanh thu hàng năm: $150,000 Chi phí vận hành: $1,243.92 Lợi Nhuận Ròng Năm 2: $147,154.04 Tỷ suất lợi nhuận: ~98% sau chi phí vận hành Chiến Lược Tối Ưu Chi Phí:\nChi phí nhân sự bằng không (dự án tự phát triển) Triển khai Multi-AZ active-passive giảm chi phí (tài nguyên dự phòng chỉ sử dụng khi chuyển đổi dự phòng) Sử dụng AWS ECS Fargate Spot cho môi trường phát triển (tiết kiệm 70% chi phí) Triển khai bộ nhớ đệm với ElastiCache để giảm truy vấn cơ sở dữ liệu Sử dụng CloudFront CDN để giảm thiểu chi phí truyền dữ liệu Tận dụng gói miễn phí của Google Gemini Flash API cho tính năng AI Sử dụng API từ điển miễn phí và thư viện dịch mã nguồn mở Công cụ phát triển và phần mềm thiết kế miễn phí (VS Code, Figma Free, v.v.) Tận dụng AWS Free Tier trong giai đoạn phát triển ban đầu RDS automated backups được bao gồm (lưu trữ 7 ngày) Sử dụng AWS Certificate Manager cho chứng chỉ SSL miễn phí Triển khai chính sách lifecycle S3 để chuyển dữ liệu cũ sang tầng lưu trữ rẻ hơn Không có chi phí dịch vụ email bằng cách hoãn tính năng email cho giai đoạn sau Task ECS dự phòng ở AZ-2 được giữ ở mức tối thiểu cho đến khi cần chuyển đổi dự phòng 7. Đánh Giá Rủi Ro Ma Trận Rủi Ro Rủi Ro Ưu Tiên Cao:\nVượt Chi Phí API AI\nẢnh hưởng: Thấp | Xác suất: Thấp Mô tả: Gói miễn phí Google Gemini Flash API có giới hạn sử dụng có thể bị vượt quá Giảm thiểu: Triển khai hạn ngạch sử dụng và giới hạn tốc độ; giám sát việc sử dụng API qua bảng điều khiển Dự phòng: Nâng cấp lên gói trả phí nếu giới hạn miễn phí bị vượt quá liên tục, hoặc triển khai hệ thống xếp hàng Vi Phạm Bảo Mật \u0026amp; Quyền Riêng Tư Dữ Liệu\nẢnh hưởng: Nghiêm trọng | Xác suất: Thấp Mô tả: Lộ dữ liệu người dùng hoặc truy cập trái phép Giảm thiểu: Triển khai mã hóa, kiểm tra bảo mật định kỳ, tuân thủ GDPR Dự phòng: Kế hoạch ứng phó sự cố, bảo hiểm, tư vấn pháp lý Vấn Đề Khả Năng Mở Rộng\nẢnh hưởng: Cao | Xác suất: Trung bình Mô tả: Hiệu suất hệ thống suy giảm khi người dùng tăng Giảm thiểu: AWS ECS Auto Scaling ở AZ hoạt động, RDS Multi-AZ active-passive cho tính sẵn sàng cao, ElastiCache cho hiệu suất Dự phòng: Mở rộng task ECS ở AZ hoạt động, kích hoạt thêm task ở AZ thụ động nếu cần, nâng cấp class instance RDS Rủi Ro Ưu Tiên Trung Bình:\nNgừng Hoạt Động Dịch Vụ Bên Thứ Ba\nẢnh hưởng: Trung bình | Xác suất: Thấp Mô tả: Phụ thuộc vào API bên ngoài (gói miễn phí Gemini Flash, API từ điển miễn phí) Giảm thiểu: Suy giảm nhẹ nhàng, thông báo người dùng khi tính năng AI không khả dụng Dự phòng: Phản hồi được lưu trong bộ nhớ đệm cho tra cứu từ điển, tùy chọn chấm điểm thủ công cho bài kiểm tra khi gặp sự cố Thách Thức Thu Hút Người Dùng\nẢnh hưởng: Cao | Xác suất: Trung bình Mô tả: Khó khăn trong việc thu hút và giữ chân người dùng Giảm thiểu: Chiến lược marketing, tối ưu hóa SEO, chương trình giới thiệu Dự phòng: Điều chỉnh tính năng dựa trên phản hồi, hợp tác với trường học Vấn Đề Kiểm Duyệt Nội Dung\nẢnh hưởng: Trung bình | Xác suất: Cao Mô tả: Nội dung không phù hợp trong blog, bình luận hoặc phòng học Giảm thiểu: Lọc nội dung tự động, hệ thống báo cáo, đội ngũ kiểm duyệt Dự phòng: Hướng dẫn cộng đồng, cấm người dùng, tuyên bố miễn trừ pháp lý Rủi Ro Ưu Tiên Thấp:\nCông Nghệ Lỗi Thời\nẢnh hưởng: Thấp | Xác suất: Trung bình Mô tả: Các công nghệ được chọn trở nên lỗi thời Giảm thiểu: Cập nhật dependency định kỳ, kiến trúc module hóa Dự phòng: Kế hoạch di chuyển dần dần, ngân sách tái cấu trúc Cạnh Tranh Từ Các Nền Tảng Đã Thành Lập\nẢnh hưởng: Trung bình | Xác suất: Cao Mô tả: Cạnh tranh với Duolingo, IELTS.org, v.v. Giảm thiểu: Tính năng độc đáo (phòng học, đánh giá AI), nhắm mục tiêu thị trường ngách Dự phòng: Chiến lược khác biệt hóa, đổi mới tính năng Chiến Lược Giảm Thiểu Giảm Thiểu Kỹ Thuật:\nTriển khai xử lý lỗi toàn diện và ghi log với CloudWatch Thiết lập cảnh báo CloudWatch cho việc sử dụng tài nguyên và lỗi Sao lưu tự động định kỳ với RDS Multi-AZ và khôi phục theo thời điểm Sử dụng CloudFront CDN cho tài nguyên tĩnh để giảm tải ECS Triển khai giới hạn tốc độ API để ngăn chặn lạm dụng Đánh giá mã và kiểm thử tự động trong pipeline CI/CD (AWS CodePipeline/GitHub Actions) AWS WAF cho bảo mật ứng dụng và bảo vệ DDoS Giảm Thiểu Kinh Doanh:\nBắt đầu với mô hình freemium để xây dựng cơ sở người dùng Giai đoạn thử nghiệm beta để xác định vấn đề nghiêm trọng Triển khai tính năng dần dần để quản lý chi phí Xây dựng cộng đồng qua mạng xã hội và marketing nội dung Thiết lập quan hệ đối tác với giáo viên và tổ chức IELTS Giảm Thiểu Pháp Lý \u0026amp; Tuân Thủ:\nĐiều khoản dịch vụ và Chính sách quyền riêng tư Tuân thủ GDPR và bảo vệ dữ liệu Thỏa thuận cấp phép nội dung Sự đồng ý của người dùng cho xử lý dữ liệu Kiểm tra tuân thủ định kỳ Kế Hoạch Dự Phòng Lỗi Kỹ Thuật:\nLỗi cơ sở dữ liệu: Chuyển đổi dự phòng tự động sang instance standby RDS Multi-AZ ở AZ-2 (thụ động) Lỗi task ECS ở AZ-1: Auto Scaling thay thế task không khỏe mạnh; lỗi nghiêm trọng kích hoạt AZ-2 Ngừng hoạt động API: Phục vụ nội dung được lưu trong bộ nhớ đệm từ ElastiCache và xếp hàng yêu cầu Vi phạm bảo mật: Cảnh báo ngay lập tức từ AWS Security Hub, khóa và điều tra Multi-AZ active-passive đảm bảo tính sẵn sàng cao với chuyển đổi dự phòng tự động sang AZ-2 thụ động Lỗi Kinh Doanh:\nTỷ lệ chấp nhận người dùng thấp: Chuyển sang mô hình B2B (trường học, gia sư) Tỷ lệ rời bỏ cao: Phỏng vấn người dùng, cải thiện tính năng Thiếu hụt doanh thu: Tối ưu hóa chi phí, tìm kiếm đầu tư Vấn Đề Pháp Lý:\nKhiếu nại bản quyền: Quy trình gỡ bỏ nội dung Khiếu nại quyền riêng tư: Xóa dữ liệu và đánh giá tuân thủ Vi phạm điều khoản: Tạm ngừng người dùng và điều tra 8. Kết Quả Kỳ Vọng Cải Tiến Kỹ Thuật Khả Năng Nền Tảng:\nỨng dụng web hoạt động đầy đủ với 5 module tích hợp Tính năng cộng tác thời gian thực (cuộc gọi video/thoại, nhắn tin) Đánh giá được hỗ trợ bởi AI cho Speaking và Writing sử dụng Google Gemini Flash Kiến trúc Multi-AZ có thể mở rộng trên AWS ECS hỗ trợ 10,000+ người dùng đồng thời Thiết kế đáp ứng trên mobile để học mọi lúc mọi nơi API RESTful mạnh mẽ được xây dựng với Spring Boot nguyên khối Tính sẵn sàng cao với thời gian hoạt động 99.9% thông qua triển khai Multi-AZ active-passive Thành Tựu Kỹ Thuật:\nPhát triển web full-stack hiện đại với Next.js và Spring Boot Triển khai giao tiếp thời gian thực (WebRTC, Spring WebSocket) Tích hợp AI/ML Google Gemini Flash và quản lý API Hạ tầng đám mây AWS và triển khai kiến trúc Multi-AZ active-passive Thiết kế và tối ưu hóa cơ sở dữ liệu PostgreSQL Điều phối container với Amazon ECS Fargate Thực hành bảo mật tốt nhất với Spring Security và dịch vụ AWS Thực hành DevOps với giám sát CloudWatch và triển khai tự động Tác Động Giáo Dục Cho Sinh Viên:\nNền tảng chuẩn bị IELTS dễ tiếp cận, giá cả phải chăng Lộ trình học tập cá nhân hóa và theo dõi tiến độ Phản hồi ngay lập tức về bài kiểm tra thực hành Môi trường học tập do cộng đồng thúc đẩy Truy cập tài liệu học tập và bài kiểm tra thực hành 24/7 Ước tính giảm 30-40% chi phí so với các khóa học truyền thống Kết Quả Học Tập:\nCải thiện điểm IELTS thông qua thực hành nhất quán Quản lý thời gian tốt hơn với tích hợp Pomodoro Nâng cao từ vựng thông qua hệ thống flashcard Tự tin Speaking thông qua phản hồi AI Cải thiện kỹ năng Writing với phân tích chi tiết Giá Trị Kinh Doanh Vị Thế Thị Trường:\nGiải pháp thay thế cạnh tranh cho các khóa học chuẩn bị IELTS đắt đỏ Kết hợp độc đáo các tính năng (phòng học + AI + cộng đồng) Mô hình kinh doanh SaaS có thể mở rộng Tiềm năng cho thị trường B2C và B2B (trường học, trung tâm gia sư) Mục Tiêu Tăng Trưởng Người Dùng:\nTuần 12 (Ra mắt): 100 người dùng đăng ký (người thử nghiệm beta) Tháng 6: 500 người dùng đăng ký Tháng 12: 2,000 người dùng đăng ký Năm 2: 10,000 người dùng đăng ký Tỷ lệ chuyển đổi Premium: 10-15% Tiềm Năng Doanh Thu:\nNăm 1: $17,500 (sau khi ra mắt vào Tháng 6) Năm 2: $150,000+ (với 500 premium, 1,000 thành viên thường) Năm 3: $500,000+ (với mở rộng thị trường và quan hệ đối tác) Giá Trị Dài Hạn Phát Triển Nền Tảng:\nNền tảng cho các module học ngôn ngữ khác (TOEFL, SAT, v.v.) Thu thập dữ liệu để cải thiện mô hình AI Thư viện nội dung do cộng đồng tạo ra Tiềm năng cho hệ thống gamification và thành tích Phát triển ứng dụng mobile dựa trên thành công của nền tảng web Tác Động Xã Hội:\nDân chủ hóa việc chuẩn bị IELTS cho sinh viên trên toàn thế giới Giảm rào cản học ngôn ngữ Xây dựng cộng đồng học tập hỗ trợ Cho phép chia sẻ kiến thức ngang hàng Tạo cơ hội cho những người sáng tạo nội dung giáo dục Lợi Ích Portfolio \u0026amp; Nghề Nghiệp:\nDự án full-stack toàn diện với Spring Boot và Next.js cho portfolio của nhà phát triển Kinh nghiệm thực tế với dịch vụ đám mây AWS (ECS, RDS, S3, CloudFront, v.v.) Kinh nghiệm kiến trúc Multi-AZ active-passive và thiết kế hệ thống có tính sẵn sàng cao Kinh nghiệm tích hợp AI với Google Gemini Flash Hiểu biết về công nghệ giáo dục (EdTech) Điều phối container và chiến lược chuyển đổi dự phòng Cơ hội khởi nghiệp tiềm năng hoặc mục tiêu mua lại Chỉ Số Thành Công:\nMức độ tương tác người dùng: Trung bình 3+ phiên mỗi tuần Tỷ lệ hoàn thành bài kiểm tra: 70%+ bài kiểm tra đã bắt đầu Giữ chân người dùng: 60%+ người dùng hoạt động hàng tháng Điểm NPS: 50+ (cho thấy sự hài lòng mạnh mẽ của người dùng) Cải thiện điểm IELTS trung bình: Tăng 0.5-1.0 band Bản kế hoạch dự án "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-ai-service/5.6.2-sqs-queues/","title":"SQS Queues","tags":[],"description":"","content":"Tổng Quan Tạo Amazon SQS queues cho asynchronous AI processing với Dead Letter Queues cho failed messages.\nTạo Writing Assessment Queue Setting Value Name ielts-ai-dev-writing-evaluation Type Standard Visibility timeout 5 minutes Message retention 14 days Dead-letter queue ielts-ai-dev-writing-evaluation-dlq Max receives 3 Create Speaking Assessment Queue Setting Value Name ielts-ai-dev-speaking-evaluation Visibility timeout 15 minutes Dead-letter queue ielts-ai-dev-speaking-evaluation-dlq Create Flashcard Generation Queue Setting Value Name ielts-ai-dev-flashcard-generation Visibility timeout 15 minutes Dead-letter queue ielts-ai-dev-flashcard-generation-dlq AWS CLI Commands # Tạo Dead Letter Queue aws sqs create-queue --queue-name ielts-writing-dlq # Tạo main queue với DLQ aws sqs create-queue \\ --queue-name ielts-writing-queue \\ --attributes \u0026#39;{ \u0026#34;VisibilityTimeout\u0026#34;: \u0026#34;300\u0026#34;, \u0026#34;MessageRetentionPeriod\u0026#34;: \u0026#34;1209600\u0026#34;, \u0026#34;RedrivePolicy\u0026#34;: \u0026#34;{\\\u0026#34;deadLetterTargetArn\\\u0026#34;:\\\u0026#34;arn:aws:sqs:ap-southeast-1:{account}:ielts-writing-dlq\\\u0026#34;,\\\u0026#34;maxReceiveCount\\\u0026#34;:\\\u0026#34;3\\\u0026#34;}\u0026#34; }\u0026#39; # Lặp lại cho speaking và flashcard queues aws sqs create-queue --queue-name ielts-speaking-dlq aws sqs create-queue --queue-name ielts-speaking-queue \\ --attributes \u0026#39;{\u0026#34;VisibilityTimeout\u0026#34;: \u0026#34;900\u0026#34;}\u0026#39; aws sqs create-queue --queue-name ielts-flashcard-dlq aws sqs create-queue --queue-name ielts-flashcard-queue \\ --attributes \u0026#39;{\u0026#34;VisibilityTimeout\u0026#34;: \u0026#34;900\u0026#34;}\u0026#39; Tóm Tắt Queue Queue Visibility Timeout DLQ Max Receives ielts-writing-queue 5 min ielts-writing-dlq 3 ielts-speaking-queue 15 min ielts-speaking-dlq 3 ielts-flashcard-queue 15 min ielts-flashcard-dlq 3 Bước Tiếp Theo Tiến hành đến Lambda Functions.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.7-cicd-pipeline/5.7.2-test-gwe/","title":"Tạo CodePipeline với trigger theo tag GitLab","tags":[],"description":"","content":"Thiết kế CodePipeline (Source → Build → Deploy) Build (CodeBuild) Project: dự án CodeBuild của dự án này (Source = CodePipeline) Environment variables: theo nhu cầu build của dự án Buildspec: dùng buildspec.yml có sẵn trong repository Hướng dẫn tạo CodePipeline Ở phần chọn tùy chọn tạo pipeline, chọn Build custom pipeline. Trong tab pipeline settings, đặt tên pipeline và dùng các thiết lập mặc định. Bật webhook events và thêm bộ lọc theo tag. Đặt mẫu tag là \u0026ldquo;v*\u0026rdquo;. Thêm dự án frontend/backend bằng AWS CodeBuild ở bước Build. Ở bước Deploy, chọn Amazon ECS làm nhà cung cấp triển khai. Chỉ định cluster và service để deploy. Điền file image definition như minh họa. Gửi tạo và hoàn tất, pipeline sẽ được tạo. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Bài thu hoạch: AWS Cloud Mastery Series #1 — AI/ML/GenAI on AWS Mục đích của sự kiện Cung cấp cái nhìn tổng quan về bối cảnh AI/ML tại Việt Nam. Giới thiệu chi tiết các dịch vụ AI/ML quan trọng của AWS, đặc biệt là Amazon SageMaker. Đi sâu vào Generative AI thông qua Amazon Bedrock, bao gồm các Foundation Models và các kỹ thuật triển khai hiện đại (RAG, Prompt Engineering). Nội dung nổi bật Sáng: AWS AI/ML Services Overview Giới thiệu: tổng quan về bối cảnh AI/ML tại Việt Nam và mục tiêu của workshop. Amazon SageMaker: nền tảng ML end-to-end của AWS. Quy trình ML: chuẩn bị dữ liệu (Data Preparation), gắn nhãn (Labeling), huấn luyện (Training), tinh chỉnh (Tuning), và triển khai mô hình (Deployment). Tích hợp MLOps. Live demo: walkthrough SageMaker Studio. Chiều: Generative AI with Amazon Bedrock Foundation Models: so sánh và hướng dẫn chọn giữa Claude, Llama, Titan, v.v. Prompt Engineering: Kỹ thuật nâng cao: Chain-of-Thought reasoning, Few-shot learning. Retrieval-Augmented Generation (RAG): Kiến trúc RAG và cách tích hợp với Knowledge Base bên ngoài. Bedrock Agents: xây dựng multi-step workflows và tích hợp công cụ. Guardrails: nguyên tắc an toàn và lọc nội dung. Live demo: xây dựng chatbot Generative AI sử dụng Bedrock. Những gì học được / Giá trị rút ra SageMaker: hiểu được SageMaker như một nền tảng toàn diện cho toàn bộ vòng đời ML (data prep → training → deployment). Bedrock \u0026amp; GenAI: nắm vai trò của Amazon Bedrock, biết so sánh các FM và hiểu các kỹ thuật cốt lõi như Prompt Engineering, RAG. Ứng dụng vào dự án: kiến thức về RAG và Bedrock Agents hữu ích để nâng cấp tính năng AI/Chatbot trong dự án Travel-Guided. Trải nghiệm Live Demo giúp thấy luồng triển khai thực tế và tốc độ prototyping với Bedrock. Trải nghiệm trong event Ấn tượng với các Live Demo, đặc biệt là xây dựng chatbot GenAI dùng Bedrock nhanh chóng. Cơ hội kết nối và trao đổi với các chuyên gia về AI/ML tại Việt Nam. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3 Khắc phục vấn đề tài khoản AWS và tạo tài khoản mới nếu cần. Thành thạo cấu hình Hybrid DNS với Route 53 Resolver. Triển khai và hiểu VPC Peering cho giao tiếp giữa các VPC. Thảo luận kế hoạch dự án và chọn ngôn ngữ lập trình với team. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Quản trị quyền truy cập với AWS Identity and Access Management (IAM) 21/09/2025 23/09/2025 Quản trị quyền truy cập với AWS Identity and Access Management (IAM) 3 - Hoàn thành Lab 10: Route 53 và cấu hình Hybrid DNS.\n- Khởi chạy máy chủ ảo để triển khai và kiểm tra DNS.\n- Hoàn thành: Hybrid DNS Management with Amazon Route 53. 24/09/2025 25/09/2025 FCJ Playlist 4 - Triển khai VPC Peering cho giao tiếp private giữa các VPC.\n- Tạo các tài nguyên cần thiết cho cấu hình VPC Peering.\n- Dọn dẹp tài nguyên sau khi hoàn thành.\n- Hoàn thành: Network Integration with VPC Peering. 25/09/2025 26/09/2025 AWS VPC Peering 5 - Tham gia họp nhóm để thảo luận kế hoạch dự án và chọn ngôn ngữ lập trình.\n- Đặt deadline cho các thành viên nghiên cứu công nghệ đã chọn. 28/09/2025 28/09/2025 Họp nhóm Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Hybrid DNS Management with Amazon Route 53 Mạng ✅ Network Integration with VPC Peering Mạng ✅ Networking on AWS Workshop Mạng ✅ Infrastructure as Code with AWS CloudFormation DevOps ✅ Cloud Development with AWS Cloud9 Phát triển ✅ Static Website Hosting with Amazon S3 Lưu trữ ✅ Kết quả đạt được tuần 3 Kỹ năng kỹ thuật đã tiếp thu:\nRoute 53 và Hybrid DNS:\nCấu hình thành công hạ tầng Hybrid DNS với Route 53 Resolver Tạo và cấu hình Outbound Endpoints để chuyển tiếp DNS queries Thiết lập Route 53 Resolver rules cho conditional DNS resolution Triển khai Inbound Endpoints cho DNS queries từ on-premises đến AWS Kết nối thành công với RD Gateway Server trong các bài thực hành VPC Peering:\nNắm vững khái niệm VPC Peering cho giao tiếp private giữa các VPC mà không qua internet công cộng Kích hoạt Cross-Zone and Cross-Region DNS Resolution trong VPC Peering: EC2 instances có thể phân giải DNS của instances trong VPCs được peering ra địa chỉ IP private Hiểu rằng nếu không có tính năng này, DNS queries trả về public IPs, định tuyến traffic qua internet Học quy trình dọn dẹp tài nguyên để tránh chi phí không cần thiết Infrastructure as Code:\nHọc cách provision tài nguyên AWS sử dụng CloudFormation templates Hiểu nguyên tắc quản lý hạ tầng declarative Khám phá AWS Cloud9 như môi trường phát triển trên cloud Hợp tác nhóm:\nTham gia họp nhóm để xác định hướng đi dự án Chọn ngôn ngữ lập trình cho dự án Thiết lập deadline cho các thành viên nghiên cứu công nghệ đã chọn Tiếp tục hành trình học tập với sự hỗ trợ của FCJ team Bài học chính:\nHybrid DNS cho phép phân giải DNS liền mạch giữa on-premises và AWS VPC Peering hiệu quả về chi phí để kết nối VPCs nhưng có giới hạn (không có transitive peering) CloudFormation templates đảm bảo triển khai hạ tầng nhất quán, có thể lặp lại AWS Cloud9 loại bỏ sự phức tạp của việc thiết lập môi trường phát triển local "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.3-blog3/","title":"Multi-Region keys: Một cách tiếp cận mới cho nhân bản khóa trong AWS Payment Cryptography","tags":[],"description":"","content":"Ngày đăng: 2025‑09‑16 – Tác giả: Ruy Cavalcanti và Mark Cline trong Announcements, Financial Services, Industries, Intermediate (200), Security, Identity, \u0026amp; Compliance, Technical How-to\nTrong bài viết trước của chúng tôi (Phần 1 của loạt bài về nhân bản khóa), Automatically replicate your card payment keys across AWS Regions, chúng tôi đã khám phá một kiến trúc serverless hướng sự kiện sử dụng AWS PrivateLink để nhân bản an toàn các khóa thanh toán thẻ giữa các Region AWS. Giải pháp đó minh họa cách xây dựng framework nhân bản khóa mã hóa thanh toán tùy chỉnh.\nDựa trên phản hồi từ khách hàng mong muốn cách thức tự động cao hơn, không cần code, chúng tôi rất vui mừng công bố một tùy chọn bổ sung với Multi-Region keys cho AWS Payment Cryptography trong Phần 2 của loạt bài.\nVới tính năng mới này, bạn có thể tự động đồng bộ các khóa mã hóa thanh toán từ Region chính sang các Region khác mà bạn chọn, cải thiện khả năng chịu lỗi và tính sẵn sàng của ứng dụng thanh toán. Bạn cũng có thể lựa chọn giữa nhân bản ở cấp tài khoản (account-level) hoặc cấp khóa (key-level), mang lại linh hoạt hơn trong quản lý khóa thanh toán giữa các Region.\nMulti-Region keys: Tổng quan và lợi ích Tính năng mới nhân bản khóa Multi-Region cho AWS Payment Cryptography cung cấp cho bạn quyền kiểm soát linh hoạt đối với chiến lược nhân bản khóa thông qua các khả năng chính sau:\nQuyết định xem các khóa có được nhân bản hay không Lựa chọn các Region cụ thể để nhân bản khóa Quản lý các thay đổi cấu hình nhân bản Cấu hình nhân bản ở cấp tài khoản hoặc cấp khóa tùy theo nhu cầu kinh doanh Multi-Region keys mang đến nhiều lợi ích cho hoạt động thanh toán toàn cầu, bao gồm:\nTăng tính sẵn sàng: Truy cập khóa thanh toán ngay cả khi một Region không khả dụng. Khả năng phục hồi thảm họa: Duy trì hoạt động kinh doanh khi có sự cố bằng cách nhân bản khóa giữa các Region. Vận hành toàn cầu: Hỗ trợ xử lý thanh toán trên nhiều vùng địa lý. Quản lý đơn giản: Kiểm soát tập trung với khả năng phân tán. ID khóa nhất quán: ID khóa giống nhau giữa các Region giúp đơn giản hóa phát triển ứng dụng. Tùy chọn cấu hình Payment Cryptography cung cấp hai phương thức riêng biệt để cấu hình nhân bản khóa Multi-Region, giúp bạn linh hoạt trong việc triển khai chiến lược phù hợp nhất với tổ chức: bạn có thể chọn giữa cách tiếp cận rộng (cấp tài khoản) hoặc cách tiếp cận chi tiết hơn (cấp khóa).\nCấp tài khoản (Account-level) Với cấu hình cấp tài khoản, AWS sẽ tự động sao chép các khóa đối xứng có thể xuất (exportable symmetric keys) được tạo trong tài khoản Payment Cryptography của bạn từ Region chính mà bạn chỉ định sang các Region khác mà bạn chỉ định. Điều này giúp đơn giản hóa việc quản lý khóa trong các triển khai đa vùng, cung cấp tính sẵn có nhất quán của khóa trong các Region bạn chọn và giảm bớt chi phí vận hành quản lý khóa.\nĐể cấu hình nhân bản cấp tài khoản bằng AWS Command Line Interface (AWS CLI), sử dụng API mới enable-default-key-replication-regions để đặt các Region mà AWS sẽ nhân bản khóa của bạn. Để loại bỏ Region khỏi danh sách nhân bản mặc định, dùng API disable-default-key-replication-regions .\nLưu ý: Chỉ các khóa đối xứng được tạo sau khi nhân bản cấp tài khoản được bật mới được nhân bản.\nNhân bản cấp khóa (Key-level replication) Bằng cách sử dụng key-level replication, bạn có thể đạt được mức kiểm soát chi tiết hơn thông qua việc:\nChỉ định các khóa cụ thể là multi-Region keys. Xác định mục tiêu nhân bản tùy chỉnh cho từng khóa multi-Region. Duy trì các khóa riêng biệt cho từng Region khi cần thiết. Lưu ý: Trong mỗi Region, Payment Cryptography duy trì khả năng dự phòng của khóa trên nhiều Availability Zone để đảm bảo tính sẵn sàng cao. Multi-Region key replication mở rộng điều này ra phạm vi địa lý, giúp tăng cường khả năng chống chịu với sự cố mất kết nối giữa các Region trong khi vẫn giữ quyền kiểm soát vị trí lưu trữ khóa.\nBạn có thể chỉ định các Region nhân bản ngay khi tạo khóa bằng cách sử dụng tham số --replication-regions trong AWS CLI, thông qua các API create-key hoặc import-key. Đối với các khóa đã tồn tại, bạn có thể sử dụng các API mới add-key-replication-regions và remove-key-replication-regions để quản lý những Region nào sẽ nhận bản nhân bản của khóa.\nQuan trọng: Khi bạn chỉ định các Region nhân bản trong quá trình tạo khóa, các thiết lập này sẽ có độ ưu tiên cao hơn so với cấu hình nhân bản mặc định ở cấp tài khoản.\nCách hoạt động Hình 1 mô tả quy trình khi bạn nhân bản một khóa trong Payment Cryptography:\nKhóa được tạo trong Region chính mà bạn chỉ định. Payment Cryptography tự động nhân bản không đồng bộ (asynchronously) phần key material đến các Region được chọn làm bản sao. Các khóa nhân bản duy trì cùng một Key ID trên tất cả các Region — chỉ phần Region trong Amazon Resource Name (ARN) thay đổi. Khóa trong Region chính được gắn nhãn MultiRegionKeyType: PRIMARY Các khóa trong các Region nhân bản được gắn nhãn MultiRegionKeyType: REPLICA và có tham chiếu tới Region chính. Khi xóa một khóa, việc xóa này sẽ tự động lan truyền (cascade) từ khóa chính sang các bản sao ở các Region khác. | Hình 1: Minh họa quá trình nhân bản khóa từ us-east-1 sang us-west-2\nVí dụ: Tạo khóa multi-Region ở cấp khóa Ví dụ sau minh họa việc tạo card verification key (CVK) trong Region chính (us-east-1) với việc nhân bản sang us-west-2:\naws payment-cryptography create-key \\\n--exportable \\\n--key-attributes KeyAlgorithm=TDES_2KEY,\\\nKeyUsage=TR31_C0_CARD_VERIFICATION_KEY,\\\nKeyClass=SYMMETRIC_KEY,KeyModesOfUse=\u0026rsquo;{Generate=true,Verify=true}\u0026rsquo; \\\n--region us-east-1 \\\n--replication-regions us-west-2\nKết quả phản hồi cho thấy khóa đang được tạo và quá trình nhân bản đang diễn ra:\n{\n\u0026ldquo;Key\u0026rdquo;: {\n\u0026quot;KeyArn\u0026quot;: \u0026quot;arn:aws:payment-cryptography:us-east-1:111122223333:key/qs6643jl4ohibtqk\u0026quot;, \u0026quot;KeyAttributes\u0026quot;: { \u0026quot;KeyUsage\u0026quot;: \u0026quot;TR31\\_C0\\_CARD\\_VERIFICATION\\_KEY\u0026quot;, \u0026quot;KeyClass\u0026quot;: \u0026quot;SYMMETRIC\\_KEY\u0026quot;, \u0026quot;KeyAlgorithm\u0026quot;: \u0026quot;TDES\\_2KEY\u0026quot;, \u0026quot;KeyModesOfUse\u0026quot;: { \u0026quot;Encrypt\u0026quot;: false, \u0026quot;Decrypt\u0026quot;: false, \u0026quot;Wrap\u0026quot;: false, \u0026quot;Unwrap\u0026quot;: false, \u0026quot;Generate\u0026quot;: true, \u0026quot;Sign\u0026quot;: false, \u0026quot;Verify\u0026quot;: true, \u0026quot;DeriveKey\u0026quot;: false, \u0026quot;NoRestrictions\u0026quot;: false } }, \u0026quot;KeyCheckValue\u0026quot;: \u0026quot;CC5EE2\u0026quot;, \u0026quot;KeyCheckValueAlgorithm\u0026quot;: \u0026quot;ANSI\\_X9\\_24\u0026quot;, \u0026quot;Enabled\u0026quot;: true, \u0026quot;Exportable\u0026quot;: true, \u0026quot;KeyState\u0026quot;: \u0026quot;CREATE\\_COMPLETE\u0026quot;, \u0026quot;KeyOrigin\u0026quot;: \u0026quot;AWS\\_PAYMENT\\_CRYPTOGRAPHY\u0026quot;, \u0026quot;CreateTimestamp\u0026quot;: \u0026quot;2025-08-21T15:25:54.475000-03:00\u0026quot;, \u0026quot;UsageStartTimestamp\u0026quot;: \u0026quot;2025-08-21T15:25:54.287000-03:00\u0026quot;, \u0026quot;MultiRegionKeyType\u0026quot;: \u0026quot;PRIMARY\u0026quot;, **\u0026quot;ReplicationStatus\u0026quot;: {** **\u0026quot;us-west-2\u0026quot;: {** **\u0026quot;Status\u0026quot;: \u0026quot;IN\\_PROGRESS\u0026quot;** **}** }, \u0026quot;UsingDefaultReplicationRegions\u0026quot;: false }\n}\nKhi quá trình nhân bản hoàn tất, trạng thái sẽ được cập nhật thành SYNCHRONIZED:\naws payment-cryptography get-key \\\n--key-identifier arn:aws:payment-cryptography:us-east-1:111122223333:key/qs6643jl4ohibtqk \\\n--region us-east-1\nKết quả trả về cho thấy khóa chính đã đồng bộ hoàn tất:\n\u0026ldquo;ReplicationStatus\u0026rdquo;: {\n\u0026quot;us-west-2\u0026quot;: { \u0026quot;Status\u0026quot;: \u0026quot;SYNCHRONIZED\u0026quot; } } Bạn có thể truy cập khóa ở Region bản sao (us-west-2) bằng cách sử dụng cùng Key ID, chỉ thay đổi tên Region:\naws payment-cryptography get-key \\\n--key-identifier arn:aws:payment-cryptography:us-west-2:111122223333:key/qs6643jl4ohibtqk \\\n--region us-west-2\nKết quả trả về hiển thị khóa bản sao với tham chiếu đến Region chính (PrimaryRegion: us-east-1).\nNhững điều cần lưu ý Khi sử dụng multi-Region keys, có một số điểm quan trọng cần cân nhắc:\nChỉ hỗ trợ symmetric keys có thuộc tính exportable, không hỗ trợ asymmetric keys. Chi phí tính riêng cho từng Region — ví dụ, nhân bản sang 3 Region sẽ phát sinh chi phí cho khóa chính cộng thêm chi phí của mỗi khóa bản sao. Key alias và tags cần được quản lý riêng ở từng Region vì chúng không được nhân bản tự động. Khóa chính (primary key) có thể được chỉnh sửa hoặc cập nhật, trong khi khóa bản sao (replica) chỉ là bản read-only hỗ trợ các thao tác mật mã (cryptographic operations). Mọi thay đổi phải được thực hiện ở khóa chính và Payment Cryptography sẽ tự động đồng bộ sang các Region bản sao. Theo dõi trạng thái nhân bản để đảm bảo các thay đổi đã được đồng bộ thành công. Hành vi khi xóa khóa Khi lên lịch xóa khóa chính:\nTất cả các khóa bản sao sẽ bị xóa ngay lập tức. Khóa chính sẽ chuyển sang trạng thái pending deletion trong tối thiểu 3 ngày, trong thời gian này có thể hủy xóa (cancel deletion). Nếu bạn khôi phục khóa chính, bạn cần bật lại nhân bản để tái tạo các bản sao ở các Region mong muốn. Sau khi thời gian 3 ngày trôi qua, khóa chính sẽ bị xóa vĩnh viễn và không thể phục hồi. Việc xóa một replica key chỉ ảnh hưởng đến Region đó, không ảnh hưởng đến khóa chính hoặc các bản sao khác. Mô hình nhất quán cuối cùng (Eventual consistency) Nhân bản khóa đa vùng hoạt động theo mô hình eventual consistency — nghĩa là các thay đổi có thể không xuất hiện ngay lập tức trên tất cả các Region.\nDo đó, ứng dụng nên được thiết kế để xử lý mô hình này và không giả định rằng khóa hoặc thay đổi sẽ có sẵn ngay lập tức ở các Region bản sao.\nNếu ứng dụng của bạn yêu cầu tính nhất quán mạnh (strong consistency), hãy triển khai cơ chế polling bằng cách sử dụng API GetKey để xác minh rằng các thay đổi đã được đồng bộ trước khi tiến hành các thao tác mã hóa.\nGhi nhật ký và giám sát (Logging and monitoring) Payment Cryptography ghi lại hoạt động API thông qua AWS CloudTrail, hiện đã bao gồm các sự kiện (event) và thuộc tính (attribute) mới dành riêng cho tính năng Multi-Region key replication.\nSự kiện CloudTrail mới Dịch vụ này ghi nhận một loại sự kiện mới có tên SynchronizeMultiRegionKey, xuất hiện ở cả Region chính và Region bản sao.\nSự kiện ở Region chính: Mỗi Region bản sao được định nghĩa sẽ tạo ra hai sự kiện SynchronizeMultiRegionKey trong Region chính:\nMột sự kiện liên quan đến quá trình export khóa.\n\u0026ldquo;serviceEventDetails\u0026rdquo;: {\n\u0026ldquo;keyArn\u0026rdquo;: \u0026ldquo;arn:aws:payment-cryptography:us-east-1:111122223333:key/qs6643jl4ohibtqk\u0026rdquo;,\n\u0026ldquo;replicationRegion\u0026rdquo;: \u0026ldquo;us-west-2\u0026rdquo;,\n\u0026ldquo;replicationType\u0026rdquo;: \u0026ldquo;ExportKeyReplica\u0026rdquo;\n},\nMột sự kiện liên quan đến quá trình import khóa.\n\u0026ldquo;serviceEventDetails\u0026rdquo;: {\n\u0026ldquo;keyArn\u0026rdquo;: \u0026ldquo;arn:aws:payment-cryptography:us-east-1:111122223333:key/qs6643jl4ohibtqk\u0026rdquo;,\n\u0026ldquo;replicationRegion\u0026rdquo;: \u0026ldquo;us-west-2\u0026rdquo;,\n\u0026ldquo;replicationType\u0026rdquo;: \u0026ldquo;ImportKeyReplica\u0026rdquo;\n},\nSự kiện ở Region bản sao: Mỗi Region bản sao ghi lại một sự kiện SynchronizeMultiRegionKey tương ứng với quá trình import khóa:\n\u0026ldquo;eventName\u0026rdquo;: \u0026ldquo;SynchronizeMultiRegionKey\u0026rdquo;,\n\u0026ldquo;awsRegion\u0026rdquo;: \u0026ldquo;us-west-2\u0026rdquo;,\n\u0026ldquo;serviceEventDetails\u0026rdquo;: {\n\u0026quot;keyArn\u0026quot;: \u0026quot;arn:aws:payment-cryptography:us-west-2:111122223333:key/qs6643jl4ohibtqk\u0026quot;, \u0026quot;replicationRegion\u0026quot;: \u0026quot;us-west-2\u0026quot;, **\u0026quot;replicationType\u0026quot;: \u0026quot;ImportKeyReplica\u0026quot;** }, Thuộc tính CloudTrail mới Các API quản lý khóa (key management APIs) giờ đây bao gồm những thuộc tính mới để phản ánh hoạt động của Multi-Region replication.\nVí dụ, sự kiện CreateKey trong Region chính (us-east-1) nay có thêm thuộc tính:\n\u0026ldquo;requestParameters\u0026rdquo;: {\n**\u0026quot;replicationRegions\u0026quot;: \\[\u0026quot;us-west-2\u0026quot;\\]** }\nSự kiện CreateKey trong Region bản sao (us-west-2) sẽ phản ánh quá trình khởi tạo khóa replica tương ứng, với các thông tin tương tự về KeyUsage, Algorithm và KeyCheckValue.\nBắt đầu sử dụng Để bắt đầu sử dụng Multi-Region key replication trong Payment Cryptography, hãy thực hiện các bước sau:\nXác định Region chính (primary Region).\nXác định các Region bản sao (replica Regions) và quyết định xem bạn sẽ dùng cấu hình account-level hay key-level.\nTạo symmetric key có thể export (exportable symmetric key) mới hoặc cập nhật các khóa hiện có để bật tính năng Multi-Region replication.\nCập nhật ứng dụng của bạn để sử dụng Key ID nhất quán giữa các Region.\nKết luận Tính năng Multi-Region key replication mới trong AWS Payment Cryptography nâng cao khả năng nhân bản khóa tự động, giúp cải thiện khả năng chịu lỗi, tính sẵn sàng, và đơn giản hóa việc quản lý khóa thanh toán toàn cầu. Tính năng này đảm bảo rằng các payment cryptography keys của bạn luôn khả dụng mọi lúc, mọi nơi, đồng thời cung cấp sự linh hoạt trong việc lựa chọn chiến lược nhân bản giữa account-level và key-level, giúp tổ chức tối ưu hiệu năng, bảo mật, và chi phí trong môi trường đa vùng (multi-Region).\nRuy Cavalcanti Ruy là Senior Security Architect là chuyên gia trong ngành tài chính Mỹ Latinh tại AWS. Ông đã làm việc trong lĩnh vực CNTT và Bảo mật hơn 19 năm, giúp khách hàng xây dựng kiến ​​trúc bảo mật và giải quyết các thách thức về bảo vệ dữ liệu và tuân thủ. Khi không phải thiết kế các giải pháp bảo mật, ông thích chơi guitar, nấu món thịt nướng kiểu Brazil và dành thời gian cho gia đình và bạn bè. Mark Cline Mark là Trưởng phòng Quản lý Sản phẩm tại AWS Payments, nơi ông có hơn 15 năm kinh nghiệm trong lĩnh vực dịch vụ tài chính trên nhiều trường hợp sử dụng và lĩnh vực khác nhau. Ông hợp tác với các ngân hàng, tổ chức tài chính và nhà cung cấp công nghệ hàng đầu để giảm bớt gánh nặng cho hệ thống thanh toán, cho phép khách hàng tập trung vào đổi mới. Khi không bận rộn với việc đơn giản hóa thanh toán, bạn có thể thấy ông đang huấn luyện các đội bóng chày nhỏ hoặc chạy bộ. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-setup-fe/5.4.3-sg/","title":"Cấu hình Security Group","tags":[],"description":"","content":"Các container Frontend của chúng ta hoạt động trong Private Subnet. Để cho phép chúng nhận lưu lượng truy cập, ta cần cấu hình Security Group đóng vai trò như một bức tường lửa ảo.\nTuân thủ nguyên tắc bảo mật (best practices), chúng ta sẽ chỉ cho phép truy cập từ Application Load Balancer (ALB) vào cổng 3000. Mọi truy cập trực tiếp từ Internet hoặc các nguồn khác đều sẽ bị chặn.\n1. Tạo Security Group Truy cập EC2 Dashboard \u0026gt; Security Groups \u0026gt; Create security group. Basic details (Thông tin cơ bản): Security group name: ecs-private-sg. Description: security group for ecs. VPC: Chọn band-up-vpc. 2. Cấu hình Inbound Rules (Quy tắc chiều vào) Đây là bước quan trọng nhất. Chúng ta cần cho phép ALB giao tiếp với ứng dụng Next.js.\nInbound rules: Nhấn Add rule. Type: Custom TCP. Port range: 3000 (Cổng mà ứng dụng Next.js đang lắng nghe). Source: Chọn Custom và tìm chọn Security Group ID của ALB (ví dụ: alb-sg). Lưu ý: Bằng cách chọn ID của Security Group thay vì dải IP, chúng ta đảm bảo rằng chỉ có lưu lượng xuất phát từ Load Balancer mới được chấp nhận. Outbound rules (Quy tắc chiều ra): Giữ nguyên mặc định (Allow all traffic) để container có thể tải các gói tin hoặc gọi API bên ngoài. Nhấn Create security group. Security Group hiện đã sẵn sàng để được gắn vào ECS Task trong bước tiếp theo.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-network/","title":"Hạ tầng Mạng &amp; Bảo mật","tags":[],"description":"","content":"Tổng quan Trong phần này, chúng ta sẽ xây dựng lớp mạng nền tảng và các thiết lập bảo mật cốt lõi cho IELTS BandUp.\nMột kiến trúc mạng vững chắc là yếu tố then chốt để bảo vệ dữ liệu người dùng và đảm bảo tính sẵn sàng cao của hệ thống. Thay vì sử dụng các cài đặt mạng mặc định, chúng ta sẽ xây dựng một Virtual Private Cloud (VPC) tùy chỉnh, được thiết kế chuyên biệt cho môi trường production. Thiết lập này cho phép kiểm soát chặt chẽ luồng truy cập giữa các thành phần ứng dụng (Frontend, Backend, Database) và Internet.\nNgoài ra, chúng ta sẽ cấu hình các VPC Endpoints để cho phép các container trong mạng nội bộ giao tiếp an toàn với các dịch vụ AWS (như ECR và S3) mà không cần đi qua Internet công cộng, giúp tối ưu hóa cả về bảo mật lẫn hiệu năng mạng.\nCác bước thực hiện Chúng ta sẽ chia quy trình thiết lập hạ tầng thành các nhiệm vụ chính sau:\nVPC \u0026amp; Kết nối: Khởi tạo môi trường mạng cô lập, phân chia thành các Subnet Public/Private và cấu hình Internet Gateway (IGW) cho kết nối ra bên ngoài. Cân bằng tải (ALB): Thiết lập Application Load Balancer và các Target Group để phân phối lưu lượng truy cập đến các ECS task sau này. Bảo mật IAM: Cấp phát ecsTaskExecutionRole để ủy quyền cho Fargate container thực hiện các tác vụ như tải image và ghi log. Cấu hình VPC Endpoints: Thiết lập kết nối riêng tư đến các dịch vụ AWS (ECR, CloudWatch, S3) để bảo mật lưu lượng nội bộ. Nội dung Cấu hình VPC, Subnets \u0026amp; Routing Cài đặt Application Load Balancer (ALB) IAM Roles cho ECS Thiết lập VPC Endpoints "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-network/5.3.3-iam/","title":"IAM Roles cho ECS","tags":[],"description":"","content":"Để Amazon ECS có thể quản lý các container, dịch vụ này cần được cấp một số quyền hạn nhất định. Chúng ta phải tạo một IAM Role để ủy quyền cho ECS agent thực hiện các tác vụ như kéo (pull) container image từ Amazon ECR và gửi log đến Amazon CloudWatch thay mặt cho bạn.\nTạo ecsTaskExecutionRole Truy cập IAM Dashboard. Ở thanh điều hướng bên trái, chọn Roles. Nhấn Create role. Bước 1: Thực thể tin cậy (Trusted Entity)\nTrusted entity type: Chọn AWS service. Service or use case: Chọn Elastic Container Service. Chọn Elastic Container Service Task trong các tùy chọn hiện ra. Nhấn Next. Bước 2: Thêm quyền (Permissions)\nTrong thanh tìm kiếm, gõ AmazonECSTaskExecutionRolePolicy. Tích vào ô vuông cạnh tên chính sách AmazonECSTaskExecutionRolePolicy. Lưu ý: Đây là chính sách được AWS quản lý, cung cấp đủ quyền để kéo image từ ECR và tải log lên CloudWatch. Nhấn Next. Bước 3: Đặt tên và Xem lại\nRole name: Nhập ecsTaskExecutionRole. Kiểm tra lại cấu hình và nhấn Create role. Sau khi tạo xong, Role này đã sẵn sàng để gán cho các ECS Task Definition trong các phần tiếp theo của workshop.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-setup-be/5.5.3-redis/","title":"Tạo ElastiCache (Redis/Valkey)","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ khởi tạo một kho dữ liệu in-memory để xử lý việc quản lý session và caching cho backend. Chúng ta sẽ sử dụng Amazon ElastiCache với engine Valkey (một nhánh mã nguồn mở hiệu năng cao của Redis được AWS hỗ trợ).\n1. Cấu hình Security Group Đầu tiên, tạo Security Group để cho phép backend giao tiếp với cache cluster.\nTruy cập EC2 \u0026gt; Security Groups \u0026gt; Create security group. Name: redis-sg. Inbound rules: Cho phép lưu lượng Custom TCP tại cổng 6379 từ nguồn là ecs-backend-sg. (Lưu ý: Hãy đảm bảo tạo SG này trước khi vào giao diện ElastiCache).\n2. Tạo Subnet Group Chúng ta cần xác định các subnet mà cache node sẽ hoạt động.\nTruy cập Amazon ElastiCache \u0026gt; Subnet groups \u0026gt; Create subnet group. Name: bandup-cached-subnet-group. VPC: Chọn band-up-vpc. Subnets: Chọn private-database-subnet-1 và private-database-subnet-2 (Availability Zones ap-southeast-1a và 1b). 3. Tạo ElastiCache Cluster Bây giờ chúng ta tiến hành khởi tạo cluster.\nTruy cập ElastiCache \u0026gt; Caches \u0026gt; Create cache. Engine: Chọn Valkey - recommended (Tương thích với Redis OSS). Deployment option: Chọn Node-based cluster (Cho phép kiểm soát loại instance). Creation method: Cluster cache. Cấu hình Cluster: Cluster mode: Disabled (Cấu trúc primary-replica đơn giản là đủ). Name: bandup-redis. Description: in memory db for bandup. Cấu hình Node: Node type: cache.t3.micro (Tiết kiệm chi phí cho workshop). Number of replicas: 0 (Chạy node đơn lẻ). Kết nối (Connectivity): Network type: IPv4. Subnet groups: Chọn bandup-cached-subnet-group. Bảo mật \u0026amp; Mã hóa: Encryption at rest: Enabled (Default key). Encryption in transit: Enabled. Access control: No access control (Chúng ta dựa vào Security Group để bảo mật). Security groups: Chọn redis-sg đã tạo trước đó. Sao lưu: Bật sao lưu tự động (Retention: 1 ngày). Nhấn Create. Trạng thái của cluster sẽ chuyển sang Creating. Sau khi chuyển sang Available, hãy ghi lại Primary Endpoint (có dạng ...cache.amazonaws.com:6379) để sử dụng cấu hình cho backend.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-ai-service/5.6.3-lambda-functions/","title":"Lambda Functions","tags":[],"description":"","content":"Tổng Quan Tầng AI Service bao gồm bốn Lambda functions cung cấp sức mạnh cho nền tảng học IELTS. Các functions này xử lý yêu cầu bất đồng bộ qua SQS queues và tích hợp với Google Gemini API và Amazon Bedrock để đánh giá bằng AI.\nLambda Function 1: Writing Evaluator Đánh giá bài luận IELTS Writing Task 1 và Task 2 sử dụng Gemini API với điểm band chi tiết.\nCài Đặt Giá Trị Function name bandup-writing-evaluator Runtime Python 3.11 Memory 1024 MB Timeout 5 phút Trigger SQS (bandup-writing-queue) AI Model Google Gemini 2.0 Flash Triển Khai Chính:\nimport json import os import boto3 import logging from typing import Dict, Any logger = logging.getLogger() logger.setLevel(logging.INFO) # Import từ Lambda layer from lambda_shared.gemini_client import GeminiClient from secrets_helper import get_gemini_api_key def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict[str, Any]: \u0026#34;\u0026#34;\u0026#34;Đánh giá bài luận IELTS Writing sử dụng Gemini API.\u0026#34;\u0026#34;\u0026#34; # Parse SQS message hoặc API Gateway request if is_sqs_event(event): request_data, job_id = parse_sqs_message(event) update_job_status(job_id, \u0026#39;processing\u0026#39;, \u0026#39;writing\u0026#39;) else: request_data = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) # Lấy API key an toàn từ Secrets Manager gemini_api_key = get_gemini_api_key() # Lấy từ AWS Secrets Manager gemini_client = GeminiClient(api_key=gemini_api_key) # Trích xuất parameters từ request user_id = request_data.get(\u0026#39;user_id\u0026#39;) essay_content = request_data.get(\u0026#39;essay_content\u0026#39;) task_type = request_data.get(\u0026#39;task_type\u0026#39;, \u0026#39;TASK_2\u0026#39;) # Xây dựng prompt đánh giá prompt = build_writing_prompt(essay_content, task_type) # Gọi Gemini API để đánh giá response = gemini_client.generate_evaluation( prompt=prompt, feature=\u0026#39;writing_task2\u0026#39;, max_retries=3, timeout=60 ) # Parse và validate band scores evaluation = parse_gemini_response(response[\u0026#39;content\u0026#39;]) # Xây dựng kết quả với tiêu chí IELTS result = { \u0026#39;session_id\u0026#39;: request_data.get(\u0026#39;session_id\u0026#39;), \u0026#39;overall_band\u0026#39;: evaluation.get(\u0026#39;overall_band\u0026#39;), \u0026#39;task_achievement_band\u0026#39;: evaluation[\u0026#39;task_achievement\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;coherence_band\u0026#39;: evaluation[\u0026#39;coherence_cohesion\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;lexical_band\u0026#39;: evaluation[\u0026#39;lexical_resource\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;grammar_band\u0026#39;: evaluation[\u0026#39;grammatical_range_accuracy\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;feedback\u0026#39;: evaluation } # Lưu vào DynamoDB dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) table = dynamodb.Table(os.environ.get(\u0026#39;DYNAMODB_EVALUATIONS\u0026#39;)) table.put_item(Item={ \u0026#39;evaluation_id\u0026#39;: result[\u0026#39;session_id\u0026#39;], \u0026#39;user_id\u0026#39;: user_id, \u0026#39;evaluation_type\u0026#39;: \u0026#39;writing\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, **result }) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(result)} Mẫu Prompt Gemini:\ndef build_writing_prompt(essay_content: str, task_type: str) -\u0026gt; str: return f\u0026#34;\u0026#34;\u0026#34;You are an experienced IELTS examiner. Evaluate this essay: Task Type: {task_type} ESSAY: {essay_content} Evaluate using IELTS band descriptors (1-9, 0.5 increments): 1. Task Achievement - Addresses all parts of task 2. Coherence and Cohesion - Logical organization 3. Lexical Resource - Vocabulary range and accuracy 4. Grammatical Range and Accuracy - Sentence structures RESPOND IN JSON FORMAT: {{ \u0026#34;overall_band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;task_achievement\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;coherence_cohesion\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;lexical_resource\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;grammatical_range_accuracy\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;quoted_examples\u0026#34;: [{{\u0026#34;quote\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;issue\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;suggestion\u0026#34;: \u0026#34;...\u0026#34;}}] }}\u0026#34;\u0026#34;\u0026#34; Lambda Function 2: Speaking Evaluator Đánh giá IELTS Speaking sử dụng Gemini native audio processing - rẻ hơn 72% và nhanh gấp 2 lần so với AWS Transcribe.\nCài Đặt Giá Trị Function name bandup-speaking-evaluator Runtime Python 3.11 Memory 2048 MB Timeout 5 phút Trigger SQS (bandup-speaking-queue) AI Model Gemini 2.5 Flash (Native Audio) Triển Khai Chính:\nimport json import os import boto3 import logging from typing import Dict, Any, Tuple logger = logging.getLogger() # Import từ Lambda layer from lambda_shared.gemini_client import GeminiClient from secrets_helper import get_gemini_api_key def download_audio_from_s3(audio_url: str) -\u0026gt; Tuple[bytes, str]: \u0026#34;\u0026#34;\u0026#34;Tải file audio từ S3 và xác định MIME type.\u0026#34;\u0026#34;\u0026#34; s3_client = boto3.client(\u0026#39;s3\u0026#39;) # Parse S3 URL: s3://bucket-name/path/to/file.mp3 parts = audio_url.replace(\u0026#39;s3://\u0026#39;, \u0026#39;\u0026#39;).split(\u0026#39;/\u0026#39;, 1) bucket, key = parts[0], parts[1] response = s3_client.get_object(Bucket=bucket, Key=key) audio_bytes = response[\u0026#39;Body\u0026#39;].read() # Xác định MIME type từ extension mime_types = {\u0026#39;.mp3\u0026#39;: \u0026#39;audio/mp3\u0026#39;, \u0026#39;.wav\u0026#39;: \u0026#39;audio/wav\u0026#39;, \u0026#39;.m4a\u0026#39;: \u0026#39;audio/m4a\u0026#39;} ext = \u0026#39;.\u0026#39; + key.split(\u0026#39;.\u0026#39;)[-1].lower() mime_type = mime_types.get(ext, \u0026#39;audio/mp3\u0026#39;) return audio_bytes, mime_type def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict[str, Any]: \u0026#34;\u0026#34;\u0026#34;Đánh giá IELTS Speaking sử dụng Gemini native audio.\u0026#34;\u0026#34;\u0026#34; # Parse request request_data = parse_request(event) # Lấy API key từ Secrets Manager gemini_api_key = get_gemini_api_key() gemini_client = GeminiClient(api_key=gemini_api_key) # Trích xuất parameters audio_url = request_data.get(\u0026#39;audio_url\u0026#39;) part = request_data.get(\u0026#39;part\u0026#39;, \u0026#39;PART_1\u0026#39;) questions = request_data.get(\u0026#39;questions\u0026#39;, []) # Bước 1: Tải audio từ S3 audio_bytes, mime_type = download_audio_from_s3(audio_url) logger.info(f\u0026#34;Đã tải {len(audio_bytes)} bytes, MIME: {mime_type}\u0026#34;) # Bước 2: Gửi audio trực tiếp đến Gemini (MỘT lần gọi API) # Không cần AWS Transcribe - Gemini xử lý audio trực tiếp evaluation = gemini_client.evaluate_audio( audio_bytes=audio_bytes, part=part, questions=questions, mime_type=mime_type, max_retries=3, timeout=120 ) # Bước 3: Xây dựng response với tiêu chí IELTS Speaking result = { \u0026#39;session_id\u0026#39;: request_data.get(\u0026#39;session_id\u0026#39;), \u0026#39;transcript\u0026#39;: evaluation.get(\u0026#39;transcript\u0026#39;), \u0026#39;duration\u0026#39;: evaluation.get(\u0026#39;duration_seconds\u0026#39;), \u0026#39;overall_band\u0026#39;: evaluation.get(\u0026#39;overall_band\u0026#39;), \u0026#39;fluency_band\u0026#39;: evaluation[\u0026#39;fluency_coherence\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;lexical_band\u0026#39;: evaluation[\u0026#39;lexical_resource\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;grammar_band\u0026#39;: evaluation[\u0026#39;grammatical_range_accuracy\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;pronunciation_band\u0026#39;: evaluation[\u0026#39;pronunciation\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;model_used\u0026#39;: \u0026#39;gemini-2.5-flash-audio\u0026#39;, \u0026#39;estimated_cost\u0026#39;: evaluation[\u0026#39;usage\u0026#39;][\u0026#39;cost\u0026#39;] } # Lưu vào DynamoDB save_evaluation(result, request_data.get(\u0026#39;user_id\u0026#39;)) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(result)} So Sánh Chi Phí:\nPhương Pháp Chi Phí / 3-phút Audio Độ Trễ Gemini Native Audio ~$0.021 30-45s AWS Transcribe + LLM ~$0.076 60-90s Tiết Kiệm 72% Nhanh gấp 2x Lambda Function 3: Flashcard Generator (RAG) Tạo flashcards từ tài liệu PDF sử dụng RAG pipeline nhẹ với Titan Embeddings (in-memory vector store, tối ưu cho Lambda package \u0026lt;50MB).\nCài Đặt Giá Trị Function name bandup-flashcard-generator Runtime Python 3.11 Memory 1024 MB Timeout 10 phút Trigger SQS (bandup-flashcard-queue) AI Model Gemini + Amazon Titan Embeddings V2 Luồng RAG Pipeline:\n┌─────────────┐ ┌──────────────┐ ┌─────────────────┐ │ PDF Upload │ ──▶ │ Chunking │ ──▶ │ Titan Embeddings│ │ (S3) │ │ (3000 chars) │ │ (Bedrock) │ └─────────────┘ └──────────────┘ └────────┬────────┘ │ ▼ ┌─────────────┐ ┌──────────────┐ ┌─────────────────┐ │ Flashcards │ ◀── │ Gemini │ ◀── │ In-Memory Store │ │ (JSON) │ │ Generation │ │ (Cosine Sim) │ └─────────────┘ └──────────────┘ └─────────────────┘ Triển Khai Chính:\nimport json import os import boto3 import time import google.generativeai as genai from typing import Dict, Any, List from concurrent.futures import ThreadPoolExecutor, as_completed logger = logging.getLogger() # Global instance cho warm starts (tối ưu Lambda) _rag_instance = None _s3_client = None def get_s3_client(): \u0026#34;\u0026#34;\u0026#34;Lấy cached S3 client.\u0026#34;\u0026#34;\u0026#34; global _s3_client if _s3_client is None: _s3_client = boto3.client(\u0026#39;s3\u0026#39;) return _s3_client def get_rag_instance(api_key: str): \u0026#34;\u0026#34;\u0026#34;Lấy cached RAG instance cho warm starts.\u0026#34;\u0026#34;\u0026#34; global _rag_instance if _rag_instance is None: _rag_instance = RAG( api_key=api_key, chunk_size=int(os.environ.get(\u0026#39;RAG_CHUNK_SIZE\u0026#39;, \u0026#39;500\u0026#39;)), chunk_overlap=int(os.environ.get(\u0026#39;RAG_CHUNK_OVERLAP\u0026#39;, \u0026#39;100\u0026#39;)) ) logger.info(\u0026#34;Cold start: RAG instance created\u0026#34;) else: logger.info(\u0026#34;Warm start: Reusing RAG instance\u0026#34;) return _rag_instance def download_pdf_from_s3(bucket: str, key: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Tải PDF từ S3 về /tmp.\u0026#34;\u0026#34;\u0026#34; s3 = get_s3_client() local_path = f\u0026#34;/tmp/{key.split(\u0026#39;/\u0026#39;)[-1]}\u0026#34; s3.download_file(bucket, key, local_path) return local_path def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict[str, Any]: \u0026#34;\u0026#34;\u0026#34;Tạo flashcard dựa trên RAG (nhẹ).\u0026#34;\u0026#34;\u0026#34; start_time = time.time() is_async = is_sqs_event(event) # Parse request if is_async: request, job_id = parse_sqs_message(event) update_job_status(job_id, \u0026#39;processing\u0026#39;) else: request = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) if isinstance(event.get(\u0026#39;body\u0026#39;), str) else event # Lấy S3 location pdf_url = request.get(\u0026#39;pdf_url\u0026#39;) s3_bucket, s3_key = parse_s3_url(pdf_url) # Lấy API key từ Secrets Manager secret_arn = os.environ.get(\u0026#39;GEMINI_API_KEY_SECRET_ARN\u0026#39;) secrets_client = boto3.client(\u0026#39;secretsmanager\u0026#39;) api_key = secrets_client.get_secret_value(SecretId=secret_arn)[\u0026#39;SecretString\u0026#39;] # Lấy parameters num_cards = int(request.get(\u0026#39;num_cards\u0026#39;, 10)) difficulty = request.get(\u0026#39;difficulty\u0026#39;, \u0026#39;MEDIUM\u0026#39;) question_types = request.get(\u0026#39;question_types\u0026#39;, [\u0026#39;DEFINITION\u0026#39;, \u0026#39;VOCABULARY\u0026#39;, \u0026#39;COMPREHENSION\u0026#39;]) # Bước 1: Tải PDF từ S3 local_pdf = download_pdf_from_s3(s3_bucket, s3_key) # Bước 2: Index document với RAG (Titan Embeddings + in-memory store) rag = get_rag_instance(api_key) rag._vector_store = None # Reset cho document mới rag._chunks = [] index_result = rag.index_document(local_pdf, document_id=s3_key) logger.info(f\u0026#34;Đã index {index_result[\u0026#39;chunk_count\u0026#39;]} chunks từ {index_result[\u0026#39;page_count\u0026#39;]} trang\u0026#34;) # Bước 3: Truy xuất chunks liên quan (hybrid approach) if index_result[\u0026#39;chunk_count\u0026#39;] \u0026lt;= 15: # Document nhỏ: dùng representative chunks chunks = rag.get_representative_chunks(num_chunks=min(10, index_result[\u0026#39;chunk_count\u0026#39;])) retrieval_method = \u0026#34;representative\u0026#34; else: # Document lớn: dùng smart keyword-based queries chunks = rag.retrieve_with_smart_queries(top_k_per_query=3) retrieval_method = \u0026#34;smart_queries\u0026#34; # Bước 4: Tạo flashcards với Gemini prompt = generate_flashcards_prompt(chunks, num_cards, difficulty, question_types) flashcard_result = call_gemini(prompt, api_key) # Dọn dẹp os.remove(local_pdf) # Xây dựng response total_time = time.time() - start_time response_body = { \u0026#39;status\u0026#39;: \u0026#39;success\u0026#39;, \u0026#39;set_id\u0026#39;: request.get(\u0026#39;set_id\u0026#39;), \u0026#39;user_id\u0026#39;: request.get(\u0026#39;user_id\u0026#39;), \u0026#39;document\u0026#39;: { \u0026#39;s3_bucket\u0026#39;: s3_bucket, \u0026#39;s3_key\u0026#39;: s3_key, \u0026#39;page_count\u0026#39;: index_result[\u0026#39;page_count\u0026#39;], \u0026#39;chunk_count\u0026#39;: index_result[\u0026#39;chunk_count\u0026#39;] }, \u0026#39;retrieval\u0026#39;: { \u0026#39;method\u0026#39;: retrieval_method, \u0026#39;chunks_used\u0026#39;: len(chunks), \u0026#39;keywords\u0026#39;: index_result.get(\u0026#39;keywords\u0026#39;, [])[:5] }, \u0026#39;flashcards\u0026#39;: flashcard_result.get(\u0026#39;flashcards\u0026#39;, []), \u0026#39;total_cards\u0026#39;: len(flashcard_result.get(\u0026#39;flashcards\u0026#39;, [])), \u0026#39;metrics\u0026#39;: { \u0026#39;total_time_ms\u0026#39;: round(total_time * 1000) } } # Lưu vào DynamoDB (bảng bandup-flashcard-sets) dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) table = dynamodb.Table(os.environ.get(\u0026#39;DYNAMODB_FLASHCARD_SETS\u0026#39;)) table.put_item(Item={ \u0026#39;set_id\u0026#39;: request.get(\u0026#39;set_id\u0026#39;), \u0026#39;user_id\u0026#39;: request.get(\u0026#39;user_id\u0026#39;), \u0026#39;document_id\u0026#39;: s3_key, \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, \u0026#39;flashcards\u0026#39;: json.dumps(response_body[\u0026#39;flashcards\u0026#39;]), \u0026#39;total_cards\u0026#39;: response_body[\u0026#39;total_cards\u0026#39;], \u0026#39;page_count\u0026#39;: index_result[\u0026#39;page_count\u0026#39;], \u0026#39;chunk_count\u0026#39;: index_result[\u0026#39;chunk_count\u0026#39;], \u0026#39;created_at\u0026#39;: int(time.time()) }) if is_async: return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;OK\u0026#39;} return create_response(200, response_body) Titan Embeddings với Xử Lý Song Song:\nclass TitanEmbeddings: \u0026#34;\u0026#34;\u0026#34;Amazon Titan Text Embeddings V2 qua Bedrock với xử lý song song.\u0026#34;\u0026#34;\u0026#34; MODEL_ID = \u0026#34;amazon.titan-embed-text-v2:0\u0026#34; def __init__(self, region: str = None): self.region = region or os.environ.get(\u0026#39;BEDROCK_REGION\u0026#39;, \u0026#39;us-east-1\u0026#39;) self._client = None @property def client(self): if self._client is None: self._client = boto3.client(\u0026#39;bedrock-runtime\u0026#39;, region_name=self.region) return self._client def embed(self, text: str) -\u0026gt; List[float]: \u0026#34;\u0026#34;\u0026#34;Lấy embedding cho single text sử dụng Titan V2.\u0026#34;\u0026#34;\u0026#34; response = self.client.invoke_model( modelId=self.MODEL_ID, body=json.dumps({ \u0026#34;inputText\u0026#34;: text[:8000], # Độ dài input tối đa \u0026#34;dimensions\u0026#34;: 512, \u0026#34;normalize\u0026#34;: True }), contentType=\u0026#34;application/json\u0026#34;, accept=\u0026#34;application/json\u0026#34; ) result = json.loads(response[\u0026#39;body\u0026#39;].read()) return result[\u0026#39;embedding\u0026#39;] def embed_batch_parallel(self, texts: List[str], max_workers: int = 10) -\u0026gt; List[List[float]]: \u0026#34;\u0026#34;\u0026#34;Embed nhiều texts SONG SONG sử dụng ThreadPoolExecutor.\u0026#34;\u0026#34;\u0026#34; embeddings = [None] * len(texts) with ThreadPoolExecutor(max_workers=max_workers) as executor: futures = {executor.submit(self.embed, t): i for i, t in enumerate(texts)} for future in as_completed(futures): idx = futures[future] embeddings[idx] = future.result() return embeddings RAG Pipeline (In-Memory):\nimport math import fitz # PyMuPDF class RAG: \u0026#34;\u0026#34;\u0026#34;RAG nhẹ sử dụng Titan Embeddings + in-memory cosine similarity.\u0026#34;\u0026#34;\u0026#34; def __init__(self, api_key: str, chunk_size: int = 3000, chunk_overlap: int = 300): self.api_key = api_key self.chunk_size = chunk_size self.chunk_overlap = chunk_overlap self._chunks = [] self._embeddings = [] self._titan = TitanEmbeddings() self._keywords = [] def index_document(self, pdf_path: str, document_id: str = None) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Index PDF với Titan V2 embeddings (xử lý song song).\u0026#34;\u0026#34;\u0026#34; # Tải các trang PDF pages = [] with fitz.open(pdf_path) as doc: for page_num, page in enumerate(doc): text = page.get_text() if text.strip(): pages.append({\u0026#39;content\u0026#39;: text, \u0026#39;page\u0026#39;: page_num + 1}) # Chunk text với overlap self._chunks = [] for page in pages: chunks = self._chunk_text(page[\u0026#39;content\u0026#39;]) for chunk in chunks: self._chunks.append({ \u0026#39;text\u0026#39;: chunk, \u0026#39;page\u0026#39;: page[\u0026#39;page\u0026#39;] }) # Trích xuất keywords cho smart query generation all_text = \u0026#34; \u0026#34;.join([c[\u0026#39;text\u0026#39;] for c in self._chunks]) self._keywords = self._extract_keywords(all_text, top_n=20) # Tạo embeddings song song (10 Bedrock calls đồng thời) texts = [c[\u0026#39;text\u0026#39;] for c in self._chunks] self._embeddings = self._titan.embed_batch_parallel(texts, max_workers=10) return { \u0026#39;page_count\u0026#39;: len(pages), \u0026#39;chunk_count\u0026#39;: len(self._chunks), \u0026#39;keywords\u0026#39;: self._keywords[:10] } def _cosine_similarity(self, a: List[float], b: List[float]) -\u0026gt; float: \u0026#34;\u0026#34;\u0026#34;Tính cosine similarity giữa hai vectors.\u0026#34;\u0026#34;\u0026#34; dot_product = sum(x * y for x, y in zip(a, b)) norm_a = math.sqrt(sum(x * x for x in a)) norm_b = math.sqrt(sum(x * x for x in b)) if norm_a == 0 or norm_b == 0: return 0.0 return dot_product / (norm_a * norm_b) def similarity_search(self, query: str, top_k: int = 5) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Tìm kiếm chunks tương tự sử dụng in-memory cosine similarity.\u0026#34;\u0026#34;\u0026#34; query_embedding = self._titan.embed(query) # Tính similarities similarities = [] for i, embedding in enumerate(self._embeddings): score = self._cosine_similarity(query_embedding, embedding) similarities.append((i, score)) # Sắp xếp theo similarity (giảm dần) và trả về top-k similarities.sort(key=lambda x: x[1], reverse=True) results = [] for rank, (idx, score) in enumerate(similarities[:top_k]): chunk = self._chunks[idx] results.append({ \u0026#39;text\u0026#39;: chunk[\u0026#39;text\u0026#39;], \u0026#39;page\u0026#39;: chunk[\u0026#39;page\u0026#39;], \u0026#39;score\u0026#39;: score, \u0026#39;rank\u0026#39;: rank + 1 }) return results def generate_smart_queries(self, num_queries: int = 5) -\u0026gt; List[str]: \u0026#34;\u0026#34;\u0026#34;Tạo queries theo document sử dụng keywords đã trích xuất.\u0026#34;\u0026#34;\u0026#34; kw = self._keywords queries = [] if len(kw) \u0026gt;= 2: queries.append(f\u0026#34;definition and explanation of {kw[0]} and {kw[1]}\u0026#34;) if len(kw) \u0026gt;= 4: queries.append(f\u0026#34;key concepts about {kw[2]} {kw[3]}\u0026#34;) if len(kw) \u0026gt;= 6: queries.append(f\u0026#34;important information regarding {kw[4]} {kw[5]}\u0026#34;) return queries[:num_queries] def retrieve_with_smart_queries(self, top_k_per_query: int = 3) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Truy xuất chunks sử dụng nhiều smart queries cho coverage tốt hơn.\u0026#34;\u0026#34;\u0026#34; queries = self.generate_smart_queries() seen_texts = set() all_results = [] for query in queries: results = self.similarity_search(query, top_k=top_k_per_query) for r in results: if r[\u0026#39;text\u0026#39;] not in seen_texts: seen_texts.add(r[\u0026#39;text\u0026#39;]) all_results.append(r) return sorted(all_results, key=lambda x: x[\u0026#39;score\u0026#39;], reverse=True) def get_representative_chunks(self, num_chunks: int = 10) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Lấy chunks phân bố đều trong document.\u0026#34;\u0026#34;\u0026#34; if len(self._chunks) \u0026lt;= num_chunks: return [{\u0026#39;text\u0026#39;: c[\u0026#39;text\u0026#39;], \u0026#39;page\u0026#39;: c[\u0026#39;page\u0026#39;], \u0026#39;score\u0026#39;: 1.0} for c in self._chunks] step = len(self._chunks) // num_chunks return [{\u0026#39;text\u0026#39;: self._chunks[i * step][\u0026#39;text\u0026#39;], \u0026#39;page\u0026#39;: self._chunks[i * step][\u0026#39;page\u0026#39;], \u0026#39;score\u0026#39;: 1.0} for i in range(num_chunks)] Prompt Tạo Flashcard:\ndef generate_flashcards_prompt(chunks: List[Dict], num_cards: int, difficulty: str, question_types: List[str]) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Xây dựng prompt cho Gemini tạo flashcard.\u0026#34;\u0026#34;\u0026#34; context = \u0026#34;\\n\\n\u0026#34;.join([ f\u0026#34;[Chunk {i+1}] (Page {c.get(\u0026#39;page\u0026#39;, \u0026#39;?\u0026#39;)}):\\n{c[\u0026#39;text\u0026#39;]}\u0026#34; for i, c in enumerate(chunks) ]) return f\u0026#34;\u0026#34;\u0026#34;Based on the following document excerpts, generate {num_cards} flashcards. CONTEXT: {context} REQUIREMENTS: - Difficulty: {difficulty} - Generate exactly {num_cards} flashcards - Each flashcard should have a clear question and concise answer - Focus on key concepts, definitions, and important facts - Use these question types: {\u0026#34;, \u0026#34;.join(question_types)} OUTPUT FORMAT (JSON): {{ \u0026#34;flashcards\u0026#34;: [ {{ \u0026#34;question\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;answer\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;DEFINITION\u0026#34;, \u0026#34;difficulty\u0026#34;: \u0026#34;{difficulty}\u0026#34;, \u0026#34;source_chunk\u0026#34;: 1 }} ] }} Return ONLY valid JSON.\u0026#34;\u0026#34;\u0026#34; def call_gemini(prompt: str, api_key: str) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Gọi Gemini API để tạo flashcard.\u0026#34;\u0026#34;\u0026#34; import google.generativeai as genai genai.configure(api_key=api_key) model = genai.GenerativeModel( model_name=os.environ.get(\u0026#39;GEMINI_MODEL\u0026#39;, \u0026#39;gemini-2.0-flash\u0026#39;), generation_config={ \u0026#39;temperature\u0026#39;: 0.3, \u0026#39;max_output_tokens\u0026#39;: 4096 } ) response = model.generate_content(prompt) text = response.text # Trích xuất JSON nếu được wrap trong markdown if \u0026#39;```json\u0026#39; in text: text = text.split(\u0026#39;```json\u0026#39;)[1].split(\u0026#39;```\u0026#39;)[0] return json.loads(text.strip()) Lambda Function 4: S3 Upload Handler Tạo presigned URLs để upload file an toàn lên S3.\nCài Đặt Giá Trị Function name bandup-s3-upload Runtime Python 3.11 Memory 256 MB Timeout 30 giây Trigger API Gateway (sync) Triển Khai Chính:\nimport json import os import boto3 from datetime import datetime from typing import Dict, Any s3_client = boto3.client(\u0026#39;s3\u0026#39;) def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Tạo presigned URL cho S3 upload.\u0026#34;\u0026#34;\u0026#34; request = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) user_id = request.get(\u0026#39;user_id\u0026#39;) filename = request.get(\u0026#39;filename\u0026#39;) content_type = request.get(\u0026#39;content_type\u0026#39;, \u0026#39;application/octet-stream\u0026#39;) upload_type = request.get(\u0026#39;upload_type\u0026#39;, \u0026#39;general\u0026#39;) # Xác định bucket dựa trên upload type bucket_map = { \u0026#39;speaking_audio\u0026#39;: os.environ.get(\u0026#39;S3_BUCKET_AUDIO\u0026#39;), \u0026#39;flashcard_pdf\u0026#39;: os.environ.get(\u0026#39;S3_BUCKET_DOCUMENTS\u0026#39;), \u0026#39;writing_essay\u0026#39;: os.environ.get(\u0026#39;S3_BUCKET_DOCUMENTS\u0026#39;), } bucket = bucket_map.get(upload_type) # Tạo S3 key có tổ chức timestamp = datetime.now().strftime(\u0026#39;%Y%m%d_%H%M%S\u0026#39;) key = f\u0026#34;uploads/{upload_type}/{user_id}/{timestamp}_{filename}\u0026#34; # Tạo presigned PUT URL (hết hạn sau 15 phút) upload_url = s3_client.generate_presigned_url( \u0026#39;put_object\u0026#39;, Params={\u0026#39;Bucket\u0026#39;: bucket, \u0026#39;Key\u0026#39;: key, \u0026#39;ContentType\u0026#39;: content_type}, ExpiresIn=900 ) # Tạo presigned GET URL (hết hạn sau 1 giờ) get_url = s3_client.generate_presigned_url( \u0026#39;get_object\u0026#39;, Params={\u0026#39;Bucket\u0026#39;: bucket, \u0026#39;Key\u0026#39;: key}, ExpiresIn=3600 ) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: {\u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;}, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;upload_url\u0026#39;: upload_url, \u0026#39;get_url\u0026#39;: get_url, \u0026#39;file_url\u0026#39;: f\u0026#34;s3://{bucket}/{key}\u0026#34;, \u0026#39;expires_in\u0026#39;: 900 }) } Quản Lý Secrets An Toàn Tất cả Lambda functions sử dụng AWS Secrets Manager để lấy API keys:\n# secrets_helper.py (trong Lambda Layer) import boto3 import os from functools import lru_cache @lru_cache(maxsize=1) def get_gemini_api_key() -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Lấy Gemini API key từ Secrets Manager (có cache).\u0026#34;\u0026#34;\u0026#34; client = boto3.client(\u0026#39;secretsmanager\u0026#39;) secret_arn = os.environ.get(\u0026#39;GEMINI_API_KEY_SECRET_ARN\u0026#39;) response = client.get_secret_value(SecretId=secret_arn) return response[\u0026#39;SecretString\u0026#39;] Best Practices Bảo Mật:\nKhông bao giờ hardcode API keys trong Lambda code Sử dụng AWS Secrets Manager cho tất cả credentials nhạy cảm Rotate secrets định kỳ sử dụng automatic rotation Sử dụng IAM roles với least-privilege permissions IAM Role cho Lambda Functions { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;BedrockAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;bedrock:InvokeModel\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:bedrock:*:*:foundation-model/amazon.titan-embed-text-v2*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:Query\u0026#34;], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:dynamodb:*:*:table/bandup-evaluations\u0026#34;, \u0026#34;arn:aws:dynamodb:*:*:table/bandup-flashcard-sets\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;S3Access\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::bandup-*/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;SQSAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;sqs:ReceiveMessage\u0026#34;, \u0026#34;sqs:DeleteMessage\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sqs:*:*:bandup-*-queue\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;SecretsAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;secretsmanager:GetSecretValue\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:*:*:secret:bandup/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CloudWatchLogs\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:log-group:/aws/lambda/bandup-*\u0026#34; } ] } Bảng DynamoDB Các Lambda functions lưu kết quả vào hai bảng DynamoDB:\nBảng Sử Dụng Bởi Mục Đích bandup-evaluations Writing + Speaking Evaluators Lưu điểm band IELTS, feedback, transcripts bandup-flashcard-sets Flashcard Generator Lưu flashcards và document metadata Schema Bảng Evaluations (Writing \u0026amp; Speaking):\n# Sử dụng bởi Writing Evaluator table.put_item(Item={ \u0026#39;evaluation_id\u0026#39;: session_id, # Partition Key \u0026#39;user_id\u0026#39;: user_id, # Sort Key \u0026#39;evaluation_type\u0026#39;: \u0026#39;writing\u0026#39;, # \u0026#39;writing\u0026#39; hoặc \u0026#39;speaking\u0026#39; \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, \u0026#39;overall_band\u0026#39;: \u0026#39;7.0\u0026#39;, \u0026#39;task_achievement_band\u0026#39;: \u0026#39;7.0\u0026#39;, # Chỉ Writing \u0026#39;fluency_band\u0026#39;: \u0026#39;6.5\u0026#39;, # Chỉ Speaking \u0026#39;pronunciation_band\u0026#39;: \u0026#39;7.0\u0026#39;, # Chỉ Speaking \u0026#39;transcript\u0026#39;: \u0026#39;...\u0026#39;, # Chỉ Speaking \u0026#39;feedback\u0026#39;: json.dumps(feedback), \u0026#39;created_at\u0026#39;: timestamp }) Schema Bảng Flashcard Sets:\n# Sử dụng bởi Flashcard Generator table.put_item(Item={ \u0026#39;set_id\u0026#39;: set_id, # Partition Key \u0026#39;user_id\u0026#39;: user_id, # Sort Key \u0026#39;document_id\u0026#39;: document_id, \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, \u0026#39;flashcards\u0026#39;: json.dumps(flashcards), \u0026#39;total_cards\u0026#39;: 10, \u0026#39;page_count\u0026#39;: 5, \u0026#39;chunk_count\u0026#39;: 12, \u0026#39;created_at\u0026#39;: timestamp }) Biến Môi Trường Biến Mô Tả Ví Dụ GEMINI_API_KEY_SECRET_ARN Secrets Manager ARN arn:aws:secretsmanager:...:secret:bandup/gemini-api-key DYNAMODB_EVALUATIONS Bảng evaluations (Writing + Speaking) bandup-evaluations DYNAMODB_FLASHCARD_SETS Bảng flashcard sets bandup-flashcard-sets S3_BUCKET_AUDIO Audio bucket bandup-audio-bucket S3_BUCKET_DOCUMENTS Documents bucket bandup-documents-bucket BEDROCK_REGION Bedrock region cho Titan us-east-1 RAG_CHUNK_SIZE Chunk size cho RAG 3000 RAG_CHUNK_OVERLAP Chunk overlap 300 GEMINI_MODEL Tên Gemini model gemini-2.0-flash Deploy Lambda Functions # Đóng gói với dependencies cd rag_flashcard pip install -r requirements.txt -t package/ cp lambda_handler.py rag_pipeline.py package/ cd package \u0026amp;\u0026amp; zip -r ../function.zip . \u0026amp;\u0026amp; cd .. # Tạo Lambda function aws lambda create-function \\ --function-name bandup-flashcard-generator \\ --runtime python3.11 \\ --handler lambda_handler.lambda_handler \\ --role arn:aws:iam::${AWS_ACCOUNT_ID}:role/bandup-lambda-role \\ --timeout 600 \\ --memory-size 1024 \\ --zip-file fileb://function.zip \\ --environment Variables=\u0026#34;{ GEMINI_API_KEY_SECRET_ARN=arn:aws:secretsmanager:${AWS_REGION}:${AWS_ACCOUNT_ID}:secret:bandup/gemini-api-key, BEDROCK_REGION=us-east-1, RAG_CHUNK_SIZE=3000 }\u0026#34; # Thêm SQS trigger aws lambda create-event-source-mapping \\ --function-name bandup-flashcard-generator \\ --event-source-arn arn:aws:sqs:${AWS_REGION}:${AWS_ACCOUNT_ID}:bandup-flashcard-queue \\ --batch-size 1 Bước Tiếp Theo Tiến hành đến DynamoDB để cấu hình các bảng database.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Bài thu hoạch: AWS Cloud Mastery Series #2 — DevOps on AWS Mục đích của sự kiện Củng cố tư duy và nguyên tắc văn hóa DevOps (DevOps culture and principles). Giới thiệu chi tiết các dịch vụ AWS hỗ trợ CI/CD: CodeCommit, CodeBuild, CodeDeploy, CodePipeline. Đào sâu về Infrastructure as Code (IaC) với CloudFormation và AWS CDK. Khám phá dịch vụ Container (ECS, EKS, App Runner) và công cụ giám sát (CloudWatch, X-Ray). Nội dung nổi bật Sáng: CI/CD Pipeline \u0026amp; Infrastructure as Code (08:30 – 12:00) DevOps Mindset: nhấn mạnh các nguyên tắc cốt lõi và các chỉ số DORA (Deployment Frequency, MTTR\u0026hellip;). CI/CD Services: Source control: AWS CodeCommit và chiến lược Git (GitFlow vs. Trunk-based). Build \u0026amp; Test: AWS CodeBuild. Deployment: AWS CodeDeploy với các chiến lược Blue/Green, Canary, Rolling. Orchestration: tự động hóa luồng với AWS CodePipeline. Demo: walkthrough một CI/CD pipeline hoàn chỉnh. IaC: AWS CloudFormation: templates, stacks, drift detection. AWS CDK: constructs, reusable patterns, multi-language support. Demo \u0026amp; Discussion: triển khai bằng cả CloudFormation và CDK; thảo luận lựa chọn công cụ phù hợp. Chiều: Container, Observability \u0026amp; Best Practices (13:00 – 17:00) Container Services: Docker: cơ bản về containerization. Amazon ECR: lưu trữ, quét (scanning), quản lý lifecycle image. ECS \u0026amp; EKS: chiến lược triển khai, scaling, orchestration. App Runner: alternative PaaS for containers. Monitoring \u0026amp; Observability: AWS CloudWatch: metrics, logs, alarms, dashboards. AWS X-Ray: distributed tracing cho microservices. Best practices: Feature flags, A/B testing. Incident management và postmortems. Demo \u0026amp; Case study: so sánh chiến lược deploy cho microservices. Những gì học được DevOps Culture: nắm vững các chỉ số DORA và tư duy tự động hóa. CI/CD: hiểu cách các AWS Code services phối hợp; nắm các chiến lược deployment nâng cao (Blue/Green, Canary). IaC: có kiến thức nền tảng về CloudFormation và CDK — hữu ích để tối ưu template và kiến trúc multi-stack. Observability: tầm quan trọng của giám sát toàn diện bằng CloudWatch và X-Ray để debug lỗi (CORS, Lambda, v.v.). Container services (ECS/EKS) cung cấp định hướng cho kiến trúc phức tạp trong dự án. Phần demo CI/CD \u0026amp; IaC rất thực tế, giúp nhóm hiểu cách tối ưu hóa quá trình triển khai. Trải nghiệm trong event Workshop chi tiết, cung cấp nhiều kiến thức thực tiễn và áp dụng ngay. Phần demo và case study hữu ích cho việc áp dụng vào dự án. Cơ hội kết nối với cộng đồng và chuyên gia. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4 Theo kịp tiến độ học tập của nhóm về các dịch vụ AWS. Thành thạo thiết lập và cấu hình AWS Transit Gateway. Hiểu sâu về Amazon EC2 và các dịch vụ compute liên quan. Học Git cơ bản để hợp tác nhóm hiệu quả. Workshop: Bắt đầu VPC \u0026amp; Network Setup cho hạ tầng Bandup IELTS. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Khám phá AWS Transit Gateway: khái niệm, quy trình thiết lập và tài nguyên cần thiết.\n- So sánh sự khác biệt giữa VPC Peering và Transit Gateway.\n- Hoàn thành: Centralized Network Management with AWS Transit Gateway. 29/09/2025 30/09/2025 AWS Transit Gateway 3 - Nghiên cứu sâu về Amazon EC2 qua các bài giảng Module 3.\n- Học EC2 Auto Scaling cho quản lý tài nguyên tự động.\n- Hoàn thành: Scaling Applications with EC2 Auto Scaling. 01/10/2025 02/10/2025 FCJ Playlist 4 - Học và thực hành các lệnh Git (commit, push, pull) cho hợp tác nhóm.\n- Khám phá Amazon Lightsail cho các giải pháp compute đơn giản.\n- Hoàn thành: Simplified Computing with Amazon Lightsail. 03/10/2025 04/10/2025 Git Tutorial 5 - Đề xuất ý tưởng và phân công nhiệm vụ cho team để chuẩn bị proposal.\n- Nghiên cứu các chiến lược migration cho AWS.\n- Hoàn thành: VM Migration with AWS VM Import/Export.\n- Hoạt động Workshop: Tạo VPC với CIDR 10.0.0.0/16 và cấu hình DNS support. 05/10/2025 06/10/2025 Họp nhóm, Workshop 5.3 Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Centralized Network Management with AWS Transit Gateway Mạng ✅ Scaling Applications with EC2 Auto Scaling Compute ✅ Simplified Computing with Amazon Lightsail Compute ✅ Container Deployment with Amazon Lightsail Containers Containers ✅ VM Migration with AWS VM Import/Export Migration ✅ Database Migration with AWS DMS and SCT Migration ✅ Disaster Recovery with AWS Elastic Disaster Recovery Reliability ✅ Monitoring with Amazon CloudWatch Operations ✅ Kết quả đạt được tuần 4 Kỹ năng kỹ thuật đã tiếp thu:\nAWS Transit Gateway:\nThành thạo thiết lập và cấu hình Transit Gateway Hiểu các ưu điểm chính so với VPC Peering: Hỗ trợ topology multi-VPC phức tạp (mô hình hub-and-spoke) Cho phép transitive routing giữa các mạng được kết nối Đơn giản hóa quản lý mạng ở quy mô lớn Hỗ trợ VPN và Direct Connect attachments Học quản lý route table của Transit Gateway Amazon EC2 Deep Dive:\nHiểu toàn diện các tính năng chính của EC2: Elasticity: Scale tài nguyên lên/xuống theo nhu cầu Cấu hình linh hoạt: Nhiều instance types cho các workloads khác nhau Tối ưu chi phí: Mô hình On-Demand, Reserved, Spot instances Thành thạo EC2 Auto Scaling cho điều chỉnh tài nguyên tự động Hiểu Instance Store như block storage tạm thời cho EC2 Khám phá Amazon Lightsail như giải pháp đơn giản cho ứng dụng quy mô nhỏ Học về Lightsail Containers để triển khai container dễ dàng Dịch vụ Migration:\nHiểu AWS Application Migration Service (MGN) cho migration server Học VM Import/Export để migration máy ảo lên AWS Khám phá Database Migration Service (DMS) và Schema Conversion Tool (SCT) Nghiên cứu chiến lược disaster recovery với AWS Elastic Disaster Recovery DevOps và Monitoring:\nThành thạo các lệnh Git (commit, push, pull) và workflows nhóm Học CloudWatch cơ bản để monitor tài nguyên AWS Hợp tác nhóm:\nĐề xuất thành công ý tưởng và phân công nhiệm vụ cho proposal Team sẵn sàng bắt đầu giai đoạn implementation Thiết lập vai trò và trách nhiệm rõ ràng cho từng thành viên Tiến độ Workshop - VPC \u0026amp; Network Setup:\nTạo VPC với CIDR 10.0.0.0/16 trong region ap-southeast-1 Thiết kế kiến trúc subnet: Public subnets (10.0.1.0/24, 10.0.2.0/24) và Private subnets cho App (10.0.11.0/24, 10.0.12.0/24) và DB (10.0.21.0/24, 10.0.22.0/24) across hai AZs Cấu hình Internet Gateway cho public subnet internet access Thiết lập route tables cho proper traffic routing Bắt đầu cấu hình security groups cho multi-tier architecture Bài học chính:\nTransit Gateway thiết yếu cho quản lý kiến trúc multi-VPC phức tạp EC2 Auto Scaling đảm bảo ứng dụng xử lý được tải biến động hiệu quả Lightsail hoàn hảo cho workloads đơn giản mà không cần sự phức tạp của AWS Dịch vụ migration cung cấp nhiều đường dẫn để di chuyển workloads lên AWS Thiết kế VPC với public/private subnets riêng biệt cung cấp security isolation Triển khai Multi-AZ đảm bảo high availability từ network layer "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-setup-be/5.5.4-task/","title":"Tạo Service &amp; Task","tags":[],"description":"","content":"Trong bước cuối cùng của quá trình triển khai backend, chúng ta sẽ định nghĩa cấu hình chạy cho ứng dụng Spring Boot và khởi tạo nó dưới dạng một ECS Service ổn định.\n1. Tạo Task Definition Truy cập Amazon ECS \u0026gt; Task definitions \u0026gt; Create new task definition. Cấu hình Task definition: Family: bandup-backend. Launch type: AWS Fargate. OS/Architecture: Linux/X86_64. Task size: 1 vCPU và 2 GB Memory. Lưu ý: Ứng dụng Java (Spring Boot) thường yêu cầu nhiều bộ nhớ hơn Node.js để quản lý JVM heap hiệu quả. Task Role \u0026amp; Execution Role: Chọn ecsTaskExecutionRole. Chi tiết Container:\nName: bandup-be-container. Image URI: Nhập ECR URI (.../band-up-backend:v1.0.0). Container Port: 8080 (Cổng mặc định của Spring Boot). Cấu hình Biến môi trường (Thực hành tốt): Thay vì nhập thủ công các biến nhạy cảm (Database URL, Username, Password) dưới dạng văn bản thuần, chúng ta sẽ tải chúng từ một file bảo mật được lưu trữ trên S3.\nEnvironment files: Nhập S3 ARN của file .env (ví dụ: arn:aws:s3:::bandup2025-fcj/.env). Yêu cầu: Đảm bảo ecsTaskExecutionRole của bạn đã có quyền đọc (GetObjects) đối với file S3 này. 2. Tạo ECS Service Triển khai task definition vào cluster.\nTruy cập bandup-cluster \u0026gt; Services \u0026gt; Create. Cấu hình Deployment: Compute options: FARGATE. Family: bandup-backend (Chọn Revision mới nhất). Service name: bandup-backend-service. Desired tasks: 1. Mạng (Networking): VPC: band-up-vpc. Subnets: Chọn Private Subnets (private-subnet-1, private-subnet-2). Security group: Chọn ecs-backend-sg (Đã tạo ở bước 5.5.2). Cân bằng tải (Load Balancing): Load balancer: Chọn bandup-public-alb. Listener: Sử dụng listener có sẵn 80:HTTP. Target group: Tạo target group mới tên là target-bandup-be. Thông tin Container: Đảm bảo lưu lượng được chuyển đến cổng 8080. Nhấn Create. Dịch vụ sẽ tiến hành cấp phát tài nguyên Fargate, kéo image về, tải biến môi trường từ S3 và đăng ký container vào ALB. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-setup-fe/5.4.4-task/","title":"Tạo Task Definition &amp; Service","tags":[],"description":"","content":"Trong bước cuối cùng của phần triển khai Frontend, chúng ta sẽ định nghĩa cách ứng dụng chạy (Task Definition) và triển khai nó dưới dạng một dịch vụ (ECS Service) có khả năng mở rộng, được kết nối trực tiếp với Load Balancer.\n1. Tạo Task Definition Task Definition đóng vai trò như một bản thiết kế (blueprint) cho ứng dụng.\nTruy cập Amazon ECS \u0026gt; Task definitions \u0026gt; Create new task definition. Cấu hình Task definition: Task definition family: bandup-frontend. Launch type: AWS Fargate. OS/Architecture: Linux/X86_64. Task size: .5 vCPU và 1 GB Memory (Đủ cho ứng dụng Next.js). Task Role \u0026amp; Task Execution Role: Chọn ecsTaskExecutionRole (Đã tạo ở phần 5.3.3). Chi tiết Container: Name: bandup-fe-container. Image URI: Nhập ECR URI chúng ta đã push trước đó (ví dụ: .../band-up-frontend:v1.0.0). Container port: 3000. Nhấn Create. 2. Tạo ECS Service Bây giờ chúng ta sẽ triển khai bản thiết kế này vào Cluster.\nTruy cập Clusters \u0026gt; Chọn bandup-cluster. Tại tab Services, nhấn Create. Bước 1: Môi trường (Environment)\nCompute options: Launch type -\u0026gt; FARGATE. Task definition: bandup-frontend (Revision 1). Service name: bandup-frontend-service. Desired tasks: 1 (Số lượng container muốn chạy). Bước 2: Mạng (Networking)\nVPC: band-up-vpc. Subnets: Chọn các Private Subnets (private-subnet-1, private-subnet-2). Security group: Chọn ecs-private-sg (Cho phép traffic từ ALB). Bước 3: Cân bằng tải (Load Balancing)\nLoad balancer type: Application Load Balancer. Load balancer: Chọn bandup-public-alb. Container to load balance: bandup-fe-container 3000:3000. Listener: Chọn Create new listener tại Port 80 (HTTP). Target group: Chọn Use an existing target group -\u0026gt; target-bandup-fe. Nhấn Create. Dịch vụ sẽ bắt đầu triển khai container của bạn. Hãy đợi đến khi trạng thái chuyển sang Active và Task status là Running. 3. Kiểm tra kết quả Khi dịch vụ đã ổn định, hãy mở trình duyệt web và truy cập vào DNS name của Application Load Balancer.\nBạn sẽ thấy trang chủ của IELTS BandUp tải thành công, được phục vụ từ container nằm an toàn trong private subnet.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-network/5.3.4-endpoints/","title":"Thiết lập VPC Endpoints","tags":[],"description":"","content":"Để đảm bảo an toàn bảo mật, các dịch vụ backend chạy trong Private Subnet không nên truy cập các dịch vụ AWS quan trọng thông qua Internet công cộng. Thay vào đó, chúng ta sử dụng AWS PrivateLink (VPC Endpoints) để giữ lưu lượng này hoàn toàn bên trong mạng lưới của AWS.\nChúng ta sẽ tạo 4 Endpoints:\nInterface Endpoints: Cho ECR (Docker \u0026amp; API) và CloudWatch Logs. Gateway Endpoint: Cho Amazon S3. 1. Tạo Interface Endpoints (ECR \u0026amp; CloudWatch) Chúng ta sẽ bắt đầu tạo endpoint cho ECR Docker (ecr.dkr). Quy trình này hoàn toàn tương tự cho ECR API (ecr.api) và CloudWatch (logs).\nBước 1: Chọn dịch vụ\nTruy cập VPC Dashboard \u0026gt; Endpoints \u0026gt; Create endpoint. Name tag: ecr-endpoint (cho Docker). Service category: Chọn AWS services. Services: Tìm kiếm ecr.dkr và chọn com.amazonaws.ap-southeast-1.ecr.dkr. Bước 2: Cấu hình VPC \u0026amp; Subnets\nVPC: Chọn band-up-vpc. Subnets: Chọn các Availability Zone và tích chọn các Private Subnets (private-app-subnet-1 và private-app-subnet-2). Lưu ý: Bước này sẽ tạo các Network Interface (ENI) trong private subnet đóng vai trò là cổng kết nối. Bước 3: Chọn Security Group\nSecurity groups: Chọn Security Group cho phép lưu lượng HTTPS (Port 443) từ VPC của bạn. Trong workshop này, bạn có thể chọn default security group nếu nó cho phép inbound traffic từ nội bộ VPC. Nhấn Create endpoint. Bước 4: Lặp lại cho ECR API và CloudWatch Lặp lại các bước trên để tạo thêm 2 Interface Endpoints:\nECR API: Tìm kiếm ecr.api -\u0026gt; Đặt tên: ecr-api-endpoint. CloudWatch Logs: Tìm kiếm logs -\u0026gt; Đặt tên: cloudwatch-endpoint. 2. Tạo Gateway Endpoint (S3) Đối với Amazon S3, chúng ta sử dụng Gateway Endpoint. Loại này tiết kiệm chi phí hơn và sử dụng bảng định tuyến (Route Table) thay vì card mạng ảo.\nNhấn Create endpoint. Name tag: s3-endpoint. Services: Tìm kiếm s3 và chọn com.amazonaws.ap-southeast-1.s3 (Loại: Gateway). VPC: Chọn band-up-vpc. Route tables: Tích chọn các Route Table được liên kết với Private Subnets. Nhấn Create endpoint. 3. Kiểm tra kết quả Sau khi hoàn tất, quay lại danh sách Endpoints. Bạn sẽ thấy 4 endpoint đang hoạt động, đảm bảo kết nối bảo mật cho hạ tầng hệ thống.\necr-endpoint (Interface) ecr-api-endpoint (Interface) cloudwatch-endpoint (Interface) s3-endpoint (Gateway) "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-setup-fe/","title":"Triển khai Frontend (ECS Fargate)","tags":[],"description":"","content":"Tổng quan Trong phần này, chúng ta sẽ tiến hành triển khai Frontend của IELTS BandUp (ứng dụng Next.js) lên hạ tầng AWS Cloud.\nChúng ta sẽ sử dụng Amazon Elastic Container Service (ECS) với loại hình khởi chạy Fargate. Cách tiếp cận serverless này cho phép vận hành các container mà không cần quản lý các máy chủ EC2 vật lý bên dưới. Dịch vụ Frontend sẽ được đặt trong các Private Subnet để đảm bảo bảo mật, nhưng vẫn cho phép người dùng truy cập thông qua Application Load Balancer (ALB) đã cấu hình ở phần trước.\nCác bước thực hiện Để triển khai thành công Frontend, chúng ta sẽ tuân theo quy trình sau:\nContainer Registry (ECR): Tạo kho lưu trữ (repository) để chứa các Docker image và đẩy mã nguồn từ máy local lên AWS. Cấu hình Bảo mật (Security Group): Thiết lập các quy tắc tường lửa, đảm bảo Frontend container chỉ nhận lưu lượng truy cập từ ALB. ECS Task \u0026amp; Service: Thiết lập bản thiết kế (Task Definition) cho container (CPU, RAM, Biến môi trường) và khởi chạy nó dưới dạng một Service ổn định. Nội dung Đóng gói ứng dụng với Docker Thiết lập ECR \u0026amp; Đẩy Image Cấu hình Security Group Tạo Task Definition \u0026amp; Service "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":" Event 1: Kick-off Chương Trình The First Cloud Journey (FCJ) Thời gian tổ chức: 06/09/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Khởi động chương trình FCJ, kết nối các thành viên, giới thiệu lộ trình 12 tuần, hướng dẫn thành lập nhóm và bảo mật tài khoản AWS. Kết quả/Bài học: Hiểu rõ tầm quan trọng của kỷ luật, cam kết, quy trình lập nhóm, bảo mật tài khoản AWS và bắt đầu hành trình học tập với động lực rõ ràng. Event 2: DX Talk#7: Reinventing DevSecOps with AWS Generative AI Thời gian tổ chức: 16/10/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Khai thác chiến lược AI trong DevSecOps, phân tích case study từ CMC Global và AWS, giới thiệu các công cụ CI/CD, SAST/DAST và Amazon Q Developer. Kết quả/Bài học: Hiểu giải pháp tích hợp AI trong DevSecOps, ứng dụng các công cụ vào dự án thực tế, định hướng phát triển chuyên môn DevSecOps. Event 3: AWS Cloud Mastery Series #1 — AI/ML/GenAI on AWS Thời gian tổ chức: 15/11/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Tổng quan AI/ML tại Việt Nam, giới thiệu dịch vụ AI/ML của AWS, demo xây dựng chatbot GenAI với Bedrock. Kết quả/Bài học: Hiểu về SageMaker, Bedrock, ứng dụng AI/ML vào dự án, trải nghiệm live demo và kết nối chuyên gia. Event 4: AWS Cloud Mastery Series #2 — DevOps on AWS Thời gian tổ chức: 17/11/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Củng cố tư duy DevOps, giới thiệu dịch vụ CI/CD, IaC, Container, giám sát hệ thống, demo CI/CD pipeline và IaC. Kết quả/Bài học: Chiến lược deployment, kiến thức IaC, giám sát hệ thống, áp dụng thực tiễn vào dự án. Event 5: AWS Cloud Mastery Series #3 — Theo AWS Well-Architected Security Pillar Thời gian tổ chức: 29/11/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Giới thiệu Security Pillar, hướng dẫn 5 trụ cột bảo mật Cloud, best practices, playbook xử lý sự cố, demo IAM Identity Center, Secrets Manager. Kết quả/Bài học: Nắm nguyên tắc bảo mật, quản lý IAM nâng cao, bảo vệ dữ liệu, xây dựng playbook xử lý sự cố, định hướng học tiếp về bảo mật Cloud. Event 6: Vietnam Cloud Day HCMC Connect Edition Thời gian tổ chức: 18/09/2025 Địa điểm: Tầng 26, Tòa tháp Bitexco, 02 Đường Hải Triều, quận Sài Gòn, Thành Phố Hồ Chí Minh Vai trò: Người tham dự Nội dung chính: Track 1 — AI, Data \u0026amp; Infrastructure Modernization: Xây dựng Data Foundation cho AI, lộ trình Generative AI trên AWS, AI-Driven Development Lifecycle (AI-DLC), bảo mật cho GenAI và AI Agents. Kết quả/Bài học: Hiểu rõ cách thiết kế nền tảng dữ liệu cho AI, nhận diện các công cụ và dịch vụ hỗ trợ GenAI (ví dụ Bedrock), nắm các chiến lược bảo mật đặc thù cho GenAI và các cân nhắc kiến trúc (Serverless vs Container) cho dự án. Event 7: AI-Driven Development Life Cycle: Tái tưởng tượng Kỹ thuật Phần mềm Thời gian tổ chức: 18/09/2025 Địa điểm: Thành Phố Hồ Chí Minh / Online Vai trò: Người tham dự Nội dung chính: Giới thiệu AI-Driven Development Life Cycle (AI-DLC), một phương pháp chuyển đổi đặt AI làm cộng tác viên trung tâm trong toàn bộ quy trình phát triển phần mềm. Sự kiện bao gồm ba giai đoạn (Inception, Construction, Operations), thực thi do AI với giám sát con người, và giới thiệu Kiro—một AI-native IDE với phát triển dựa trên spec, hooks cho giám sát tự động, và đồng bộ hóa giữa specs và code. Kết quả/Bài học: Hiểu cách AI-DLC tái tưởng tượng kỹ thuật phần mềm bằng cách đặt AI ở trung tâm của phát triển, học về cấu trúc ba giai đoạn với sự cộng tác AI-con người, nhận ra tiềm năng cho chu kỳ phát triển chuyển từ tuần sang giờ/ngày, và hiểu biết về công cụ sẵn sàng sản xuất của Kiro kết nối prototyping và hệ thống sản xuất. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-ai-service/5.6.4-dynamodb/","title":"DynamoDB","tags":[],"description":"","content":"Tổng Quan Tạo hai bảng DynamoDB để lưu kết quả Lambda function:\nBảng Sử Dụng Bởi Mục Đích bandup-evaluations Writing + Speaking Evaluators Lưu điểm band IELTS, feedback, transcripts bandup-flashcard-sets Flashcard Generator Lưu flashcards và document metadata Bảng 1: Evaluations Table Lưu kết quả từ cả hai Lambda functions Writing Evaluator và Speaking Evaluator.\nCài Đặt Giá Trị Table name bandup-evaluations Partition key evaluation_id (String) Sort key user_id (String) Billing mode On-demand (PAY_PER_REQUEST) Schema Bảng:\nAttribute Type Mô Tả evaluation_id String Session ID duy nhất (PK) user_id String User identifier (SK) evaluation_type String writing hoặc speaking status String processing, completed, failed overall_band String Điểm band IELTS tổng (ví dụ: \u0026ldquo;7.0\u0026rdquo;) task_achievement_band String Chỉ Writing coherence_band String Chỉ Writing lexical_band String Cả Writing và Speaking grammar_band String Cả Writing và Speaking fluency_band String Chỉ Speaking pronunciation_band String Chỉ Speaking transcript String Chỉ Speaking - audio đã transcribe feedback String JSON-encoded detailed feedback model_used String AI model sử dụng để đánh giá created_at Number Unix timestamp Ví Dụ Item (Writing):\n{ \u0026#34;evaluation_id\u0026#34;: \u0026#34;eval-abc123\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user-456\u0026#34;, \u0026#34;evaluation_type\u0026#34;: \u0026#34;writing\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;completed\u0026#34;, \u0026#34;overall_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;task_achievement_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;coherence_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;lexical_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;grammar_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;feedback\u0026#34;: \u0026#34;{\\\u0026#34;strengths\\\u0026#34;:[...],\\\u0026#34;weaknesses\\\u0026#34;:[...]}\u0026#34;, \u0026#34;model_used\u0026#34;: \u0026#34;gemini-writing_task2\u0026#34;, \u0026#34;created_at\u0026#34;: 1733644800 } Ví Dụ Item (Speaking):\n{ \u0026#34;evaluation_id\u0026#34;: \u0026#34;speak-xyz789\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user-456\u0026#34;, \u0026#34;evaluation_type\u0026#34;: \u0026#34;speaking\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;completed\u0026#34;, \u0026#34;overall_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;fluency_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;lexical_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;grammar_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;pronunciation_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;transcript\u0026#34;: \u0026#34;Well, I\u0026#39;d like to talk about...\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;120.5\u0026#34;, \u0026#34;word_count\u0026#34;: 185, \u0026#34;feedback\u0026#34;: \u0026#34;{\\\u0026#34;fluency\\\u0026#34;:{...},\\\u0026#34;pronunciation\\\u0026#34;:{...}}\u0026#34;, \u0026#34;model_used\u0026#34;: \u0026#34;gemini-2.5-flash-audio\u0026#34;, \u0026#34;created_at\u0026#34;: 1733644800 } Bảng 2: Flashcard Sets Table Lưu kết quả từ Lambda function Flashcard Generator.\nCài Đặt Giá Trị Table name bandup-flashcard-sets Partition key set_id (String) Sort key user_id (String) Billing mode On-demand (PAY_PER_REQUEST) Schema Bảng:\nAttribute Type Mô Tả set_id String ID bộ flashcard duy nhất (PK) user_id String User identifier (SK) document_id String S3 key của tài liệu nguồn status String processing, completed, failed flashcards String JSON-encoded array của flashcards total_cards Number Số lượng flashcards được tạo page_count Number Số trang trong PDF nguồn chunk_count Number Số text chunks đã index created_at Number Unix timestamp Ví Dụ Item:\n{ \u0026#34;set_id\u0026#34;: \u0026#34;flashcard-set-123\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user-456\u0026#34;, \u0026#34;document_id\u0026#34;: \u0026#34;uploads/documents/user-456/vocab-guide.pdf\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;completed\u0026#34;, \u0026#34;flashcards\u0026#34;: \u0026#34;[{\\\u0026#34;question\\\u0026#34;:\\\u0026#34;What is...\\\u0026#34;,\\\u0026#34;answer\\\u0026#34;:\\\u0026#34;...\\\u0026#34;}]\u0026#34;, \u0026#34;total_cards\u0026#34;: 15, \u0026#34;page_count\u0026#34;: 8, \u0026#34;chunk_count\u0026#34;: 24, \u0026#34;created_at\u0026#34;: 1733644800 } Tạo Tables với AWS CLI # Tạo bảng evaluations (Writing + Speaking) aws dynamodb create-table \\ --table-name bandup-evaluations \\ --attribute-definitions \\ AttributeName=evaluation_id,AttributeType=S \\ AttributeName=user_id,AttributeType=S \\ --key-schema \\ AttributeName=evaluation_id,KeyType=HASH \\ AttributeName=user_id,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --tags Key=Project,Value=bandup Key=Environment,Value=production # Tạo bảng flashcard sets aws dynamodb create-table \\ --table-name bandup-flashcard-sets \\ --attribute-definitions \\ AttributeName=set_id,AttributeType=S \\ AttributeName=user_id,AttributeType=S \\ --key-schema \\ AttributeName=set_id,KeyType=HASH \\ AttributeName=user_id,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --tags Key=Project,Value=bandup Key=Environment,Value=production Bật Point-in-Time Recovery Bật PITR để bảo vệ dữ liệu:\n# Bật PITR cho bảng evaluations aws dynamodb update-continuous-backups \\ --table-name bandup-evaluations \\ --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true # Bật PITR cho bảng flashcard sets aws dynamodb update-continuous-backups \\ --table-name bandup-flashcard-sets \\ --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true Query Patterns Lấy lịch sử đánh giá của user:\nresponse = table.query( IndexName=\u0026#39;user_id-created_at-index\u0026#39;, # Nếu có GSI KeyConditionExpression=Key(\u0026#39;user_id\u0026#39;).eq(\u0026#39;user-456\u0026#39;), ScanIndexForward=False, # Mới nhất trước Limit=10 ) Lấy đánh giá cụ thể theo ID:\nresponse = table.get_item( Key={ \u0026#39;evaluation_id\u0026#39;: \u0026#39;eval-abc123\u0026#39;, \u0026#39;user_id\u0026#39;: \u0026#39;user-456\u0026#39; } ) Lấy flashcard sets của user:\nresponse = table.query( KeyConditionExpression=Key(\u0026#39;user_id\u0026#39;).eq(\u0026#39;user-456\u0026#39;), FilterExpression=Attr(\u0026#39;status\u0026#39;).eq(\u0026#39;completed\u0026#39;) ) Biến Môi Trường Lambda Cấu hình Lambda functions để sử dụng các bảng này:\nLambda Function Biến Môi Trường Giá Trị Writing Evaluator DYNAMODB_EVALUATIONS bandup-evaluations Speaking Evaluator DYNAMODB_EVALUATIONS bandup-evaluations Flashcard Generator DYNAMODB_FLASHCARD_SETS bandup-flashcard-sets IAM Policy cho Lambda Access { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:UpdateItem\u0026#34;, \u0026#34;dynamodb:Query\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:dynamodb:${AWS_REGION}:${AWS_ACCOUNT_ID}:table/bandup-evaluations\u0026#34;, \u0026#34;arn:aws:dynamodb:${AWS_REGION}:${AWS_ACCOUNT_ID}:table/bandup-flashcard-sets\u0026#34; ] } ] } Bước Tiếp Theo Tiến hành đến Bedrock Integration để cấu hình Amazon Titan Embeddings.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"Bài thu hoạch: AWS Cloud Mastery Series #3 — Theo AWS Well-Architected Security Pillar Mục đích của sự kiện Giới thiệu vai trò của Security Pillar trong AWS Well-Architected Framework. Hướng dẫn 5 trụ cột cốt lõi của bảo mật Cloud: Identity \u0026amp; Access Management, Detection, Infrastructure Protection, Data Protection và Incident Response. Cung cấp các best practices và kịch bản thực tế (Playbook) để bảo vệ ứng dụng trên Cloud. Nội dung nổi bật Pillar 1 — Identity \u0026amp; Access Management Nguyên tắc: Least Privilege, Zero Trust, Defense in Depth. IAM hiện đại: tránh long-term credentials, ưu tiên Roles và Policies. IAM Identity Center: SSO và quản lý Permission Sets. Bảo mật multi-account: SCP (Service Control Policies) và Permission Boundaries. Mini demo: validate IAM policy và mô phỏng quyền truy cập. Pillar 2 — Detection Giám sát liên tục: CloudTrail (org-level), GuardDuty, Security Hub. Logging ở mọi tầng: VPC Flow Logs, ALB/S3 logs. Tự động hóa cảnh báo: sử dụng EventBridge. Pillar 3 — Infrastructure Protection Bảo mật mạng: VPC segmentation (private vs public). Phòng thủ: Security Groups vs NACLs; dùng WAF, Shield, Network Firewall. Workload security: bảo mật EC2, ECS/EKS cơ bản. Pillar 4 — Data Protection Mã hóa: encryption at-rest \u0026amp; in-transit (S3, EBS, RDS, DynamoDB). Quản lý khóa và secrets: KMS, Secrets Manager, Parameter Store. Phân loại dữ liệu (data classification) và guardrails truy cập. Pillar 5 — Incident Response Vòng đời IR: quy trình xử lý sự cố theo AWS. IR playbook \u0026amp; automation. Kịch bản mẫu: compromised IAM key, S3 public exposure, EC2 malware detection. Tự động phản hồi bằng Lambda/Step Functions. Những gì học được Nắm được 5 trụ cột Security Pillar và nguyên tắc Shared Responsibility Model. IAM nâng cao: sử dụng IAM Identity Center, SCPs và tránh long-term credentials. Data security: tầm quan trọng của KMS và quản lý secrets. Incident Response: xây dựng playbook và tự động hóa phản hồi bằng serverless. Trải nghiệm trong event Buổi workshop là phần tổng kết của chuỗi, cung cấp kiến thức bảo mật trước khi hoàn thiện dự án. Phần trình bày về IAM Identity Center và Secrets Manager giúp giải quyết vấn đề xác thực Sub ID và quản lý khóa API của nhóm. Kịch bản IR (ví dụ S3 public exposure) rất hữu ích cho việc củng cố chính sách bảo mật dự án. Buổi Q\u0026amp;A giúp định hướng lộ trình học tiếp theo (Security Specialty). "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5 Xác định và giải quyết chi phí AWS bất thường trên tài khoản. Thiết kế và phân chia kiến trúc hạ tầng cho dự án. Bắt đầu cấu hình dự án ban đầu và phân bổ vai trò team. Khám phá AWS Skill Builder và nâng cao học tập về các chủ đề tối ưu hóa. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Phân tích và xác định nguyên nhân chi phí bất thường trên tài khoản AWS.\n- Hoàn thành: Cost and Usage Management và Managing Quotas with Service Quotas. 07/10/2025 08/10/2025 AWS Cost Explorer 3 - Thiết kế và phân chia kiến trúc hạ tầng dự án.\n- Đề xuất các template kiến trúc cơ bản cho team tham khảo.\n- Hoàn thành: Building Highly Available Web Applications. 09/10/2025 10/10/2025 FCJ Community 4 - Xây dựng code skeleton và cấu hình các file dự án ban đầu.\n- Thiết lập môi trường phát triển.\n- Hoàn thành: Development Environment with AWS Toolkit for VS Code. 11/10/2025 13/10/2025 VS Code + AWS Toolkit 5 - Đăng ký AWS Skill Builder và khám phá các khóa học.\n- Nghiên cứu kỹ thuật tối ưu EC2.\n- Hoàn thành: Right-Sizing with EC2 Resource Optimization. 11/10/2025 12/10/2025 AWS Skill Builder Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Cost and Usage Management Tối ưu chi phí ✅ Managing Quotas with Service Quotas Operations ✅ Billing Console Delegation Quản lý chi phí ✅ Right-Sizing with EC2 Resource Optimization Tối ưu chi phí ✅ Development Environment with AWS Toolkit for VS Code Phát triển ✅ Building Highly Available Web Applications Kiến trúc ✅ Database Essentials with Amazon RDS Database ✅ NoSQL Database Essentials with Amazon DynamoDB Database ✅ In-Memory Caching with Amazon ElastiCache Database ✅ Command Line Operations with AWS CLI Operations ✅ Kết quả đạt được tuần 5 Kỹ năng kỹ thuật đã tiếp thu:\nTối ưu chi phí:\nXác định nguyên nhân chi phí AWS bất thường: Xóa không hoàn toàn tài nguyên EC2 (EBS volumes, Elastic IPs) Thiếu kiểm soát tài khoản người dùng và IAM permissions Tài nguyên chạy ở các regions không sử dụng Học các best practices quản lý chi phí AWS: AWS Budgets để cảnh báo chi phí chủ động Cost Explorer để phân tích patterns chi tiêu Service Quotas để quản lý giới hạn tài khoản Billing Console Delegation cho visibility chi phí team Đề xuất các biện pháp tối ưu chi phí cho team Thiết kế kiến trúc:\nThiết kế thành công kiến trúc hạ tầng dự án Tạo các template kiến trúc tham khảo cho team áp dụng Áp dụng nguyên tắc High Availability: Triển khai Multi-AZ Chiến lược load balancing Patterns replication database Design patterns fault-tolerant Môi trường phát triển:\nThiết lập AWS Toolkit cho VS Code để phát triển streamlined Thành thạo AWS CLI cho command-line operations Xây dựng code skeleton vững chắc với các file cấu hình ban đầu Thiết lập nền tảng dự án cho hợp tác team Dịch vụ Database:\nHiểu Amazon RDS cho nhu cầu relational database Học DynamoDB cho NoSQL workloads Khám phá ElastiCache cho in-memory caching (Redis/Memcached) Áp dụng tiêu chí chọn database dựa trên use cases Tiến độ dự án:\nĐăng ký và kích hoạt tài khoản AWS Skill Builder Bắt đầu khám phá các khóa học nâng cao và learning paths Kiến trúc hạ tầng đã hoàn thiện và documented Môi trường phát triển đã cấu hình và sẵn sàng coding Bài học chính:\nTối ưu chi phí bắt đầu từ visibility - sử dụng Cost Explorer hàng ngày Right-sizing EC2 instances có thể giảm chi phí 30-50% High availability yêu cầu planning across multiple AZs AWS Toolkit cho VS Code cải thiện đáng kể developer productivity Chọn database phụ thuộc vào data model, scale, và access patterns Service Quotas ngăn ngừa các giới hạn capacity không mong muốn "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-setup-be/","title":"Triển khai Backend (ECS Fargate)","tags":[],"description":"","content":"Tổng quan Trong phần này, chúng ta sẽ triển khai IELTS BandUp Backend, một ứng dụng Spring Boot đóng vai trò là lớp xử lý logic cốt lõi của nền tảng.\nKhác với Frontend, Backend yêu cầu các cơ chế lưu trữ và bộ nhớ đệm (caching) để hoạt động hiệu quả. Do đó, trước khi khởi chạy các container trên ECS Fargate, chúng ta bắt buộc phải thiết lập hạ tầng dữ liệu (PostgreSQL và Redis). Dịch vụ Backend sẽ được đặt trong các Private Subnet, được bảo vệ nghiêm ngặt bởi Security Group và sẽ giao tiếp với các dịch vụ AI thông qua AWS SDK.\nCác bước thực hiện Để triển khai hệ thống backend hoàn chỉnh, chúng ta sẽ tuân theo trình tự sau:\nContainer Registry (ECR): Đóng gói ứng dụng Spring Boot và đẩy Docker image lên kho lưu trữ ECR riêng tư. Cơ sở dữ liệu quan hệ (RDS): Khởi tạo Amazon RDS for PostgreSQL để lưu trữ dữ liệu người dùng, kết quả bài thi và nội dung học tập. Bộ nhớ đệm (ElastiCache): Thiết lập cụm Amazon ElastiCache (Redis) để quản lý phiên đăng nhập (session) và tăng tốc độ truy xuất dữ liệu. ECS Task \u0026amp; Service: Định nghĩa cấu hình task (bao gồm các biến môi trường kết nối Database) và khởi chạy dịch vụ. Nội dung Thiết lập ECR \u0026amp; Đẩy Image Tạo PostgreSQL RDS Tạo ElastiCache (Redis) Tạo Service \u0026amp; Task "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Hệ Thống Tự Học IELTS - Workshop Hạ Tầng AWS Tổng Quan Workshop toàn diện này hướng dẫn bạn xây dựng hạ tầng AWS sẵn sàng cho production cho Hệ Thống Tự Học IELTS. Bạn sẽ học cách triển khai ứng dụng web có tính sẵn sàng cao, khả năng mở rộng và bảo mật sử dụng các dịch vụ AWS hiện đại và các phương pháp tốt nhất.\nKiến trúc triển khai theo mô hình active-passive Multi-AZ trên Amazon ECS, với lớp dịch vụ AI serverless cho việc đánh giá thông minh và tạo nội dung.\nNhững Gì Bạn Sẽ Xây Dựng Sau khi hoàn thành workshop này, bạn sẽ triển khai được:\nThành Phần Dịch Vụ AWS Mục Đích Lớp Mạng VPC, Subnets, NAT Gateway Hạ tầng mạng cô lập, bảo mật Nền Tảng Container ECS Fargate, ECR Điều phối container serverless Cân Bằng Tải ALB, Route 53, ACM Phân phối lưu lượng và SSL termination Lớp Dữ Liệu RDS PostgreSQL, ElastiCache, S3 CSDL quan hệ, caching, lưu trữ object Dịch Vụ AI API Gateway, SQS, Lambda, DynamoDB Pipeline xử lý AI serverless CI/CD CodePipeline, CodeBuild Pipeline triển khai tự động Bảo Mật IAM, Secrets Manager, WAF Quản lý danh tính và bảo vệ Giám Sát CloudWatch Logs, Alarms Quan sát và cảnh báo Điểm Nổi Bật Kiến Trúc Thiết Kế Tính Sẵn Sàng Cao:\nTriển khai Multi-AZ trên hai Availability Zones Failover active-passive cho ECS services RDS Multi-AZ với failover tự động Application Load Balancer với health checks Kiến Trúc AI Serverless:\nAPI Gateway cho các RESTful AI endpoints SQS cho xử lý message bất đồng bộ Lambda functions cho Writing Assessment, Speaking Assessment, và RAG-based Flashcard Generation DynamoDB để lưu trữ kết quả AI Tích hợp Amazon Bedrock cho các AI models (Gemma 3 12B, Titan Embeddings) Google Gemini API cho smart query generation Phương Pháp Bảo Mật Tốt Nhất:\nPrivate subnets cho application và database tiers Security groups với least-privilege access AWS WAF cho application-level protection Secrets Manager cho quản lý credentials IAM roles với quyền tối thiểu cần thiết Điều Kiện Tiên Quyết Trước khi bắt đầu workshop này, hãy đảm bảo bạn có:\nTài khoản AWS với quyền phù hợp AWS CLI đã cài đặt và cấu hình Hiểu biết cơ bản về các dịch vụ AWS (VPC, EC2, ECS) Docker đã cài đặt locally cho container builds Git cho version control Thời Gian Hoàn Thành Phần Thời Gian Ước Tính Điều kiện tiên quyết 15 phút VPC \u0026amp; Network Setup 30 phút ECS \u0026amp; Container Setup 45 phút Load Balancer Configuration 30 phút Database \u0026amp; Storage Setup 45 phút AI Service Architecture 60 phút CI/CD Pipeline 30 phút Security \u0026amp; IAM 30 phút Monitoring Setup 20 phút Tổng ~5 giờ Nội Dung Tổng Quan Workshop Điều Kiện Tiên Quyết VPC \u0026amp; Network Setup ECS \u0026amp; Container Setup Load Balancer Configuration Database \u0026amp; Storage Setup AI Service Architecture CI/CD Pipeline Security \u0026amp; IAM Monitoring \u0026amp; Logging Clean Up "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-ai-service/5.6.5-bedrock-integration/","title":"Bedrock Integration","tags":[],"description":"","content":"Tổng Quan Cấu hình Amazon Bedrock cho AI model access bao gồm Gemma 3 12B và Titan Embeddings.\nEnable Model Access Điều hướng đến Amazon Bedrock → Model access Request access đến: Amazon Titan Text Express (cho assessments) Amazon Titan Embeddings V2 (cho RAG) Meta Llama 3 hoặc Anthropic Claude (optional) Test Bedrock API import boto3 import json bedrock = boto3.client(\u0026#39;bedrock-runtime\u0026#39;, region_name=\u0026#39;ap-southeast-1\u0026#39;) # Test Titan Text response = bedrock.invoke_model( modelId=\u0026#39;amazon.titan-text-express-v1\u0026#39;, body=json.dumps({ \u0026#39;inputText\u0026#39;: \u0026#39;Hello, how are you?\u0026#39;, \u0026#39;textGenerationConfig\u0026#39;: { \u0026#39;maxTokenCount\u0026#39;: 100, \u0026#39;temperature\u0026#39;: 0.7 } }) ) print(json.loads(response[\u0026#39;body\u0026#39;].read())) Titan Embeddings cho RAG # Generate embeddings response = bedrock.invoke_model( modelId=\u0026#39;amazon.titan-embed-text-v2:0\u0026#39;, body=json.dumps({ \u0026#39;inputText\u0026#39;: \u0026#39;Document chunk text here\u0026#39; }) ) embedding = json.loads(response[\u0026#39;body\u0026#39;].read())[\u0026#39;embedding\u0026#39;] # Lưu trong OpenSearch hoặc dùng cho similarity search Google Gemini Integration Cho smart query generation:\nimport google.generativeai as genai genai.configure(api_key=os.environ[\u0026#39;GEMINI_API_KEY\u0026#39;]) model = genai.GenerativeModel(\u0026#39;gemini-2.5-flash\u0026#39;) response = model.generate_content( f\u0026#34;\u0026#34;\u0026#34;Analyze this document and generate 10 intelligent questions: {document_text} \u0026#34;\u0026#34;\u0026#34; ) Tối Ưu Chi Phí Sử dụng Titan Text Express cho assessments (lower cost) Batch embeddings generation khi có thể Implement caching cho repeated queries Sử dụng Google Gemini free tier cho query generation Bước Tiếp Theo Tiến hành đến CI/CD Pipeline.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6 Nắm vững các dịch vụ lưu trữ AWS cơ bản và use cases của chúng. Nâng cao kỹ năng lập trình Python thông qua các bài tập thực hành. Thiết kế và hoàn thiện kiến trúc hạ tầng dự án. Tham gia webinar \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; để khám phá thực hành DevSecOps và Amazon Q Developer. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu Amazon S3 cơ bản: Kiến trúc Bucket, đảm bảo độ bền, và khả năng host static website.\n- Khám phá S3 Storage Classes (Standard, Standard-IA) và Amazon Glacier cho giải pháp cold storage.\n- Hoàn thành: Static Website Hosting with Amazon S3. 14/10/2025 15/10/2025 AWS S3 Documentation 3 - Học các loại AWS Storage Gateway (File, Volume, Tape Gateway) và patterns tích hợp.\n- Hiểu Object Lifecycle Management policies để tối ưu chi phí.\n- Thực hành Python cơ bản: data structures, functions, và error handling.\n- Tham gia webinar: \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; với sự góp mặt của anh Hoàng Kha. 16/10/2025 17/10/2025 AWS Storage Gateway\nAWS Events 4 - Nghiên cứu khái niệm disaster recovery: RTO, RPO, và các chiến lược Backup \u0026amp; Restore.\n- Khám phá dịch vụ AWS Backup cho quản lý backup tập trung.\n- Thực hành: Tạo S3 buckets, upload files, cấu hình static website hosting, và test lifecycle policies.\n- Nghiên cứu phương pháp DevSecOps: CI/CD pipelines, SAST/DAST tools, Infrastructure as Code. 18/10/2025 19/10/2025 AWS Backup 5 - Hoàn thiện sơ đồ kiến trúc hạ tầng dự án với các mối quan hệ component chi tiết.\n- Tái cấu trúc code skeleton để phù hợp với thiết kế kiến trúc đã cập nhật.\n- Chuẩn hóa lựa chọn ngôn ngữ lập trình và framework cho tính nhất quán của team.\n- Khám phá khả năng Amazon Q Developer: AI-powered code generation, testing, và vulnerability scanning. 20/10/2025 21/10/2025 Amazon Q Developer Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Static Website Hosting with Amazon S3 Lưu trữ ✅ Data Protection with AWS Backup Reliability ✅ Content Delivery with Amazon CloudFront Mạng ✅ Kết quả đạt được tuần 6 Thành thạo Dịch vụ Lưu trữ:\nHiểu toàn diện về kiến trúc Amazon S3: Buckets, độ bền (99.999999999%), và static website hosting Nắm vững S3 Storage Classes: Standard, Standard-IA, Glacier cho các access patterns khác nhau Học patterns tích hợp AWS Storage Gateway cho hybrid cloud storage Hiểu Object Lifecycle Management cho automated data tiering và tối ưu chi phí Disaster Recovery \u0026amp; Backup:\nNắm bắt fundamentals disaster recovery: RTO (Recovery Time Objective) và RPO (Recovery Point Objective) Học dịch vụ AWS Backup cho quản lý backup tập trung across services Hiểu các chiến lược Backup \u0026amp; Restore cho business continuity Kỹ năng Phát triển:\nNâng cao lập trình Python thông qua các bài tập thực hành Tạo thành công S3 buckets, cấu hình static websites, và test lifecycle policies Cải thiện hiểu biết về data structures và error handling Lập kế hoạch Dự án:\nHoàn thiện sơ đồ kiến trúc hạ tầng toàn diện Tái cấu trúc code skeleton với cấu trúc thư mục phù hợp Chuẩn hóa technology stack cho hợp tác team Insights DevSecOps:\nTham gia webinar \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; (16/10/2025) Học tích hợp DevSecOps: Security trong SDLC sử dụng Jenkins (CI/CD), SonarQube (SAST), OWASP ZAP (DAST), Terraform (IaC) Khám phá Amazon Q Developer: AI assistant cho code generation, testing, vulnerability scanning, và AWS optimization Bài học chính:\nS3 là nền tảng cho object storage trên AWS - hiểu storage classes là cực kỳ quan trọng cho tối ưu chi phí Lifecycle policies tự động hóa quản lý dữ liệu và giảm chi phí lưu trữ đáng kể AWS Backup cung cấp quản lý backup thống nhất across multiple AWS services DevSecOps tích hợp security xuyên suốt development lifecycle, không phải là afterthought "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.6-event6/","title":"Event 6","tags":[],"description":"","content":"Bài thu hoạch — Vietnam Cloud Day HCMC Connect Edition Mục Đích của Sự Kiện Cung cấp tầm nhìn chiến lược về Chuyển đổi số (Digital Transformation) và vai trò của Cloud trong việc hiện đại hóa hạ tầng.\nTập trung vào Track 1: AI, Data \u0026amp; Infrastructure Modernization — giới thiệu phương pháp và dịch vụ AWS để xây dựng nền tảng dữ liệu và AI.\nTạo cơ hội kết nối và học hỏi từ các chuyên gia hàng đầu trong ngành Cloud.\nDanh Sách Diễn Giả (phiên buổi chiều) Jun Kai Loke — AI/ML Specialist SA, AWS\nKien Nguyen — Solutions Architect, AWS\nTamelly Lim — Storage Specialist SA, AWS\nBinh Tran — Senior Solutions Architect, AWS\nTaiki Dang — Solutions Architect, AWS\nMichael Armentano — Principal WW GTM Specialist, AWS\nNội Dung Nổi Bật (Track 1 — Phiên Buổi Chiều) Xây dựng Nền tảng Dữ liệu Thống nhất cho AI và Analytics\nChủ đề: Building a Unified Data Foundation on AWS for AI and Analytics Workloads\nNội dung: Chiến lược và best practices để xây dựng nền tảng dữ liệu thống nhất, có khả năng mở rộng trên AWS — bao gồm Data Ingestion, Storage, Processing và Governance.\nĐịnh hướng và Tương lai của Generative AI (GenAI) trên AWS\nChủ đề: Building the Future: Gen AI Adoption and Roadmap on AWS\nNội dung: Tầm nhìn, xu hướng và lộ trình chiến lược của AWS cho việc áp dụng Generative AI; các dịch vụ hỗ trợ đổi mới bằng GenAI.\nAI-Driven Development Lifecycle (AI-DLC)\nChủ đề: AI-Driven Development Lifecycle (AI-DLC) — Shaping the future of Software Implementation\nNội dung: Giới thiệu AI-DLC — tích hợp AI làm trung tâm trong vòng đời phát triển phần mềm để cải thiện tốc độ, chất lượng và đổi mới.\nBảo mật Ứng dụng Generative AI\nChủ đề: Securing Generative AI Applications with AWS: Fundamentals and Best Practices\nNội dung: Thách thức bảo mật ở mọi tầng GenAI stack; chiến lược mã hóa, kiến trúc zero-trust, giám sát liên tục và kiểm soát truy cập chi tiết.\nAI Agents: Công cụ nhân bội năng suất\nChủ đề: Beyond Automation: AI Agents as Your Ultimate Productivity Multipliers\nNội dung: Vai trò AI Agents như đối tác thông minh tự học, thích ứng và thực thi các tác vụ phức tạp để tăng năng suất.\nNhững Gì Học Được / Giá trị rút ra AI / Data Foundation: Hiểu cách xây dựng Data Foundation để chuẩn bị dữ liệu cho AI, bao gồm dịch vụ lưu trữ và xử lý.\nTầm nhìn GenAI: Nắm được lộ trình GenAI của AWS và các dịch vụ cốt lõi như Bedrock.\nAI-Driven Development: Nhận ra tiềm năng tích hợp AI trong SDLC để tăng tốc độ và chất lượng phát triển.\nBảo mật GenAI: Học các chiến lược bảo mật cho GenAI stack (zero-trust, encryption, fine-grained access control).\nNetwork Modernization: Kiến thức về Transit Gateway và đơn giản hóa Network Topology, hữu ích cho lab VPC Peering đã thực hiện.\nCompute Decision: Tiêu chí lựa chọn giữa Serverless và Container — giúp hiểu lý do nhóm chọn Serverless (SAM).\nTrải nghiệm trong event Kiến thức tiên tiến: Tiếp cận trực tiếp chuyên gia về GenAI và AI-DLC, cập nhật xu hướng mới.\nTính ứng dụng cao: Phiên về Data Foundation và Securing GenAI có thể áp dụng trực tiếp vào dự án (luồng xử lý ảnh AI, bảo mật dữ liệu).\nNăng lượng và truyền cảm hứng: Sự kiện tạo động lực, giúp hiểu rõ nhu cầu thị trường và tiềm năng phát triển trong lĩnh vực Cloud.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-ai-service/","title":"AI Service Architecture","tags":[],"description":"","content":"Tổng Quan Phần này bao gồm kiến trúc serverless AI service sử dụng API Gateway, SQS, Lambda, DynamoDB, và Amazon Bedrock cho intelligent assessment và content generation.\nKiến Trúc AI Service AI service triển khai theo mô hình fully serverless:\nUser → API Gateway → SQS Queue → Lambda → AI Model → DynamoDB → Response Ba Lambda Functions:\nFunction Mục Đích AI Model Writing Evaluate IELTS writing assessment Gemma 3 12B / Gemini Speaking Evaluate Audio transcription + assessment Transcribe + Gemma 3 12B Flashcard Generate RAG-based flashcard creation Titan Embeddings + Gemini Nội Dung API Gateway SQS Queues Lambda Functions DynamoDB Bedrock Integration Request Flow User submits request (writing sample, audio, document) API Gateway validates và enqueues message đến SQS SQS triggers appropriate Lambda function Lambda processes với AI model (Bedrock/Gemini) Results stored trong DynamoDB User retrieves results qua API Thời Gian Ước Tính: ~60 phút Ước Tính Chi Phí Tóm Tắt Chi Phí Hàng Tháng:\nChi Phí Ban Đầu Chi Phí Hàng Tháng Tổng Chi Phí 12 Tháng Tiền Tệ $0.00 $23.61 $283.32 USD Lưu ý: Bao gồm chi phí ban đầu\nChi Tiết Phân Tích Chi Phí:\nDịch Vụ Mô Tả Khu Vực Chi Phí Hàng Tháng (USD) Chi Phí Hàng Năm (USD) AWS Lambda Writing Evaluator Asia Pacific (Singapore) $0.00 $0.00 AWS Lambda Speaking Evaluator Asia Pacific (Singapore) $0.00 $0.00 AWS Lambda Evaluation Status Asia Pacific (Singapore) $0.00 $0.00 AWS Lambda S3 Upload Asia Pacific (Singapore) $0.00 $0.00 Amazon API Gateway HTTP API Asia Pacific (Singapore) $0.42 $5.04 S3 Standard Audio bucket Asia Pacific (Singapore) $0.51 $6.12 S3 Standard Documents Bucket Asia Pacific (Singapore) $0.53 $6.36 DynamoDB Evaluations Table Asia Pacific (Singapore) $0.37 $4.44 DynamoDB Flashcard Sets Table Asia Pacific (Singapore) $0.52 $6.24 Amazon SQS Writing/Speaking/Flashcard queues Asia Pacific (Singapore) $0.00 $0.00 AWS Secrets Manager Secrets management Asia Pacific (Singapore) $0.45 $5.40 Amazon CloudWatch RAG Lambda logs Asia Pacific (Singapore) $0.01 $0.08 Amazon Bedrock Bedrock inference US East (N. Virginia) $0.50 $6.00 OpenAI GPT inference US East (N. Virginia) $20.30 $243.65 Tổng Cộng $23.61 $283.32 AWS Pricing Calculator chỉ cung cấp ước tính về phí AWS của bạn và không bao gồm bất kỳ loại thuế nào có thể áp dụng. Phí thực tế của bạn phụ thuộc vào nhiều yếu tố, bao gồm việc sử dụng thực tế các dịch vụ AWS của bạn.\nXem chi tiết phân tích chi phí: AWS Pricing Calculator\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Tổng Quan Thực Tập Trong suốt thời gian thực tập tại Amazon Web Services (AWS) từ 08/09 đến 09/12/2024, tôi đã có cơ hội quý báu để học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường điện toán đám mây thực tế.\nTôi đã tham gia xây dựng Nền tảng Học IELTS Bandup - một ứng dụng AI toàn diện giúp học sinh chuẩn bị cho kỳ thi IELTS thông qua đánh giá Writing và Speaking tự động, cũng như tạo Flashcard thông minh từ tài liệu học tập.\nThành Tựu Chính Qua dự án này, tôi đã phát triển và cải thiện các kỹ năng:\nKiến Trúc Cloud \u0026amp; Dịch Vụ AWS:\nThiết kế và triển khai kiến trúc serverless có khả năng mở rộng sử dụng AWS Lambda, API Gateway và SQS Cấu hình mạng VPC với public/private subnets, NAT Gateway và Security Groups Thiết lập điều phối container với Amazon ECS và Fargate Quản lý lưu trữ dữ liệu với Amazon S3, DynamoDB và ElastiCache (Redis) Tích hợp dịch vụ AI bao gồm Amazon Bedrock (Titan Embeddings) và Google Gemini API Phát Triển \u0026amp; DevOps:\nXây dựng Lambda functions bằng Python cho đánh giá AI Triển khai pipeline RAG (Retrieval-Augmented Generation) cho tạo flashcard Thiết lập CI/CD pipelines với GitLab và AWS CodePipeline Thực hành nguyên tắc Infrastructure as Code Tích Hợp AI/ML:\nTích hợp Google Gemini API cho xử lý audio gốc (tiết kiệm 72% chi phí so với phương pháp truyền thống) Triển khai Amazon Titan Text Embeddings V2 cho tìm kiếm vector similarity Thiết kế chiến lược prompt engineering cho chấm điểm band IELTS Tác Phong Làm Việc Trong suốt thời gian thực tập, tôi luôn cố gắng:\nHoàn thành nhiệm vụ được giao với chất lượng cao và chú ý đến chi tiết Tuân thủ chính sách công ty và AWS best practices về bảo mật và tối ưu chi phí Tích cực giao tiếp với mentors và thành viên nhóm để cải thiện hiệu quả công việc Ghi chép công việc kỹ lưỡng để chuyển giao kiến thức Tiêu Chí Tự Đánh Giá Để phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết các dịch vụ AWS, áp dụng nguyên tắc kiến trúc cloud, thành thạo công cụ phát triển ✅ ☐ ☐ 2 Khả năng học hỏi Học nhanh các dịch vụ AWS mới, công nghệ AI và thực hành phát triển ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu giải pháp, nghiên cứu tài liệu mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành Lambda functions, documentation và deployments đúng hạn với chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ lịch trình, coding standards và quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback về code reviews và quyết định kiến trúc ✅ ☐ ☐ 7 Giao tiếp Trình bày giải pháp kỹ thuật, viết documentation và báo cáo tiến độ rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Phối hợp hiệu quả với mentors và tham gia thảo luận nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, tuân thủ AWS security best practices, duy trì tính chuyên nghiệp ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Debug Lambda functions, tối ưu chi phí (tiết kiệm 72% cho xử lý audio), tìm giải pháp sáng tạo ✅ ☐ ☐ 11 Đóng góp vào dự án/tổ chức Hoàn thành 4 Lambda functions, documentation toàn diện và demo hoạt động ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Kiến Thức Thu Được Kỹ Năng Kỹ Thuật:\nHiểu sâu về kiến trúc serverless AWS Kinh nghiệm tích hợp AI/ML trong hệ thống production Thành thạo Python cho phát triển Lambda function Kiến thức về RAG pipelines và vector embeddings Kỹ Năng Mềm:\nViết tài liệu kỹ thuật Phân tích vấn đề và debug có hệ thống Chiến lược tối ưu chi phí cloud Làm việc trong môi trường doanh nghiệp Cần Cải Thiện Kỷ luật: Nâng cao quản lý thời gian và tuân thủ nghiêm ngặt lịch họp và deadline Giao tiếp: Cải thiện kỹ năng trình bày kỹ thuật và khả năng giải thích khái niệm phức tạp cho người không chuyên Giải quyết vấn đề: Phát triển phương pháp có cấu trúc hơn để debug và troubleshooting Networking: Xây dựng quan hệ chuyên nghiệp mạnh mẽ hơn trong cộng đồng AWS Lời Cảm Ơn Tôi xin bày tỏ lòng biết ơn chân thành đến:\nCác mentors tại AWS vì sự hướng dẫn và kiên nhẫn Team đã hỗ trợ và hợp tác AWS đã cung cấp cơ hội học tập tuyệt vời này Kỳ thực tập này là trải nghiệm có ý nghĩa chuyển đổi, đã nâng cao đáng kể kỹ năng của tôi về điện toán đám mây và tích hợp AI. Tôi tin tưởng rằng kiến thức và kinh nghiệm thu được sẽ có giá trị trong sự nghiệp tương lai của mình.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.7-event7/","title":"Event 7","tags":[],"description":"","content":"AI-Driven Development Life Cycle: Tái tưởng tượng Kỹ thuật Phần mềm Mục Đích của Sự Kiện Giới thiệu AI-Driven Development Life Cycle (AI-DLC), một phương pháp tiếp cận chuyển đổi trong phát triển phần mềm, đặt AI làm cộng tác viên trung tâm trong toàn bộ quy trình phát triển phần mềm. Phương pháp này nhằm chuyển đổi phát triển phần mềm bằng cách tận dụng AI để xử lý các tác vụ thường ngày trong khi vẫn duy trì sự giám sát của con người, cuối cùng giải phóng các nhà phát triển để tập trung vào giải quyết vấn đề quan trọng và các giải pháp sáng tạo. Giới thiệu Kiro, một AI IDE giúp nhà phát triển chuyển từ ý tưởng đến sản xuất thông qua trải nghiệm nhà phát triển đơn giản hóa khi làm việc với các AI agent. Kiro rất giỏi trong \u0026lsquo;vibe coding\u0026rsquo; nhưng vượt xa hơn thế—điểm mạnh của Kiro là đưa các nguyên mẫu đó vào hệ thống sản xuất với các tính năng như specs và hooks. Danh Sách Diễn Giả Toan Huynh My Nguyen Nội Dung Nổi Bật Phần 1: AI-Driven Development Life Cycle (AI-DLC) Triết lý Cốt lõi Thực thi do AI với Giám sát Con người: AI-DLC đề xuất một điểm giữa giữa phát triển \u0026ldquo;AI-assisted\u0026rdquo; (cải thiện các tác vụ cụ thể) và phát triển \u0026ldquo;AI-autonomous\u0026rdquo; (cố gắng loại bỏ con người hoàn toàn). Mô hình Tinh thần: AI khởi tạo các quy trình làm việc bằng cách tạo kế hoạch, tìm kiếm làm rõ, và triển khai giải pháp. Con người tập trung vào cung cấp ngữ cảnh, xác thực kế hoạch, và đưa ra quyết định quan trọng. Cộng tác Nhóm Động: Các tác vụ thường ngày được chuyển giao cho AI, cho phép các nhóm con người tập trung vào giải quyết vấn đề sáng tạo và ra quyết định nhanh chóng trong không gian cộng tác. Ba Giai đoạn của AI-DLC Phương pháp này tái cấu trúc Software Development Life Cycle (SDLC) truyền thống thành ba giai đoạn tương tác cao:\nInception (Mob Elaboration):\nAI chuyển đổi ý định kinh doanh thành các yêu cầu chi tiết và user stories. Toàn bộ nhóm tích cực xác thực các đề xuất của AI và trả lời các câu hỏi làm rõ để đảm bảo phù hợp với mục tiêu kinh doanh. Construction (Mob Construction):\nAI đề xuất kiến trúc logic, mô hình domain, giải pháp code, và tests. Nhóm cung cấp phản hồi thời gian thực về các quyết định kỹ thuật và lựa chọn kiến trúc. Operations:\nAI sử dụng ngữ cảnh tích lũy để quản lý infrastructure-as-code và deployments. Con người cung cấp giám sát để đảm bảo bảo mật và ổn định. Lợi ích Chính Tốc độ: Chu kỳ phát triển chuyển từ tuần sang \u0026ldquo;bolts\u0026rdquo; (giờ hoặc ngày). Chất lượng: Làm rõ liên tục đảm bảo sản phẩm phù hợp với ý định kinh doanh, trong khi AI thực thi các tiêu chuẩn tổ chức (bảo mật, design patterns). Giữ lại Ngữ cảnh: AI duy trì ngữ cảnh liên tục qua tất cả các giai đoạn, đảm bảo không có kiến thức nào bị mất giữa lập kế hoạch và coding. Phần 2: Kiro – IDE Agentic cho AI-DLC Kiro là một Integrated Development Environment (IDE) AI-native mới được thiết kế để kết nối khoảng cách giữa \u0026ldquo;vibe coding\u0026rdquo; (prototyping) và xây dựng phần mềm sẵn sàng sản xuất. Nó tạo ra các công cụ cần thiết để triển khai các phương pháp như AI-DLC.\nKhái niệm Cốt lõi: Phát triển dựa trên Spec Kiro giải quyết vấn đề \u0026ldquo;black box\u0026rdquo; của AI coding nơi các mô hình đưa ra các giả định không được ghi chép. Nó buộc một cách tiếp cận có cấu trúc nơi AI xây dựng dựa trên các đặc tả rõ ràng (\u0026ldquo;specs\u0026rdquo;) thay vì các prompt mơ hồ.\nTính năng Chính Specs (The \u0026ldquo;Brain\u0026rdquo;):\nTạo Yêu cầu: Kiro mở rộng một prompt đơn thành các user stories chi tiết với tiêu chí chấp nhận (sử dụng ký hiệu EARS). Thiết kế Kỹ thuật: Nó phân tích codebase để tạo sơ đồ luồng dữ liệu, TypeScript interfaces, và database schemas trước khi viết code. Triển khai Tác vụ: Nó chia nhỏ phát triển thành các tác vụ có trình tự (với dependencies, unit tests, và yêu cầu accessibility) để con người phê duyệt. Hooks (The \u0026ldquo;Guardian\u0026rdquo;):\nTự động hóa theo sự kiện hoạt động như một nhà phát triển cấp cao đang quan sát bạn. Ví dụ: Tự động cập nhật tests khi một component được lưu, làm mới READMEs khi APIs thay đổi, hoặc quét rò rỉ bảo mật trước khi commit. Hooks thực thi tính nhất quán và tiêu chuẩn coding của toàn nhóm một cách tự động. Đồng bộ hóa: Kiro giữ specs và code đồng bộ. Nếu code thay đổi, Kiro có thể cập nhật specs, ngăn chặn documentation drift.\nTương thích \u0026amp; Hệ sinh thái Tương thích VS Code: Được xây dựng trên Code OSS, cho phép các nhà phát triển giữ các cài đặt và extensions hiện có của họ. Model Context Protocol (MCP): Hỗ trợ kết nối các công cụ chuyên biệt và nhà cung cấp ngữ cảnh. Những Gì Học Được / Giá trị rút ra Phương pháp AI-DLC Cách tiếp cận Chuyển đổi: Hiểu cách AI-DLC tái tưởng tượng kỹ thuật phần mềm bằng cách đặt AI ở trung tâm của quy trình phát triển thay vì chỉ coi nó như một trợ lý. Cấu trúc Ba Giai đoạn: Học cách phương pháp này tái cấu trúc SDLC thành các giai đoạn Inception, Construction, và Operations với sự cộng tác AI-con người ở mỗi giai đoạn. Tốc độ và Chất lượng: Nhận ra tiềm năng cho chu kỳ phát triển chuyển từ tuần sang giờ/ngày trong khi vẫn duy trì chất lượng thông qua làm rõ liên tục và các tiêu chuẩn được AI thực thi. Giữ lại Ngữ cảnh: Đánh giá cao cách AI duy trì ngữ cảnh liên tục qua tất cả các giai đoạn, đảm bảo không có kiến thức nào bị mất giữa lập kế hoạch và coding. Kiro IDE Phát triển dựa trên Spec: Hiểu cách Kiro giải quyết vấn đề \u0026ldquo;black box\u0026rdquo; bằng cách buộc AI xây dựng dựa trên các đặc tả rõ ràng thay vì các prompt mơ hồ. Công cụ Sẵn sàng Sản xuất: Học cách Kiro kết nối khoảng cách giữa prototyping (\u0026ldquo;vibe coding\u0026rdquo;) và phần mềm sẵn sàng sản xuất thông qua các tính năng như specs và hooks. Giám sát Tự động: Nhận ra cách hooks hoạt động như các guardian tự động, thực thi tính nhất quán và tiêu chuẩn coding của toàn nhóm. Tích hợp Hệ sinh thái: Đánh giá cao khả năng tương thích của Kiro với VS Code và hỗ trợ Model Context Protocol (MCP). Kết nối giữa AI-DLC và Kiro Phương pháp và Công cụ: Hiểu rằng trong khi AI-DLC là phương pháp (cách thức và lý do tổ chức nhóm và quy trình làm việc xung quanh AI), Kiro là một công cụ (cái gì) cho phép sự thay đổi này. Vận hành hóa: Nhận ra cách tính năng \u0026ldquo;Specs\u0026rdquo; của Kiro vận hành hóa các giai đoạn \u0026ldquo;Inception\u0026rdquo; và \u0026ldquo;Construction\u0026rdquo; của AI-DLC bằng cách buộc AI lập kế hoạch và tìm kiếm xác thực trước khi thực thi, trong khi \u0026ldquo;Hooks\u0026rdquo; tự động hóa sự giám sát cần thiết trong giai đoạn \u0026ldquo;Operations\u0026rdquo;. Trải nghiệm trong event Sự kiện cung cấp một giới thiệu toàn diện về tương lai của kỹ thuật phần mềm thông qua AI-DLC và Kiro:\nPhương pháp Cách mạng Thay đổi Mô hình: Bài trình bày đã chứng minh rõ ràng cách AI-DLC đại diện cho một sự thay đổi cơ bản từ phát triển AI-assisted truyền thống sang một mô hình cộng tác nơi AI và con người làm việc như một nhóm thống nhất. Cấu trúc Thực tế: Cách tiếp cận ba giai đoạn (Inception, Construction, Operations) cung cấp một khung rõ ràng để hiểu cách AI có thể được tích hợp trong toàn bộ vòng đời phát triển. Công cụ Đổi mới Tập trung Sản xuất: Sự nhấn mạnh của Kiro về việc vượt ra ngoài prototyping đến các hệ thống sẵn sàng sản xuất đặc biệt có giá trị, giải quyết một khoảng trống phổ biến trong các công cụ AI coding. Cách tiếp cận dựa trên Spec: Khái niệm phát triển dựa trên spec cộng hưởng mạnh mẽ, vì nó giải quyết vấn đề quan trọng của AI đưa ra các giả định không được ghi chép. Ứng dụng Thực tế Cộng tác Nhóm: Sự nhấn mạnh về cộng tác nhóm động và chuyển giao các tác vụ thường ngày cho AI trong khi vẫn duy trì sự giám sát của con người cung cấp những hiểu biết thực tế để cải thiện quy trình làm việc phát triển. Đảm bảo Chất lượng: Sự tích hợp của hooks cho giám sát tự động và đồng bộ hóa giữa specs và code đã chứng minh cách AI có thể thực thi các tiêu chuẩn trong khi vẫn duy trì tính linh hoạt. Kết luận Sự kiện đã thành công giới thiệu cả tầm nhìn chiến lược (AI-DLC) và công cụ thực tế (Kiro) cần thiết để chuyển đổi phát triển phần mềm. Sự kết hợp của phương pháp và triển khai cung cấp một con đường rõ ràng phía trước cho các nhóm muốn tận dụng AI trong khi vẫn duy trì kiểm soát và tiêu chuẩn chất lượng của con người.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7 Tập trung ôn tập toàn diện và củng cố kiến thức chuẩn bị cho kỳ thi giữa kỳ. Luyện tập các bài lab và câu hỏi trắc nghiệm trên các nền tảng AWS Builders và AWSboy để làm quen với format đề thi. Hệ thống hóa các dịch vụ AWS cơ bản đã học: EC2, S3, VPC, IAM, RDS, Lambda, DynamoDB. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Hệ thống hóa kiến thức dịch vụ Compute (EC2, Lambda). - Thực hành: Hoàn thành bài tập/lab về tạo, cấu hình, quản lý vòng đời của EC2 Instances. - Ôn tập tạo Lambda function, triggers, và execution models. 22/10/2024 22/10/2024 AWS Builders, AWSboy 3 - Ôn tập kiến thức dịch vụ Storage (S3, EBS, EFS). - Thực hành: Hoàn thành bài tập về S3 storage classes (Standard, IA, Glacier), EBS volume types, và EFS use cases. - Thực hành S3 bucket policies và access control. 23/10/2024 23/10/2024 AWS Builders, AWSboy 4 - Củng cố kiến thức về Networking (VPC, Subnets, Route Tables, Internet Gateway, Security Groups, NACLs). - Thực hành: Luyện tập câu hỏi về cấu hình VPC, Security Group rules vs NACL rules, và routing principles. - Ôn tập VPC Peering và Transit Gateway concepts. 24/10/2024 24/10/2024 AWS Builders, AWSboy 5 - Ôn tập Database services (RDS, DynamoDB) và Security/Identity (IAM). - Thực hành: Tập trung vào các khái niệm IAM Policies, IAM Roles, và IAM Users cơ bản. - Thực hành thiết kế DynamoDB table và cấu hình RDS instance. 25/10/2024 25/10/2024 AWS Builders, AWSboy 6 - Tổng kết và Luyện đề: Làm các bài thi thử toàn diện trên nền tảng AWS Builders và AWSboy. - Rà soát các lĩnh vực yếu được xác định trong bài thi thử để nghiên cứu thêm. - Tạo ghi chú tóm tắt để tham khảo nhanh trước kỳ thi. 26/10/2024 26/10/2024 AWS Builders, AWSboy Kết quả đạt được tuần 7 Hoàn thành ôn tập toàn diện các nhóm dịch vụ AWS cơ bản: Compute, Storage, Networking, Database, Security (IAM). Luyện tập thành công nhiều labs và câu hỏi trắc nghiệm trên các nền tảng AWS Builders và AWSboy. Nắm vững các thông số cơ bản của EC2 (Instance Types, AMI, EBS volumes) và hoạt động của S3 (Storage Classes, Object/Bucket management). Hiểu rõ mối quan hệ và cấu hình của các thành phần trong VPC (Public/Private Subnets, Routing, Security Groups vs NACLs). Tự tin hơn với kiến thức đã học, sẵn sàng cho kỳ thi giữa kỳ sắp tới. Tạo ghi chú học tập toàn diện bao gồm tất cả các danh mục dịch vụ AWS chính. Xác định và giải quyết các khoảng trống kiến thức thông qua các phiên thực hành có mục tiêu. Bài học chính:\nSecurity Groups là stateful (return traffic tự động được phép), NACLs là stateless (cần rules hai chiều) EC2 instance types được tối ưu cho các workloads khác nhau (compute, memory, storage, GPU) S3 storage classes cân bằng chi phí vs. tần suất truy cập IAM policies tuân theo nguyên tắc explicit deny - policy hạn chế nhất thắng VPC routing tuân theo nguyên tắc most specific route match "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" Phần này chia sẻ trải nghiệm cá nhân và phản hồi của tôi khi tham gia chương trình First Cloud Journey (FCJ) tại AWS, hy vọng sẽ giúp team FCJ tiếp tục cải thiện chương trình cho các thực tập sinh tương lai.\nĐánh Giá Chung 1. Môi trường làm việc\nMôi trường làm việc tại AWS vượt xa mong đợi của tôi. Văn phòng hiện đại, trang bị đầy đủ và được thiết kế để tối ưu năng suất. Điều ấn tượng nhất là văn hóa cởi mở nơi mọi người, bất kể cấp bậc, đều dễ tiếp cận và sẵn sàng hỗ trợ. Sự linh hoạt làm việc từ xa/hybrid cũng rất được đánh giá cao, cho phép tôi cân bằng việc học và phát triển hiệu quả.\nTeam FCJ tạo ra bầu không khí hỗ trợ nơi việc đặt câu hỏi được khuyến khích, không bị đánh giá. Được truy cập tài nguyên và dịch vụ AWS để thực hành là vô giá - tôi có thể thử nghiệm với hạ tầng cloud thực thay vì chỉ đọc tài liệu.\n2. Sự hỗ trợ của Mentor / Team Admin\nSự hướng dẫn tôi nhận được là xuất sắc. Mentor không chỉ đưa ra câu trả lời - họ hướng dẫn tôi qua quá trình giải quyết vấn đề, giúp tôi phát triển kỹ năng tư duy phản biện cho các quyết định kiến trúc cloud. Những điểm nổi bật:\nBuổi 1:1 hàng tuần để review tiến độ và giải quyết thách thức Code review với phản hồi xây dựng giúp cải thiện coding practices Thảo luận kiến trúc giúp tôi hiểu \u0026ldquo;tại sao\u0026rdquo; đằng sau các quyết định thiết kế Hướng dẫn nghề nghiệp về AWS certifications và các hướng phát triển cloud engineering Team admin xử lý hiệu quả mọi công việc hậu cần - từ account access đến resource provisioning - để tôi có thể tập trung hoàn toàn vào học và xây dựng.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nDự án Bandup IELTS hoàn toàn phù hợp với nền tảng khoa học máy tính của tôi đồng thời đẩy tôi vào những lĩnh vực mới:\nKiến Thức Học Thuật Áp Dụng Kỹ Năng Mới Học Được Lập trình Python AWS Lambda \u0026amp; Serverless architecture Cấu trúc dữ liệu \u0026amp; thuật toán RAG pipelines \u0026amp; Vector embeddings Cơ sở dữ liệu DynamoDB \u0026amp; ElastiCache Mạng máy tính cơ bản VPC, Subnets, Security Groups Kỹ thuật phần mềm CI/CD, Infrastructure as Code Dự án thách thức tôi tích hợp các dịch vụ AI (Gemini API, Titan Embeddings) vào hệ thống production-ready - điều vượt xa các bài tập trên lớp.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nChương trình FCJ cung cấp cơ hội học tập xuất sắc:\nKinh nghiệm AWS thực tế với 15+ dịch vụ (Lambda, API Gateway, SQS, DynamoDB, S3, ECS, Fargate, Bedrock, v.v.) Sở hữu dự án thực - Tôi không chỉ làm task nhỏ; tôi xây dựng Lambda functions hoàn chỉnh từ đầu Kỹ năng tối ưu chi phí - Học cách đạt được tiết kiệm 72% thông qua quyết định kiến trúc thông minh Thực hành documentation - Tạo hướng dẫn workshop toàn diện này như một tài liệu chia sẻ kiến thức Tiếp xúc AI/ML - Tích hợp các AI models tiên tiến cho ứng dụng thực tế Việc tự học kết hợp với hướng dẫn của mentor tạo ra sự cân bằng hoàn hảo cho phát triển kỹ năng.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa customer obsession và ownership của AWS thể hiện rõ ràng trong suốt kỳ thực tập:\nCác thành viên trong team thực sự quan tâm đến việc giúp tôi thành công Thất bại được coi là cơ hội học hỏi, không phải chỉ trích Đổi mới được khuyến khích - đề xuất của tôi về Gemini native audio (tiết kiệm 72% chi phí) được hoan nghênh và triển khai Tư duy \u0026ldquo;Day 1\u0026rdquo; giữ cho mọi người luôn có động lực và hướng về tương lai Tôi cảm thấy như một người đóng góp có giá trị, không chỉ là \u0026ldquo;thực tập sinh.\u0026rdquo; Công việc của tôi có ý nghĩa, và điều đó tạo ra sự khác biệt lớn trong sự gắn kết và động lực của tôi.\n6. Chính sách / phúc lợi cho thực tập sinh\nChương trình FCJ cung cấp hỗ trợ tuyệt vời:\n✅ Phụ cấp thực tập cạnh tranh ✅ Giờ làm việc linh hoạt phù hợp lịch học sinh viên ✅ Truy cập tài nguyên đào tạo AWS và certifications ✅ Tech talks nội bộ và các buổi học ✅ Cơ hội networking với các chuyên gia AWS ✅ Kinh nghiệm dự án thực để xây dựng portfolio Câu Hỏi Phản Ánh Điều tôi thấy hài lòng nhất trong kỳ thực tập?\nXây dựng thứ gì đó thực sự hoạt động. Nhìn thấy nền tảng Bandup đánh giá bài luận IELTS và tạo flashcards bằng AI - biết rằng tôi đã xây dựng những Lambda functions đó - mang lại cho tôi sự hài lòng to lớn. Khoảnh khắc Speaking Evaluator xử lý thành công audio qua Gemini là điểm nhấn mà tôi sẽ không bao giờ quên.\nĐiều gì có thể cải thiện cho thực tập sinh tương lai?\nTruy cập AWS account sớm hơn - Có quyền truy cập đầy đủ từ ngày 1 sẽ đẩy nhanh quá trình học Onboarding có cấu trúc hơn - Checklist các khái niệm AWS \u0026ldquo;cần biết\u0026rdquo; sẽ giúp thực tập sinh mới làm quen nhanh hơn Hợp tác giữa các thực tập sinh - Ghép cặp thực tập sinh trong các dự án bổ sung có thể nâng cao học tập Tiếp xúc nhiều hơn với các team khác - Cơ hội shadowing với các team AWS khác sẽ mở rộng góc nhìn Tôi có khuyên bạn bè thực tập ở đây không?\nChắc chắn có. Đối với bất kỳ ai quan tâm đến cloud computing, chương trình FCJ tại AWS là không thể sánh bằng. Bạn được:\nKinh nghiệm thực hành với các dịch vụ cloud hàng đầu Mentorship từ các chuyên gia giàu kinh nghiệm Sở hữu và chịu trách nhiệm dự án thực Kỹ năng được đánh giá cao trên thị trường lao động Điều kiện tiên quyết duy nhất là sự sẵn sàng học hỏi và làm việc chăm chỉ.\nĐề Xuất \u0026amp; Mong Muốn Tương Lai Đề xuất để cải thiện trải nghiệm thực tập:\nTạo hub tài nguyên cho thực tập sinh - Tài liệu, tutorials và FAQs tập trung cho các thách thức thường gặp Buổi demo hai tuần một lần - Thực tập sinh trình bày công việc cho team rộng hơn để nhận feedback và visibility Hỗ trợ AWS certification - Vouchers hoặc study groups cho kỳ thi Cloud Practitioner/Solutions Architect Mạng lưới alumni - Kết nối thực tập sinh hiện tại với cựu FCJ để tư vấn nghề nghiệp Tôi có muốn tiếp tục với chương trình này không?\nCó! Tôi muốn:\nQuay lại làm cloud engineer chính thức sau khi tốt nghiệp Mentor cho các thực tập sinh FCJ tương lai, trả lại sự hướng dẫn tôi đã nhận được Tiếp tục đóng góp cho workshops và documentation FCJ Suy nghĩ cuối cùng:\nKỳ thực tập này đã thay đổi hiểu biết của tôi về cloud computing và tích hợp AI. Tôi đến với kiến thức lập trình cơ bản; tôi rời đi với khả năng thiết kế và triển khai kiến trúc serverless có khả năng mở rộng. Team FCJ không chỉ dạy tôi AWS - họ cho tôi thấy ý nghĩa của việc trở thành một kỹ sư chuyên nghiệp.\nCảm ơn AWS và team FCJ vì cơ hội tuyệt vời này. 🙏\n\u0026ldquo;Cách tốt nhất để học là xây dựng. Cách tốt nhất để phát triển là được thử thách. FCJ cung cấp cả hai.\u0026rdquo;\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.7-cicd-pipeline/","title":"CI/CD với CodeBuild &amp; CodePipeline","tags":[],"description":"","content":"Quy trình CI/CD với AWS CodeBuild \u0026amp; CodePipeline Tài liệu này hướng dẫn triển khai quy trình CI/CD dùng AWS CodePipeline và CodeBuild với GitLab làm SCM. Khi tạo một Release mới trong repository GitLab, CodePipeline sẽ được kích hoạt, CodeBuild chạy hai dự án frontend và backend dựa trên frontend-buildspec.yml và backend-buildspec.yml hiện có, sau đó CodePipeline deploy lên ECS.\nBạn sẽ làm gì 5.3.1 – Cấu hình dự án CodeBuild (frontend/backend) và trigger theo Release GitLab 5.3.2 – Thiết kế CodePipeline để deploy ECS và tích hợp artifact sau build Điều kiện tiên quyết Quyền IAM cho CodeBuild, CodePipeline, S3, Secrets Manager (nếu dùng token GitLab) và IAM pass role. Ứng dụng mẫu có buildspec.yml (chúng tôi sẽ cung cấp mẫu tối thiểu trong bước). S3 bucket cho artifact của pipeline (trình hướng dẫn CodePipeline sẽ tạo/chọn giúp bạn). Sơ đồ tổng quan Luồng chính: Tag push từ GitLab -\u0026gt; API Gateway/Lambda -\u0026gt; upload archive lên S3 -\u0026gt; CodePipeline (S3 Source) kích hoạt -\u0026gt; CodeBuild build -\u0026gt; (Tùy chọn) Deploy.\nĐặt sơ đồ tại: static/images/5-Workshop/5.3-S3-vpc/ci-overview.png.\nMẹo: Dùng đường dẫn ảnh tuyệt đối /images/... và lưu screenshot trong static/images/5-Workshop/5.3-S3-vpc/.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8 Hoàn thành kỳ thi giữa kỳ (Ngày 31/10) với kết quả tốt. Bắt đầu triển khai các chức năng CRUD (Create, Read, Update, Delete) nền tảng cho dự án Bandup IELTS. Nghiên cứu và lập kế hoạch tích hợp dịch vụ AWS Serverless (Lambda, API Gateway, DynamoDB) cho kiến trúc dự án. Thiết lập môi trường phát triển và xây dựng cấu trúc dự án. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn tập tổng hợp lần cuối kiến thức chuẩn bị cho kỳ thi giữa kỳ. - Rà soát các câu hỏi khó và các khái niệm thường bị nhầm lẫn (IAM Policies vs Roles, Security Groups vs NACLs, VPC routing). - Thực hành quản lý thời gian cho việc hoàn thành bài thi. 28/10/2024 28/10/2024 Ghi chú cá nhân, AWS Builders 3 - Chuẩn bị tâm lý và thiết lập công cụ cho kỳ thi. - Thực hành: Bắt đầu thiết lập môi trường phát triển cho dự án Bandup IELTS. - Cài đặt và cấu hình Python development tools, AWS CLI, và IDE setup. 29/10/2024 30/10/2024 AWS CLI Documentation 4 - Thi giữa kỳ (Ngày 31/10) - Hoàn thành mục tiêu quan trọng nhất. - Phản ánh sau kỳ thi về hiệu suất và các lĩnh vực cần cải thiện. 31/10/2024 31/10/2024 Địa điểm thi 5 - Bắt đầu triển khai chức năng CRUD cơ bản đầu tiên (Create operation: tạo flashcard sets). - Nghiên cứu và triển khai thử nghiệm AWS Lambda functions cho serverless compute. - Nghiên cứu thiết kế DynamoDB table để lưu trữ dữ liệu flashcard. 01/11/2024 01/11/2024 Tài liệu AWS Lambda \u0026amp; DynamoDB 6 - Lập kế hoạch tích hợp kiến trúc Serverless: + Nghiên cứu API Gateway cho RESTful API endpoints. + Thiết kế luồng dữ liệu: Frontend → API Gateway → Lambda → DynamoDB. + Định nghĩa cấu trúc Lambda function và event handling patterns. - Triển khai chức năng Read cơ bản để truy xuất flashcard sets từ DynamoDB. 02/11/2024 02/11/2024 Tài liệu API Gateway, Serverless patterns Kết quả đạt được tuần 8 Hoàn thành kỳ thi giữa kỳ (Ngày 31/10) thành công. Thiết lập thành công môi trường phát triển cơ bản cho dự án với Python, AWS CLI, và cấu hình IDE. Bắt đầu xây dựng chức năng Create/Read đầu tiên cho dự án Bandup IELTS sử dụng AWS Lambda và DynamoDB. Nghiên cứu và thiết kế serverless architecture pattern: API Gateway cho HTTP endpoints Lambda functions cho business logic DynamoDB cho NoSQL data storage Củng cố kiến thức về các dịch vụ Serverless thiết yếu (Lambda, DynamoDB, API Gateway) quan trọng cho phát triển dự án. Tạo cấu trúc dự án ban đầu với tổ chức thư mục phù hợp. Triển khai Lambda function handler đầu tiên cho Create operation. Bài học chính:\nKiến trúc Serverless loại bỏ overhead quản lý server Lambda functions là event-driven và scale tự động DynamoDB cung cấp độ trễ millisecond đơn cho NoSQL workloads API Gateway hoạt động như entry point cho serverless APIs Cấu trúc dự án phù hợp ngay từ đầu đơn giản hóa phát triển tương lai "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.8-cleanup/","title":"Dọn Dẹp Tài Nguyên","tags":[],"description":"","content":"Tổng Quan Phần này hướng dẫn bạn dọn dẹp tất cả tài nguyên AWS đã tạo trong workshop này để tránh các khoản phí phát sinh. Thực hiện theo thứ tự các bước vì một số tài nguyên phụ thuộc vào tài nguyên khác.\nQuan trọng: Việc xóa tài nguyên không thể hoàn tác. Hãy đảm bảo bạn đã sao lưu bất kỳ dữ liệu nào cần thiết trước khi tiếp tục.\nThời Gian Ước Tính: ~30 phút Bước 1: Xóa Tài Nguyên CI/CD Pipeline Đầu tiên, xóa CI/CD pipeline để dừng mọi deployment tự động.\nTruy cập console AWS CodePipeline Chọn pipeline của bạn (ví dụ: ielts-pipeline) Click Delete pipeline → Xác nhận xóa Truy cập console AWS CodeBuild Xóa tất cả build projects liên quan đến workshop Xóa bất kỳ S3 buckets nào được sử dụng cho pipeline artifacts Bước 2: Xóa ECS Services và Cluster Dừng và xóa tất cả ECS services trước khi xóa cluster.\nTruy cập console Amazon ECS Chọn cluster của bạn (ví dụ: ielts-cluster) Vào tab Services Với mỗi service: Chọn service Click Update → Đặt Desired tasks thành 0 → Update Chờ các running tasks dừng lại Click Delete service → Xác nhận Sau khi tất cả services đã xóa, quay lại Clusters Chọn cluster → Delete cluster → Xác nhận Bước 3: Xóa ECR Repositories Xóa container images và repositories.\nTruy cập console Amazon ECR Chọn từng repository: ielts-frontend ielts-backend Click Delete → Nhập tên repository để xác nhận Bước 4: Xóa Tài Nguyên AI Service Xóa các thành phần AI serverless theo thứ tự:\n4.1 Xóa Lambda Functions Truy cập console AWS Lambda Xóa từng function: writing-evaluator speaking-evaluator flashcard-generator evaluation-status s3-upload Chọn function → Actions → Delete → Xác nhận 4.2 Xóa API Gateway Truy cập console Amazon API Gateway Chọn API của bạn (ví dụ: ielts-ai-api) Click Actions → Delete API → Xác nhận 4.3 Xóa SQS Queues Truy cập console Amazon SQS Xóa từng queue: writing-evaluation-queue writing-evaluation-dlq speaking-evaluation-queue speaking-evaluation-dlq flashcard-generation-queue flashcard-generation-dlq Chọn queue → Delete → Xác nhận 4.4 Xóa DynamoDB Tables Truy cập console Amazon DynamoDB Xóa từng table: evaluations flashcard-sets Chọn table → Delete → Xác nhận xóa Bước 5: Xóa Tài Nguyên Load Balancer Truy cập console EC2 → Load Balancers Chọn ALB của bạn (ví dụ: ielts-alb) Click Actions → Delete → Xác nhận Vào Target Groups Xóa tất cả target groups liên quan đến workshop Vào Listeners và xóa bất kỳ listeners còn lại Bước 6: Xóa Tài Nguyên Database 6.1 Xóa RDS Instance Truy cập console Amazon RDS Chọn database instance của bạn Click Actions → Delete Bỏ chọn Create final snapshot (nếu không cần) Chọn I acknowledge\u0026hellip; → Delete Việc xóa RDS có thể mất 5-10 phút để hoàn thành.\n6.2 Xóa ElastiCache (Redis) Truy cập console Amazon ElastiCache Chọn Redis cluster của bạn Click Delete → Xác nhận 6.3 Xóa RDS Subnet Group Trong RDS console, vào Subnet groups Chọn subnet group của bạn → Delete Bước 7: Xóa S3 Buckets Truy cập console Amazon S3 Với mỗi bucket đã tạo trong workshop: ielts-audio-bucket ielts-documents-bucket Bất kỳ pipeline artifact buckets nào Chọn bucket → Empty → Xác nhận Sau khi làm trống, chọn bucket → Delete → Xác nhận S3 buckets phải được làm trống trước khi có thể xóa.\nBước 8: Xóa Secrets Manager Secrets Truy cập console AWS Secrets Manager Chọn từng secret đã tạo cho workshop Click Actions → Delete secret Đặt thời gian khôi phục thành 7 ngày (tối thiểu) hoặc chọn xóa ngay lập tức Xác nhận xóa Bước 9: Xóa Tài Nguyên CloudWatch Truy cập console Amazon CloudWatch Vào Log groups Xóa các log groups: /aws/lambda/writing-evaluator /aws/lambda/speaking-evaluator /aws/lambda/flashcard-generator /ecs/ielts-frontend /ecs/ielts-backend Vào Alarms và xóa bất kỳ alarms đã tạo Bước 10: Xóa VPC và Tài Nguyên Mạng Xóa tài nguyên mạng theo thứ tự cụ thể này:\n10.1 Xóa NAT Gateway Truy cập console VPC → NAT Gateways Chọn NAT Gateway của bạn Click Actions → Delete NAT gateway → Xác nhận Chờ trạng thái chuyển thành Deleted 10.2 Giải Phóng Elastic IPs Vào Elastic IPs Chọn bất kỳ Elastic IPs nào liên kết với NAT Gateway Click Actions → Release Elastic IP addresses → Xác nhận 10.3 Xóa VPC Endpoints Vào Endpoints Chọn tất cả VPC endpoints đã tạo cho workshop Click Actions → Delete VPC endpoints → Xác nhận 10.4 Xóa Security Groups Vào Security Groups Xóa security groups theo thứ tự này (do phụ thuộc): Application security groups trước Database security groups Load balancer security groups Không xóa default security group 10.5 Xóa Subnets Vào Subnets Chọn tất cả subnets trong workshop VPC của bạn Click Actions → Delete subnet → Xác nhận 10.6 Xóa Route Tables Vào Route Tables Xóa custom route tables (không phải main route table) Chọn route table → Actions → Delete route table 10.7 Xóa Internet Gateway Vào Internet Gateways Chọn IGW → Actions → Detach from VPC → Xác nhận Chọn lại IGW → Actions → Delete internet gateway → Xác nhận 10.8 Xóa VPC Vào Your VPCs Chọn workshop VPC của bạn Click Actions → Delete VPC → Xác nhận Bước 11: Xóa Tài Nguyên IAM Truy cập console IAM Vào Roles và xóa: ecsTaskExecutionRole (nếu được tạo cho workshop này) ielts-lambda-execution-role Bất kỳ roles cụ thể nào khác của workshop Vào Policies và xóa custom policies đã tạo cho workshop Cẩn thận không xóa tài nguyên IAM được sử dụng bởi các ứng dụng khác.\nDanh Sách Kiểm Tra Xác Minh Sau khi hoàn thành dọn dẹp, xác minh tất cả tài nguyên đã được xóa:\nTài Nguyên Console Dịch Vụ Trạng Thái CodePipeline CodePipeline ☐ Đã xóa ECS Cluster ECS ☐ Đã xóa ECR Repositories ECR ☐ Đã xóa Lambda Functions Lambda ☐ Đã xóa API Gateway API Gateway ☐ Đã xóa SQS Queues SQS ☐ Đã xóa DynamoDB Tables DynamoDB ☐ Đã xóa Load Balancer EC2 ☐ Đã xóa RDS Instance RDS ☐ Đã xóa ElastiCache ElastiCache ☐ Đã xóa S3 Buckets S3 ☐ Đã xóa Secrets Secrets Manager ☐ Đã xóa CloudWatch Logs CloudWatch ☐ Đã xóa NAT Gateway VPC ☐ Đã xóa VPC VPC ☐ Đã xóa IAM Roles IAM ☐ Đã xóa Xác Minh Chi Phí Để đảm bảo không có khoản phí bất ngờ:\nVào console AWS Billing Kiểm tra Bills cho tháng hiện tại Xem Cost Explorer để xác minh không còn tài nguyên hoạt động Thiết lập Budget alert nếu bạn có kế hoạch tiếp tục sử dụng AWS Chờ 24-48 giờ và kiểm tra lại billing dashboard để xác nhận tất cả tài nguyên đã được dọn dẹp và không có khoản phí nào đang phát sinh.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9 Hoàn tất quá trình chuyển đổi sang framework phát triển AWS SAM (Serverless Application Model). Tái cấu trúc (Refactor) và triển khai lại các chức năng CRUD theo patterns kiến trúc SAM. Giải quyết các vấn đề liên quan đến môi trường để đạt được trạng thái triển khai thành công lên AWS. Tích hợp Docker cho môi trường build chuẩn hóa và quản lý dependencies. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu chuyên sâu về AWS SAM: Hiểu cấu trúc template.yaml, SAM CLI commands, và cách các tài nguyên Serverless (Lambda, API Gateway) hoạt động trong mô hình SAM. - Lập kế hoạch chiến lược migration: Chuyển đổi các Lambda functions hiện có sang cấu trúc tương thích SAM. - Nghiên cứu khả năng SAM local testing (sam local invoke, sam local start-api). 04/11/2024 04/11/2024 Tài liệu AWS SAM, AWS Study Group 3 - Tái cấu trúc mã nguồn: Viết lại các chức năng CRUD (Create/Read operations) sử dụng SAM patterns (Lambda handlers và API Gateway events). - Tích hợp Docker: Cài đặt và cấu hình Docker để đảm bảo môi trường Python runtime nhất quán cho quá trình sam build. - Tạo Dockerfile cho Lambda layer dependencies. 05/11/2024 06/11/2024 Tài liệu Docker, SAM CLI 4 - Gỡ lỗi và kiểm thử Local: Thực hiện sam local invoke để test các Lambda functions riêng lẻ. - Gặp sự cố nghiêm trọng trong môi trường Local: Dependency conflicts, Python version mismatches, vấn đề kết nối DynamoDB local. - Cố gắng giải quyết các rào cản local testing thông qua điều chỉnh cấu hình. 06/11/2024 07/11/2024 Báo cáo lỗi SAM CLI, Stack Overflow 5 - Ra quyết định chiến lược: Backend Team quyết định áp dụng chiến lược deploy-then-test trên môi trường AWS thực tế để vượt qua các hạn chế gỡ lỗi Local, chấp nhận rủi ro đã tính toán. - Tập trung khắc phục các lỗi cấu hình trong template.yaml (resource definitions, IAM permissions, environment variables). - Xác thực SAM template syntax và resource dependencies. 07/11/2024 08/11/2024 CloudFormation Template Validator 6 - Triển khai thành công: Thực hiện sam deploy --guided và triển khai thành công dự án lên môi trường AWS. - Xác thực cơ bản: Kiểm tra các API endpoints đã tạo bằng Postman/curl, xác nhận chức năng CRUD đã hoạt động. - Ghi lại quy trình triển khai và cấu hình cho team tham khảo. 08/11/2024 08/11/2024 Log triển khai AWS CloudFormation Kết quả đạt được tuần 9 Hoàn thành chuyển đổi công nghệ sang mô hình phát triển AWS SAM cho toàn bộ dự án. Tái cấu trúc thành công các chức năng CRUD vào cấu trúc Serverless của SAM với tổ chức handler phù hợp. Đã giải quyết vấn đề môi trường bằng cách sử dụng Docker để đảm bảo quá trình sam build sử dụng đúng Python version và dependencies. Đạt được cột mốc quan trọng: Triển khai thành công dự án lên môi trường AWS, vượt qua các trục trặc gỡ lỗi Local. Dự án Bandup IELTS hiện có phiên bản API hoạt động trên môi trường Cloud thực tế (mặc dù vẫn cần kiểm thử sâu hơn). Thiết lập deployment workflow và best practices cho hợp tác team. Tạo template.yaml toàn diện với resource definitions và IAM permissions phù hợp. Bài học chính:\nSAM đơn giản hóa phát triển serverless application với infrastructure as code Docker đảm bảo môi trường build nhất quán across các máy phát triển khác nhau Chiến lược deploy-then-test có thể khả thi khi local testing có vấn đề SAM templates cung cấp single source of truth cho serverless infrastructure IAM permissions phù hợp trong SAM templates là cực kỳ quan trọng cho Lambda function execution "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.1-blog1/","title":"Làm thế nào FINRA thiết lập khả năng quan sát vận hành thời gian thực cho các workload big data trên Amazon EMR chạy trên Amazon EC2 bằng Prometheus và Grafana","tags":[],"description":"","content":"Ngày đăng: 2024-11-15 – Tác giả: Sumalatha Bachu, PremKiran Bejjam, và Akhil Chalamalasetty trong AWS Big Data, Customer Solutions, Monitoring and observability.\nBài viết này là bài khách của FINRA (Financial Industry Regulatory Authority). FINRA cam kết bảo vệ nhà đầu tư và giữ vững tính liêm chính của thị trường theo cách thức thúc đẩy sự phát triển sôi động của các thị trường vốn.\nFINRA thực hiện xử lý big data với khối lượng dữ liệu lớn và các workload với kích cỡ và loại instance khác nhau trên Amazon EMR. Amazon EMR là một môi trường big data trên đám mây, được thiết kế để xử lý lượng dữ liệu lớn sử dụng các công cụ mã nguồn mở như Hadoop, Spark, HBase, Flink, Hudi và Presto.\nViệc giám sát các cluster EMR là việc làm cần thiết để phát hiện các vấn đề nghiêm trọng với ứng dụng, cơ sở hạ tầng, hoặc dữ liệu theo thời gian thực. Một hệ thống giám sát được tinh chỉnh tốt sẽ giúp nhanh chóng xác định nguyên nhân gốc rễ, tự động sửa lỗi, giảm thiểu các tác vụ thủ công, và tăng năng suất. Ngoài ra, việc quan sát hiệu suất và mức độ sử dụng của cluster theo thời gian còn giúp các đội vận hành và kỹ thuật tìm ra những điểm nghẽn hiệu suất tiềm tàng và các cơ hội tối ưu hóa để mở rộng cluster của họ. Nhờ đó, việc này giúp giảm bớt các tác vụ thủ công và cải thiện việc tuân thủ các thỏa thuận cấp độ dịch vụ.\nTrong bài viết này, chúng tôi sẽ thảo luận về những thách thức của mình và chỉ ra cách chúng tôi xây dựng một khung quan sát (observability framework) để cung cấp các thông tin chi tiết về số liệu vận hành cho các khối lượng công việc xử lý dữ liệu lớn trên các cluster Amazon EMR trên Amazon Elastic Compute Cloud (Amazon EC2).\nThách thức\nTrong thế giới lấy dữ liệu làm trọng tâm ngày nay, các tổ chức luôn nỗ lực để trích xuất những thông tin giá trị từ lượng lớn dữ liệu. Thách thức mà chúng tôi phải đối mặt là tìm ra một phương pháp hiệu quả để giám sát và quan sát các khối lượng công việc xử lý dữ liệu lớn trên Amazon EMR do tính phức tạp của nó. Việc giám sát và quan sát các giải pháp Amazon EMR đi kèm với nhiều thách thức khác nhau:\nĐộ phức tạp và quy mô – Các cluster EMR thường xử lý lượng dữ liệu khổng lồ trên nhiều nút (node). Việc giám sát một hệ thống phân tán và phức tạp như vậy đòi hỏi phải xử lý thông lượng dữ liệu cao và giảm thiểu tác động đến hiệu suất. Quản lý và diễn giải lượng dữ liệu giám sát lớn do các cluster EMR tạo ra có thể gây quá tải, khiến việc xác định và khắc phục sự cố kịp thời trở nên khó khăn. Môi trường động (Dynamic environments) – Các cluster EMR thường có tính chất tạm thời (ephemeral), được tạo và tắt dựa trên yêu cầu của khối lượng công việc. Tính động này gây khó khăn cho việc giám sát, thu thập các chỉ số và duy trì khả năng quan sát một cách nhất quán theo thời gian. Sự đa dạng của dữ liệu – Việc giám sát tình trạng cluster và có cái nhìn tổng quan về chúng để phát hiện các điểm nghẽn, hành vi bất thường trong quá trình xử lý, độ lệch dữ liệu (data skew), hiệu suất công việc (job performance),\u0026hellip; là rất quan trọng. Việc quan sát chi tiết các cluster chạy trong thời gian dài, các nút, các tác vụ, độ lệch dữ liệu tiềm ẩn, các tác vụ bị kẹt, các vấn đề về hiệu suất và các chỉ số cấp độ công việc (như Spark và JVM) là cực kỳ quan trọng để hiểu rõ. Đạt được khả năng quan sát toàn diện trên các loại dữ liệu đa dạng này là một điều khó khăn. Tối ưu hóa tài nguyên – Các cluster EMR bao gồm nhiều thành phần và dịch vụ hoạt động cùng nhau, khiến việc giám sát hiệu quả tất cả các khía cạnh của hệ thống trở nên thách thức. Giám sát việc sử dụng tài nguyên (CPU, bộ nhớ, I/O của đĩa) trên nhiều nút để ngăn chặn các điểm nghẽn và sự thiếu hiệu quả là điều cần thiết nhưng phức tạp, đặc biệt trong một môi trường phân tán. Độ trễ và các chỉ số hiệu suất – Việc thu thập và phân tích độ trễ cùng các chỉ số hiệu suất toàn diện theo thời gian thực để xác định và giải quyết vấn đề kịp thời là rất quan trọng, nhưng lại đầy thách thức do tính chất phân tán của Amazon EMR. Bảng điều khiển quan sát tập trung – Có một bảng điều khiển duy nhất (single pane of glass) cho tất cả các khía cạnh của chỉ số cluster EMR, bao gồm tình trạng cluster, việc sử dụng tài nguyên, quá trình thực thi công việc, nhật ký (logs) và bảo mật, nhằm cung cấp một bức tranh hoàn chỉnh về hiệu suất và tình trạng của hệ thống, là một thách thức. Cảnh báo và quản lý sự cố – Thiết lập các hệ thống cảnh báo và thông báo tập trung hiệu quả là một điều khó khăn. Việc cấu hình cảnh báo cho các sự kiện quan trọng hoặc ngưỡng hiệu suất đòi hỏi phải cân nhắc kỹ lưỡng để tránh tình trạng \u0026ldquo;mệt mỏi vì cảnh báo\u0026rdquo; (alert fatigue) trong khi vẫn đảm bảo các vấn đề quan trọng được giải quyết kịp thời. Ứng phó với các sự cố từ việc giảm tốc độ hoặc gián đoạn hiệu suất sẽ tốn thời gian và công sức để phát hiện và khắc phục nếu không có cơ chế cảnh báo phù hợp. Quản lý chi phí – Cuối cùng, tối ưu hóa chi phí trong khi vẫn duy trì việc giám sát hiệu quả là một thách thức liên tục. Cân bằng giữa nhu cầu giám sát toàn diện và các ràng buộc về chi phí đòi hỏi phải có kế hoạch cẩn thận và các chiến lược tối ưu hóa để tránh các chi phí không cần thiết mà vẫn đảm bảo khả năng giám sát đầy đủ. Khả năng quan sát hiệu quả cho Amazon EMR đòi hỏi sự kết hợp của các công cụ, phương pháp và chiến lược phù hợp để giải quyết những thách thức này, từ đó cung cấp khả năng xử lý dữ liệu lớn một cách đáng tin cậy, hiệu quả và tiết kiệm chi phí.\nHệ thống Ganglia trên Amazon EMR được thiết kế để giám sát tình trạng của toàn bộ cluster và tất cả các nút (node), hiển thị nhiều chỉ số (metrics) như Hadoop, Spark và JVM. Khi chúng ta xem giao diện web của Ganglia trong trình duyệt, chúng ta sẽ thấy một cái nhìn tổng quan về hiệu suất của cluster EMR, chi tiết về tải (load), mức sử dụng bộ nhớ, mức sử dụng CPU và lưu lượng mạng của cluster thông qua các biểu đồ khác nhau.\nTuy nhiên, với việc AWS đã thông báo ngừng hỗ trợ Ganglia cho các phiên bản AWS for higher versions of Amazon EMR, việc FINRA xây dựng giải pháp này trở nên quan trọng.\nTổng quan về giải pháp\nNhững thông tin chi tiết được rút ra từ bài viết Monitor and Optimize Analytic Workloads on Amazon EMR with Prometheus and Grafana đã truyền cảm hứng cho cách tiếp cận của chúng tôi. Bài viết này đã trình bày cách thiết lập một hệ thống giám sát bằng cách sử dụng Amazon Managed Service for Prometheus và Amazon Managed Grafana để giám sát hiệu quả một cluster EMR, và sử dụng các dashboard của Grafana để xem các chỉ số nhằm khắc phục và tối ưu hóa các vấn đề về hiệu suất.\nDựa trên những thông tin này, chúng tôi đã hoàn thành một bằng chứng về khái niệm (proof of concept) thành công. Tiếp theo, chúng tôi đã xây dựng giải pháp giám sát tập trung cho doanh nghiệp của mình với Managed Prometheus và Managed Grafana để mô phỏng các chỉ số giống như Ganglia tại FINRA. Managed Prometheus cho phép thu thập dữ liệu khối lượng lớn theo thời gian thực, có thể mở rộng khả năng tiếp nhận, lưu trữ và truy vấn các chỉ số vận hành khi khối lượng công việc tăng hoặc giảm. Các chỉ số này được chuyển đến không gian làm việc của Managed Grafana để trực quan hóa.\nGiải pháp của chúng tôi bao gồm một lớp tiếp nhận dữ liệu cho mọi cluster, với cấu hình để thu thập chỉ số thông qua một script tùy chỉnh được lưu trữ trong Amazon Simple Storage Service. Chúng tôi cũng đã cài đặt Managed Prometheus khi khởi động cho các instance EC2 trên Amazon EMR thông qua một bootstrap script. Ngoài ra, các thẻ (tag) cụ thể cho ứng dụng được định nghĩa trong tệp cấu hình để tối ưu hóa việc đưa vào và thu thập các chỉ số cụ thể.\nSau khi Managed Prometheus (được cài đặt trên các cluster EMR) thu thập các chỉ số, chúng sẽ được gửi đến một không gian làm việc (workspace) Managed Prometheus từ xa. Các workspace Managed Prometheus là các môi trường logic và biệt lập dành riêng cho các máy chủ Managed Prometheus, quản lý các chỉ số cụ thể. Chúng cũng cung cấp kiểm soát truy cập để cấp quyền cho những ai hoặc những gì được gửi và nhận chỉ số từ workspace đó. Bạn có thể tạo một hoặc nhiều workspace theo tài khoản hoặc ứng dụng tùy thuộc vào nhu cầu, điều này giúp quản lý tốt hơn.\nSau khi các chỉ số được thu thập, chúng tôi đã xây dựng một cơ chế để hiển thị chúng trên các dashboard của Managed Grafana, sau đó được sử dụng để tiêu thụ thông qua một endpoint. Chúng tôi đã tùy chỉnh các dashboard cho các chỉ số cấp độ tác vụ, cấp độ nút và cấp độ cluster để chúng có thể được chuyển từ môi trường thấp hơn lên môi trường cao hơn. Chúng tôi cũng đã xây dựng một số dashboard mẫu hiển thị các chỉ số cấp độ nút như các chỉ số cấp độ hệ điều hành (CPU, bộ nhớ, mạng, I/O của đĩa), các chỉ số HDFS, các chỉ số YARN, các chỉ số Spark và các chỉ số cấp độ công việc (Spark và JVM), tối đa hóa tiềm năng cho mỗi môi trường thông qua việc tổng hợp chỉ số tự động trong mỗi tài khoản.\nChúng tôi đã chọn tùy chọn xác thực dựa trên SAML, cho phép chúng tôi tích hợp với các nhóm Active Directory (AD) hiện có, giúp giảm thiểu công việc cần thiết để quản lý quyền truy cập của người dùng và cấp quyền truy cập dashboard Grafana dựa trên vai trò người dùng. Chúng tôi đã sắp xếp ba nhóm chính—quản trị viên (admins), người chỉnh sửa (editors) và người xem (viewers)—để xác thực người dùng Grafana dựa trên vai trò của họ.\nThông qua việc tự động hóa giám sát phức tạp, những chỉ số mong muốn này được đẩy tới Amazon CloudWatch. Chúng tôi sử dụng CloudWatch để cảnh báo khi cần thiết, khi các chỉ số vượt quá ngưỡng mong muốn.\nCác dashboard mẫu Các ảnh chụp màn hình sau đây giới thiệu các dashboard mẫu.\nKết luận\nTrong bài viết này, chúng tôi đã chia sẻ cách FINRA nâng cao việc ra quyết định dựa trên dữ liệu bằng khả năng quan sát khối lượng công việc trên EMR một cách toàn diện, nhằm tối ưu hóa hiệu suất, duy trì độ tin cậy và thu được các thông tin chuyên sâu quan trọng về các hoạt động dữ liệu lớn, từ đó dẫn đến sự xuất sắc trong vận hành.\nGiải pháp của FINRA đã cho phép các đội vận hành và kỹ thuật sử dụng một bảng điều khiển duy nhất (single pane of glass) để giám sát các khối lượng công việc dữ liệu lớn và nhanh chóng phát hiện bất kỳ vấn đề vận hành nào. Giải pháp có khả năng mở rộng này đã giúp giảm đáng kể thời gian xử lý sự cố và nâng cao tổng thể khả năng vận hành của chúng tôi. Giải pháp đã cung cấp cho các đội vận hành và kỹ thuật những thông tin chuyên sâu toàn diện về nhiều chỉ số Amazon EMR khác nhau như cấp độ hệ điều hành (OS levels), Spark, JMX, HDFS và Yarn, tất cả được tổng hợp tại một nơi duy nhất. Chúng tôi cũng đã mở rộng giải pháp này cho các trường hợp sử dụng như các cluster Amazon Elastic Kubernetes Service (Amazon EKS), bao gồm cả các cluster EMR trên EKS và các ứng dụng khác, biến nó thành một hệ thống duy nhất để giám sát các chỉ số trên toàn bộ cơ sở hạ tầng và ứng dụng của chúng tôi.\nSumalatha Bachu Sumalatha là Giám đốc cấp cao (Senior Director) của Bộ phận Công nghệ tại FINRA. Cô phụ trách mảng Vận hành Dữ liệu lớn (Big Data Operations), bao gồm việc quản lý dữ liệu quy mô petabyte và xử lý các khối lượng công việc phức tạp trên nền tảng đám mây. Ngoài ra, cô còn là một chuyên gia trong việc phát triển các giải pháp Giám sát và Quan sát Ứng dụng Doanh nghiệp, Phân tích Dữ liệu Vận hành, và các quy trình quản trị Mô hình Học máy. Ngoài công việc, cô thích tập yoga, luyện hát và dạy học trong thời gian rảnh rỗi. PremKiran Bejjam PremKiran là Kỹ sư Tư vấn chính (Lead Engineer Consultant) tại FINRA. Anh chuyên phát triển các hệ thống có khả năng phục hồi và mở rộng. Với sự tập trung cao độ vào việc thiết kế các giải pháp giám sát để tăng cường độ tin cậy của cơ sở hạ tầng, anh luôn tận tâm với việc tối ưu hóa hiệu suất hệ thống. Ngoài công việc, anh thích dành thời gian chất lượng bên gia đình và không ngừng tìm kiếm các cơ hội học hỏi mới. Akhil Chalamalasetty Akhil là Giám đốc (Director) của Bộ phận Công nghệ Giám sát Thị trường (Market Regulation Technology) tại FINRA. Anh là một chuyên gia về Dữ liệu lớn (Big Data), chuyên sâu trong việc xây dựng các giải pháp tiên tiến với quy mô lớn, cùng với việc tối ưu hóa khối lượng công việc, dữ liệu và khả năng xử lý của chúng. Akhil thích đua xe mô phỏng (sim racing) và xem đua xe Công thức 1 (Formula 1) trong thời gian rảnh. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10 Ổn định môi trường triển khai AWS SAM/Serverless và giải quyết các vấn đề quan trọng. Tập trung gỡ lỗi các vấn đề cốt lõi: Cấu hình CORS, template validation errors, và định dạng API response. Tích hợp Frontend/Backend để cho phép kiểm thử end-to-end trên giao diện người dùng. Hoàn thiện các chức năng Read và Delete cơ bản với error handling phù hợp. Tham gia sự kiện AWS Cloud Mastery Series để nhận hướng dẫn chuyên gia và giải quyết thách thức dự án. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Gỡ lỗi CORS: Phân tích cấu hình CORS trong API Gateway (CORS headers, preflight OPTIONS requests) và Lambda response headers để cho phép Frontend truy cập. - Khắc phục template validation errors: Rà soát và tối ưu file template.yaml để tránh deployment loop errors và resource dependency issues trong sam deploy. 11/11/2024 11/11/2024 Tài liệu API Gateway/CORS 3 - Củng cố chức năng Read (Truy xuất flashcard sets): Đảm bảo dữ liệu được query từ DynamoDB chính xác và trả về đúng định dạng JSON cho Frontend consumption. - Triển khai error handling cho missing records và invalid queries. - Thêm logging cho mục đích debugging. 12/11/2024 12/11/2024 Tài liệu DynamoDB Query 4 - Tích hợp Frontend: Bắt đầu kết hợp Frontend codebase với dự án và test các API endpoints đã deploy. - Thành công hiển thị danh sách flashcard sets trên giao diện người dùng. - Kiểm thử kết nối API và data rendering trong React/Vue components. 13/11/2024 13/11/2024 Tài liệu Frontend Framework 5 - Triển khai và kiểm thử chức năng Delete (Xóa flashcard sets). - Gặp lỗi: Xác định vấn đề authorization với Cognito User Sub ID khi thực hiện Delete function - Lambda không thể extract/process Sub ID từ Cognito token chính xác. - Bắt đầu troubleshooting authentication flow. 14/11/2024 14/11/2024 Tài liệu AWS Cognito 6 - Tham gia sự kiện AWS Cloud Mastery Series: + Nhận hướng dẫn chuyên gia và giải đáp các câu hỏi về Serverless architecture, Lambda best practices, và authentication patterns. - Phân tích lỗi Update/Delete: Áp dụng hướng dẫn từ Mentor để giải quyết vấn đề authorization và Cognito token parsing problems. - Ghi lại các giải pháp để tham khảo trong tương lai. 15/11/2024 15/11/2024 Mentor, AWS Cloud Mastery Series Kết quả đạt được tuần 10 Khắc phục thành công lỗi CORS và ổn định quá trình triển khai SAM (giảm thiểu template validation errors). Tham gia sự kiện AWS Cloud Mastery Series và thu thập thông tin thiết yếu để giải quyết các blockers lớn của dự án. Hoàn thành tích hợp Frontend và Backend, đạt được giao diện người dùng chức năng đầu tiên cho kiểm thử end-to-end. Đã triển khai thành công chức năng Read (Truy xuất flashcard sets) và Delete (Xóa flashcard sets), hoạt động trên giao diện web. Xác định và có hướng giải quyết cho các điểm nghẽn quan trọng: Lỗi authorization: Lambda không thể lấy/xử lý không đúng Cognito Sub ID từ JWT token, ảnh hưởng đến các thao tác cần quyền Dependency chức năng Update: Yêu cầu authentication flow phù hợp và token validation Dự án đã chuyển sang giai đoạn kiểm thử người dùng cơ bản với các thao tác CRUD hoạt động. Thiết lập debugging workflow và error handling patterns cho team. Bài học chính:\nCORS yêu cầu cấu hình phù hợp trong cả API Gateway và Lambda response headers Cognito JWT tokens phải được decode đúng cách để extract user identity (Sub ID) Tích hợp Frontend-Backend yêu cầu chú ý cẩn thận đến API contracts và data formats Error handling và logging là thiết yếu cho debugging production issues AWS Cloud Mastery Series cung cấp insights thực tế quý giá từ các practitioners giàu kinh nghiệm "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Tham gia sự kiện AWS Cloud Mastery Series #2 để tiếp tục giải đáp các vấn đề kỹ thuật chuyên sâu. Tái cấu trúc và thống nhất cấu trúc Frontend để tăng tính ổn định và dễ bảo trì. Triển khai kiến trúc Multi-Stack để tối ưu hóa tốc độ triển khai và quản lý dự án Serverless. Tích hợp các chức năng CRUD cơ bản với AI Image Processing (sử dụng Rekognition) vào trang web. Khắc phục triệt để các lỗi triển khai (đặc biệt là lỗi CORS) để ổn định hệ thống. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu CN - Tham gia sự kiện AWS Cloud Mastery Series #2 (Ngày 17/11): Tiếp tục nhận hướng dẫn và giải đáp thắc mắc chuyên sâu hơn về lỗi xác thực và luồng AI. 17/11/2024 17/11/2024 Mentor, AWS Cloud Mastery Series 2 - Thống nhất và tái cấu trúc Frontend: Tiến hành họp nhóm để thống nhất lại cấu trúc code Frontend nhằm đảm bảo tính đồng bộ và dễ bảo trì. - Nghiên cứu giải pháp Multi-Stack: Bắt đầu phân tích cách tách file template.yaml thành các Stack nhỏ hơn (Multi-Stack) để tối ưu hóa quá trình sam deploy. 18/11/2024 18/11/2024 Tài liệu Kiến trúc Serverless 3 - Triển khai kiến trúc Multi-Stack: Bắt đầu tách và cấu hình các Stack riêng biệt (như Stack cho Backend API, Stack cho Frontend Hosting). - Tiến hành tích hợp AI Image Processing: Kết hợp các chức năng CRUD cơ bản với logic xử lý ảnh (ví dụ: gọi API Rekognition/S3 trigger) để chuẩn bị cho chức năng Update. 19/11/2024 19/11/2024 Codebase Backend, AWS Rekognition 4 - Gặp lỗi sau khi tích hợp AI: Hệ thống tiếp tục gặp lỗi sau khi kết hợp chức năng AI, yêu cầu phải xóa Stack cũ và Deploy lại hoàn toàn. - Leader phát triển Stack dự phòng: Leader tạo một Stack Multi-Stack riêng biệt, đã tối ưu hóa, để dự phòng và làm tham chiếu cho việc triển khai tối ưu hóa sau này. 20/11/2024 20/11/2024 Stack dự phòng của Leader 5 - Lỗi CORS tái diễn: Sau khi deploy lại, hệ thống tiếp tục gặp lỗi CORS. - Gỡ lỗi CORS chuyên sâu: Dành thời gian phân tích triệt để nguyên nhân gốc rễ và sửa chữa dứt điểm lỗi CORS, đảm bảo các headers phản hồi được cấu hình chính xác trên cả API Gateway và Lambda. 21/11/2024 21/11/2024 Cấu hình API Gateway/Lambda 6 - Họp bàn và ổn định hóa dự án: Họp nhóm để kiểm tra cấu trúc Frontend mới, ổn định lại Stack dự án chính và đồng bộ hóa các bản sửa lỗi CORS và Template. - Tối ưu hóa bảo trì: Đưa ra giải pháp sử dụng Stack riêng (do leader phát triển) để đảm bảo tính linh hoạt và dễ tối ưu hóa trong quá trình phát triển tiếp theo. 22/11/2024 22/11/2024 Báo cáo cấu trúc mới Kết quả đạt được tuần 11: Tham gia chuỗi sự kiện AWS Cloud Mastery Series #2, thu thập thêm kiến thức sâu hơn về Serverless, Rekognition, và giải pháp cho các lỗi xác thực. Tái cấu trúc thành công Frontend và thống nhất được cấu trúc chung cho dự án, cải thiện khả năng bảo trì. Triển khai kiến trúc Multi-Stack (hoặc ít nhất là có giải pháp/Stack dự phòng) giúp đẩy nhanh quá trình deploy và dễ dàng quản lý tài nguyên. Khắc phục được triệt để lỗi CORS sau khi tìm ra nguyên nhân gốc rễ, đảm bảo đường truyền giữa Frontend và Backend ổn định. Lĩnh hội được cách khắc phục các lỗi Template cơ bản và hiểu rõ hơn về các vấn đề triển khai trên AWS SAM. Phát triển thêm Stack riêng biệt để dự phòng/tối ưu hóa, tăng tính linh hoạt và an toàn cho dự án trong các lần cập nhật lớn sau này. Dự án đã bước vào giai đoạn thử nghiệm chức năng AI, mặc dù vẫn còn lỗi, nhưng đã có hướng đi rõ ràng để gỡ rối. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.2-blog2/","title":"AWS cho các Ngành công nghiệp: 150 Mô hình và Đang tăng - Hướng dẫn về các Mô hình Generative AI cho Y tế và Khoa học Đời sống","tags":[],"description":"","content":"Ngày đăng: 07-05-2025 – Tác giả: Malvika Viswanathan, Amrita Sarkar, và Stephanie Dattoli trong Amazon Athena, Amazon Bedrock, Healthcare, Industries.\nGenerative AI đang định hình lại ngành Y tế và Khoa học Đời sống (HCLS). Từ AstraZeneca và Pfizer đến 3M và Allen Institute, các nhà đổi mới đang sử dụng AI để thúc đẩy quá trình khám phá thuốc, tăng năng suất của các nhà khoa học và hợp lý hóa các quy trình làm việc lâm sàng.\nKhi việc áp dụng ngày càng tăng, nhu cầu về các mô hình được tùy chỉnh cho những thách thức riêng biệt của HCLS cũng vậy—từ tóm tắt văn bản y tế, phân loại hình ảnh DICOM, đến cải thiện hiệu quả của việc khám phá thuốc. Tuy nhiên, nhiều tổ chức vẫn dựa vào truyền miệng hoặc các sự kiện trong ngành để xác định các mô hình phù hợp, gây ra cả sự trở ngại và chậm trễ trong vòng đời phát triển AI.\nĐó là lúc Amazon Web Services (AWS) Marketplace phát huy thế mạnh. Là danh mục được tuyển chọn lớn nhất về các mô hình AI cho y tế và khoa học đời sống, nó cung cấp quy trình mua sắm cấp doanh nghiệp đã được phê duyệt trước để hợp lý hóa việc triển khai ở quy mô lớn, tăng tốc độ khám phá các mô hình chuyên biệt của ngành và tích hợp nhanh chóng vào các quy trình lâm sàng, nghiên cứu hoặc vận hành. Dù bạn đang muốn cải thiện việc lựa chọn nhóm đối tượng, tăng tốc phát triển thuốc, hay mở rộng các quy trình làm việc về hình ảnh, AWS Marketplace giúp việc áp dụng mô hình generative AI phù hợp trở nên dễ dàng—và nhanh chóng.\nNhiều khách hàng đang chuyển sang áp dụng AI Tác nhân (Agentic AI) để cho phép các quy trình làm việc tự chủ trên chuỗi giá trị HCLS. Việc sử dụng đúng mô hình có thể giúp triển khai nhanh chóng các tác nhân để đưa ra các quyết định thông minh, phù hợp với ngữ cảnh mà không cần phải đào tạo mô hình.\nChúng tôi sẽ làm nổi bật một số mô hình generative AI phù hợp nhất hiện có trên AWS Marketplace, và khám phá các dịch vụ của AWS giúp vận hành AI ở quy mô lớn trong môi trường HCLS.\nTìm kiếm mô hình phù hợp Với việc nhiều tổ chức đã đặt nền móng cho việc áp dụng generative AI, chúng tôi đang thấy một sự thay đổi rõ rệt. Khách hàng ngày càng chuyển sang sử dụng các mô hình chuyên biệt cho từng ngành để giải quyết các thách thức phức tạp hơn. Một số khách hàng cũng đang tìm cách nâng cao các ứng dụng hiện có bằng các mô hình chuyên sâu, mang lại độ chính xác cao hơn, cải thiện tính an toàn và đạt được kết quả tốt hơn.\nSau đây là một số ví dụ nổi bật về cách các tổ chức hàng đầu đang tận dụng những mô hình chuyên biệt này (tất cả đều có sẵn trên AWS Marketplace):\nBio-FMs để nhận diện thuốc mới: Các mô hình Generative AI có thể giúp dự đoán các đặc tính hấp thụ, phân phối, chuyển hóa và bài tiết (ADME) quan trọng của các ứng viên thuốc. Bằng cách phân tích cấu trúc phân tử và dữ liệu hóa lý, các mô hình này có thể dự báo một hợp chất sẽ hoạt động như thế nào trong cơ thể. Evolutionary Scales’ ESMC models là một ví dụ điển hình cho loại mô hình này. Hoạt động y tế và an toàn bệnh nhân: Generative AI đang đóng vai trò quan trọng trong việc giám sát an toàn thử nghiệm lâm sàng, đặc biệt là xác định các phản ứng thuốc có hại tiềm ẩn (ADR). Mô hình John Snow Labs Adverse Drug Events (ADE) được đào tạo trên hơn 400 loại thực thể y tế, cho phép phát hiện chính xác ADR trong các nguồn dữ liệu phi cấu trúc như mạng xã hội và ghi chú lâm sàng. Thiết kế thử nghiệm lâm sàng: Các mô hình của QuantHealth dự đoán các điểm cuối của thử nghiệm lâm sàng và việc đăng ký tham gia thử nghiệm. QuantHealth sở hữu thư viện mô hình phát triển lâm sàng được đào tạo trên dữ liệu của hàng triệu cuộc sống bệnh nhân, dự đoán độ an toàn và hiệu quả với độ chính xác 85% trong các lĩnh vực ung thư, tim mạch và bệnh tự miễn. Các mô hình này sẽ có mặt trên AWS Marketplace vào tháng 5 năm 2025. Tối ưu hóa thử nghiệm lâm sàng: Các tổ chức khoa học đời sống ngày càng tìm đến các mô hình ngôn ngữ lớn (LLM) trên Amazon Bedrock, như Anthropic’s Claude, để hợp lý hóa việc tạo tài liệu thử nghiệm lâm sàng (ví dụ: giao thức thử nghiệm đối chứng ngẫu nhiên). Việc tự động hóa này giúp các đội nghiên cứu tập trung vào thiết kế nghiên cứu và tuyển dụng bệnh nhân. Các mô hình thị giác máy tính trong môi trường lâm sàng: Được sử dụng cho một loạt các ứng dụng từ giám sát PPE đến hỗ trợ chẩn đoán. Ví dụ, mô hình Diabetic Retinopathy Detector của VITech Lab phân tích hình ảnh quét võng mạc để phát hiện và xếp hạng các bất thường liên quan đến bệnh tiểu đường, giúp ưu tiên các trường hợp khẩn cấp. Phân tích hình ảnh bệnh lý để phát hiện ung thư sớm: Mô hình Bioptimus H-Optimus-O là mô hình nền tảng lớn nhất thế giới về bệnh lý học, với 1,1 tỷ tham số. Nó cho phép phân loại cấp độ bản vá (patch-level) của các lát cắt bệnh lý, hỗ trợ phát hiện ung thư sớm và giảm sự chậm trễ trong chẩn đoán. Tóm tắt y tế cho các quy trình làm việc lâm sàng: Các mô hình như John Snow Medical LLMs được xây dựng có chủ đích để tóm tắt ghi chú xuất viện, báo cáo X-quang và kết quả bệnh lý. Chúng giúp các bác sĩ lâm sàng điều hướng qua các dữ liệu phi cấu trúc dày đặc. Chẩn đoán và lập kế hoạch điều trị có hỗ trợ AI: Palmyra-Med 70B của Writer là một LLM được thiết kế riêng cho y tế, đạt điểm chuẩn sinh học y tế 85,87%. Nó thực hiện nhận dạng thực thể nâng cao, trích xuất các khái niệm y tế từ văn bản phi cấu trúc, hỗ trợ ra quyết định lâm sàng. Khám phá, tinh chỉnh và triển khai các mô hình generative AI trong ngành HCLS Khi bạn đã xác định được mô hình phù hợp, AWS cung cấp bộ công cụ đầy đủ để khám phá, tinh chỉnh và triển khai trong môi trường an toàn và tuân thủ.\nAmazon SageMaker Unified Studio – Phát triển và tinh chỉnh mô hình hoàn chỉnh Cung cấp môi trường tích hợp để xây dựng và tinh chỉnh các mô hình HCLS. Nó tích hợp liền mạch với Amazon EMR, AWS Glue, Amazon Athena, Amazon Redshift và các dịch vụ ML của SageMaker, cho phép:\nTinh chỉnh mô hình bằng các bộ dữ liệu chuyên biệt của HCLS. Xử lý dữ liệu đa phương thức (có cấu trúc, văn bản, hình ảnh, omics). Phát triển và triển khai các ứng dụng generative AI hoàn chỉnh. Amazon Bedrock – Suy luận và đánh giá mô hình nhanh chóng Lý tưởng để triển khai nhanh các mô hình nền tảng (FMs) mà không cần quản lý cơ sở hạ tầng. Với hơn 160 mô hình FM, các tính năng chính bao gồm:\nAmazon Bedrock Evaluations: Đánh giá và so sánh các mô hình nhanh chóng. Truy cập dựa trên API vào các mô hình hàng đầu. Tích hợp liền mạch với SageMaker và các công cụ AWS khác. AWS HealthOmics – Tăng tốc Khám phá Khoa học Tăng tốc thông tin chuyên sâu sinh học bằng các quy trình làm việc Ready2Run (từ NVIDIA, Sentieon, Element Biosciences), hỗ trợ:\nCác Thực tiễn Tốt nhất của GATK từ Broad Institute. AlphaFold để dự đoán cấu trúc protein. Các đường ống khám phá thuốc độc quyền. Các Giải pháp Lưu trữ của AWS Cơ sở hạ tầng dữ liệu an toàn và có thể mở rộng:\nAmazon S3: Lưu trữ dữ liệu linh hoạt, đa năng. AWS HealthImaging: Chuyên dụng cho hình ảnh y tế. AWS HealthOmics: Tối ưu hóa cho dữ liệu omics. Kết Luận Chúng tôi đã khám phá các trường hợp sử dụng chính trong ngành Y tế và Khoa học Đời sống (HCLS), nơi các mô hình generative AI chuyên biệt có thể mang lại những cải thiện đáng kể về hiệu suất kinh doanh và kết quả điều trị cho bệnh nhân.\nVới các công cụ như Amazon SageMaker và Amazon Bedrock, AWS cung cấp một trong những lựa chọn mô hình phong phú nhất được tùy chỉnh cho các thách thức của HCLS.\nCác bước tiếp theo:\nKhám phá danh mục các mô hình generative AI trên AWS Marketplace. Làm việc với đội ngũ AWS để xác định mô hình phù hợp với mục tiêu lâm sàng. Hợp tác với Kiến trúc sư Giải pháp AWS hoặc Đối tác AWS HCLS để thiết kế kiến trúc mở rộng. Tìm hiểu thêm tại:\nPre-training genomic language models using AWS HealthOmics and Amazon SageMaker John Snow Labs Medical LLMs are now available in Amazon SageMaker JumpStart Accelerate digital pathology slide annotation workflows on AWS using H-optimus-0 Malvika Viswanathan Malvika Viswanathan là Trưởng nhóm Giải pháp GenAI cho ngành Y tế và Khoa học Đời sống tại AWS. Cô có 15 năm kinh nghiệm làm việc với các tổ chức cung cấp dịch vụ, công ty bảo hiểm và tổ chức khoa học đời sống. Malvika chuyên giúp khách hàng áp dụng công nghệ mới nhất để chuyển đổi doanh nghiệp và mang lại kết quả tối ưu cho bệnh nhân. Amrita Sarkar Amrita Sarkar, Tiến sĩ, là Principal trong đội ngũ Healthcare \u0026amp; Life Sciences Startups tại AWS. Cô làm việc với các nhà sáng lập và nhà đầu tư để giúp các startup HCLS xây dựng ở quy mô lớn. Trước đây, cô là nhà đầu tư mạo hiểm tại Paris và đã cố vấn cho hàng trăm startup. Cô có bằng Tiến sĩ Sinh học Tính toán và MBA từ Collège des Ingénieurs. Stephanie Dattoli Stephanie Dattoli là Giám đốc Toàn cầu phụ trách Marketing về Khoa học Đời sống và Genomics tại AWS. Cô chuyên sâu về giao điểm giữa khoa học đời sống và công nghệ đám mây, giúp các tổ chức đưa sản phẩm mới ra thị trường. Cô có bằng cao học về di truyền học từ Đại học Stanford. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Hoàn thiện 100% các chức năng CRUD cơ bản và AI xử lý ảnh (bao gồm chức năng Update). Nâng cấp kiến trúc xử lý ảnh bằng cách tích hợp SQS để phân luồng và xử lý bất đồng bộ. Hoàn thành các tính năng thiết yếu cuối cùng của dự án: Bảo mật, Ghim Map, và SNS. Hoàn thiện các giao diện chính của Frontend, chuẩn bị mua tên miền và tham gia sự kiện AWS Cloud Mastery Series cuối cùng. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Hoàn thiện chức năng Update và AI: Khắc phục triệt để các lỗi cuối cùng (Sub ID, Rekognition) để chức năng CRUD và xử lý ảnh hoạt động trọn vẹn. 25/11/2024 25/11/2024 Hướng dẫn Mentor, Codebase Backend 3 - Nâng cấp luồng AI với SQS: Triển khai AWS SQS để tạo hàng đợi xử lý ảnh bất đồng bộ, giúp phân luồng và cải thiện hiệu suất khi lượng ảnh tải lên lớn. - Tạo luồng xử lý rõ ràng: Định nghĩa lại luồng đi của dữ liệu (Upload -\u0026gt; S3 -\u0026gt; SQS -\u0026gt; Lambda (AI) -\u0026gt; DynamoDB). 26/11/2024 26/11/2024 Tài liệu AWS SQS, Kiến trúc Lambda 4 - Frontend hoàn thiện giao diện: Hoàn tất các giao diện cho các trang chính (Homepage, Chi tiết bài viết, Trang quản lý cá nhân). - Triển khai Ghim Map: Tích hợp chức năng Ghim Map (Map Pinning) cho các bài viết, sử dụng dữ liệu định vị (geo data) trong DynamoDB hoặc một dịch vụ map phù hợp. 27/11/2024 27/11/2024 Codebase Frontend, DynamoDB Geo 5 - Hoàn thiện Bảo mật (Authorization): Tối ưu hóa việc xác thực và phân quyền (IAM Policy/Cognito), đặc biệt là việc lấy Sub chính xác cho các thao tác của người dùng. - Triển khai SNS: Tích hợp AWS SNS cho các tính năng thông báo cơ bản (ví dụ: thông báo khi bài viết được xử lý xong/tải lên thành công). 28/11/2024 28/11/2024 Tài liệu AWS SNS, Cognito/IAM 6 - Tham gia sự kiện AWS Cloud Mastery Series cuối cùng: Nhận hướng dẫn tổng thể về dự án, kiểm tra và hoàn thiện các phần còn thiếu (tên miền, bảo mật, SNS) trước khi demo. - Tên miền: Tiến hành nghiên cứu và chuẩn bị mua tên miền cho trang web, cấu hình DNS cơ bản (Route 53) nếu cần thiết (dựa trên hướng dẫn mentor). 29/11/2024 29/11/2024 Mentor, AWS Cloud Mastery Series, Route 53 Kết quả đạt được tuần 12: Hoàn thành 100% các chức năng CRUD cơ bản và AI xử lý ảnh, đảm bảo tính ổn định của hệ thống. Nâng cấp kiến trúc xử lý ảnh bằng cách tích hợp SQS và xác định các luồng xử lý bất đồng bộ rõ ràng, cải thiện hiệu suất và độ tin cậy. Hoàn thiện các tính năng thiết yếu: Đã triển khai Bảo mật, Ghim Map và thông báo bằng SNS. Giao diện Frontend cơ bản đã hoàn thiện, sẵn sàng cho việc trình bày. Tham gia thành công sự kiện AWS Cloud Mastery Series cuối cùng, nhận được hướng dẫn tổng thể để hoàn thiện dự án. Đã nghiên cứu và lên kế hoạch mua tên miền cho sản phẩm. Dự án đã đạt đến trạng thái Sẵn sàng trình bày (Demo Readiness). "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/","title":"Let&#39;s Architect! Modern Data Architectures","tags":[],"description":"","content":"Post date: Nov 05, 2024 – Authors: Luca Mezzalira, Federica Ciuffo, Vittorio Denti, and Zamira Jaupaj in Amazon Machine Learning, Amazon S3, Architecture, Artificial Intelligence, AWS Big Data.\nData is the fuel for AI; modern data is even more critical for generative AI and advanced data analytics, enabling more accurate, relevant, and impactful results. Modern data comes in many forms: real-time, unstructured, or user-generated. Each form requires a distinct solution.\nAWS\u0026rsquo;s data journey began with Amazon Simple Storage Service (Amazon S3) in 2006, marking the beginning of cloud storage at scale. Since then, AWS has expanded its data services to cover the entire data lifecycle, offering a comprehensive ecosystem designed to maximize the potential of modern data—from ingestion and storage to processing and analytics—supporting the full lifecycle of AI-driven innovation.\nIn this blog post, we will cover several AWS use cases for modern data architectures, demonstrating how AWS helps organizations leverage the power of data and generative AI technologies.\nKey considerations when choosing a database for your generative AI applications This blog post focuses on selecting the right database for generative AI applications and provides knowledge that can enhance your understanding, guide decision-making, and ultimately lead to more successful AI projects. Choosing the right database for generative AI applications is not just about storage; it significantly impacts performance, scalability, ease of integration, and the overall efficiency of the AI solution.\nFigure 1. Diagram describing the key steps in the RAG workflow\nTake me to this blog\nStrategies for building a data mesh-based enterprise solution on AWS Adopting a data mesh architecture can enhance an organization\u0026rsquo;s effective data management, thereby improving performance, driving innovation, and achieving overall business success. In this guidance, you will explore several strategies for building data mesh solutions on AWS.\nFigure 2. Data mesh architecture organizes data into domains, where data is treated as quality products to be served to users\nTake me to this guidance\nOptimizing storage price and performance with Amazon S3 Amazon S3 is an object storage service that supports many use cases, including data architectures. Big data pipelines can use Amazon S3 to store input data, output data, and temporary results. Machine learning systems use Amazon S3 to process application logs and build datasets for both testing and production model training.\nGiven the importance of this service and the number of use cases a foundational storage service can support, we want to share best practices, performance optimization strategies, and cost optimization strategies when working with Amazon S3. This video shows how Anthropic designed their architecture around Amazon S3 in their data architecture.\nFigure 3. Workloads with predictable access patterns often have low retrieval rates over a long period, so we can design to apply cheaper storage classes for them.\nTake me to this video\nNote: If you are curious about the foundational architecture of Amazon S3 and want to dive deeper into its internal design, you can watch the video Dive deep on Amazon S3 from re:Invent.\nHow HPE Aruba Supply Chain optimized cost and performance by migrating to an AWS modern data architecture This is an AWS case study on how HPE Aruba Supply Chain successfully re-architected and deployed their data solution by adopting a modern data architecture on AWS.\nThe new solution helped Aruba integrate data from multiple sources while optimizing cost, performance, and scalability. This also enabled Aruba Supply Chain leadership to receive timely insights to make better decisions, thereby enhancing the customer experience.\nFigure 4. Reference architecture diagram describing the HPE Aruba Supply Chain architecture, with Amazon S3 as a prominent component.\nTake me to this blog\nAWS Modern Data Architecture Immersion Day This workshop highlights the advantages of adopting a modern data architecture on AWS. By integrating the flexibility of a data lake with specialized analytics services, organizations can significantly enhance their data-driven decision-making capabilities.\nWe encourage everyone to explore how this architecture can streamline analytics processes and support diverse use cases, from gathering real-time insights to advanced machine learning. This is a great opportunity to leverage modern data architecture.\nFigure 5. Data architectures are the foundation for powering use cases, from analytics to machine learning.\nTake me to this workshop\nSee you next time!\nThanks for reading! In our next blog post, we will share some tips to help you have the best experience working as a developer on AWS. To revisit any previous posts or explore the entire series, visit the Let’s Architect! page.\nLuca Mezzalira Luca is a Principal Solutions Architect based in London. He is an author of multiple books and an international speaker. Luca specializes in solutions architecture and has received accolades for revolutionizing front-end architecture scalability using micro-frontends. Federica Ciuffo Federica is a Solutions Architect at Amazon Web Services. She specializes in container services and is passionate about infrastructure as code. Outside of work, she enjoys reading, drawing, and exploring cuisines. Vittorio Denti Vittorio Denti is a Machine Learning Engineer at Amazon, based in London. He has a background in distributed systems and machine learning. He is particularly passionate about software engineering and the latest innovations in machine learning science. Zamira Jaupaj Zamira is an Enterprise Solutions Architect based in the Netherlands. She is a passionate IT professional with over 10 years of experience designing and implementing complex solutions using containers, serverless, and data analytics. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://thienluhoan.github.io/workshop-template/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]